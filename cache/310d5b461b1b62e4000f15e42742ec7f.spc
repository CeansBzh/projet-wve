a:4:{s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"feed";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:6:{s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:32:"https://www.unrealengine.com/rss";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:66:"Unreal Engine - News, Developer Interviews, Spotlights, Tech Blogs";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:32:"https://www.unrealengine.com/rss";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:11:"description";a:1:{i:0;a:5:{s:4:"data";s:395:"Feed containing the latest news, developer interviews, events, spotlights, and tech blogs related to Unreal.  Unreal Engine 4 is a professional suite of tools and technologies used for building high-quality games and applications across a range of platforms. Unreal Engine 4’s rendering architecture enables developers to achieve stunning visuals and also scale elegantly to lower-end systems.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"language";a:1:{i:0;a:5:{s:4:"data";s:5:"en-US";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:5:"entry";a:24:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:36:"Unreal Engine 4.24 is now available!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:164:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Funreal-engine-4-24-is-now-available%2FNews_4.24_blog_thumb-375x275-48c85fb1d7f00a77f8ec006e8fe161f7c3dd874a.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:293:"New and enhanced features for everyone, from photoreal hair and fur, to new landscape tools, atmospheric skies, SSGI, enhanced multi-display rendering, first-class USD support, Visual Dataprep, and much more. Plus, Datasmith and all of Unreal Studio’s other features are included—for free!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:4017:"We’re excited to announce that Unreal Engine 4.24 is now available for download. As you may have heard, with this release, we’re retiring Unreal Studio and folding all of its features into Unreal Engine—for free. Unreal Engine is now your one-stop solution, whether you’re working in game development, architecture, film, television, automotive, training & simulation, or any other industry.<br />
<br />
There’s a host of new features and improvements across the board, with something for everyone. You can now create even more convincing interior and exterior scenes for games and visualization with new tools for nondestructively creating and editing open-world landscapes that adapt to other scene elements; gorgeous atmospheric skies; and Screen Space Global Illumination that scales across console and desktop platforms.<br />
<img alt="News_4.24_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Funreal-engine-4-24-is-now-available%2FNews_4.24_blog_body_img4-1640x692-f1ec17f638279f26f2b34b745d9201fe2167ed86.jpg" width="auto" /><br />
For those looking to create more believable characters, creatures, and virtual beings, we’re proud to offer a first look at our new strand-based hair and fur system that enables you to simulate and render hundreds of thousands of photoreal hairs at up to real time speeds.<br />
<br />
Formerly part of Unreal Studio, Datasmith—the toolkit for converting entire scenes at high fidelity from 3ds Max, SketchUp Pro, Cinema 4D, and a host of CAD and BIM formats—is now available for free as part of 4.24 and all future versions of Unreal Engine going forward. Add to that new Visual Dataprep for streamlined, easy-to-use, automated data preparation, and getting data from any source real-time ready is faster and easier. <br />
<img alt="News_4.24_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Funreal-engine-4-24-is-now-available%2FNews_4.24_blog_body_img2-1640x941-f43755399404b07ea905ef4cf3d640c5bc2700b0.jpg" width="auto" /><br />
That’s not to mention the first-class USD support that enables modelers and layout artists to work in parallel; enhancements to multi-display rendering that make it much easier to use out of the box, even on existing projects; and a new task-based wizard to give you a better starting point when creating new projects.<br />
<br />
And last, but definitely not least, in fulfilment of our <a href="https://www.unrealengine.com/en-US/blog/unreal-engine-4-24-to-ship-with-free-quixel-megascans-unreal-studio-features-and-more" target="_blank">announcement</a> last month, you can access Quixel Megascans in the Marketplace and through Quixel Bridge—all free for use with Unreal Engine.<br />
<img alt="News_4.24_blog_body_img5.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Funreal-engine-4-24-is-now-available%2FNews_4.24_blog_body_img5-1640x1000-6a340c8043076ff9b3e8fa858a01de04c33aab91.jpg" width="auto" /><br />
<a href="https://www.unrealengine.com/en-US/features" target="_blank"><span style="color:#3498db;"><strong>See all the new features</strong></span></a><br />
<br />
If you’re an existing Unreal Engine or Unreal Studio user, you can download Unreal Engine 4.24 from the Epic Games launcher. If you haven’t yet taken the plunge, there’s never been a better time; click the link below to get started. Either way, we hope you enjoy all the new features and upgrades, and as always, we encourage your feedback!<br />
<br />
<span style="font-size:18px;"><a href="http://www.unrealengine.com/eulacheck" style="font-size: 18px;"><span style="color:#3498db;"><strong>Get started now</strong></span></a></span><br />
<span style="font-size:12px;">Some features are beta or experimental, and should not be considered production ready. See the <a href="https://docs.unrealengine.com/en-US/Support/Builds/ReleaseNotes/4_24/index.html" target="_blank">Release Notes</a> for details.</span><br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:11:{i:0;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:8:"Features";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:9:"Datasmith";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:12:"Architecture";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:17:"Film & Television";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:23:"Broadcast & Live Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:8;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:9;a:5:{s:4:"data";s:2:"AR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:10;a:5:{s:4:"data";s:11:"Ray Tracing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 09 Dec 2019 13:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 09 Dec 2019 13:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:69:"https://www.unrealengine.com/blog/unreal-engine-4-24-is-now-available";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:69:"https://www.unrealengine.com/blog/unreal-engine-4-24-is-now-available";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:1;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:48:"Celebrating the winners of the 2019 Epic MegaJam";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:183:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fcelebrating-the-winners-of-the-2019-epic-megajam%2FNews_2019EpicMegaJam_THUMB-375x281-2226fbb38b2801805492a2f39331ed64a8a15136.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:152:"After many hours of gameplay and deliberation, it’s time to find out which teams are taking home top honors for the record-breaking 2019 Epic MegaJam!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:7393:"The <a href="https://itch.io/jam/2019-epic-megajam" target="_blank">2019 Epic MegaJam</a> celebrated five fantastic years of Unreal Engine jams and smashed records with more than 460 submissions and over 1,000 jammers. From steathy space cats sneaking through ships, to clouds tasked with saving the human race, to dangerous dives into dark caverns, and beyond—participants pulled out all the stops and showcased limitless creativity. This year’s winners took home incredible prizes, including a GDC experience package from <a href="http://software.intel.com/en-us" target="_blank">Intel</a> and custom Unreal Engine-branded PCs from <a href="http://www.falcon-nw.com/" target="_blank">Falcon Northwest</a>!<br />
<img alt="News_MegaJam-Winners_body-img.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fcelebrating-the-winners-of-the-2019-epic-megajam%2FNews_MegaJam-Winners_body-img-1600x900-f82e15faf59d0944b4d60ec374a91f54b6b9c0f3.png" width="auto" />
<div style="text-align: center;"><em>Space Cats.</em></div>
<br />
On November 14, jammers began their week-long journey to create a game based on this year’s theme, “Down to Earth,” provided during the Epic MegaJam kickoff <a href="https://www.youtube.com/watch?v=RqPwOWn01ew&amp;feature=youtu.be&amp;list=PLZlv_N0_O1gbggHiwNP2JBXGeD2h12tbB" target="_blank">livestream</a>. Shortly thereafter, developers began <a href="https://twitter.com/search?q=%23ue4jam%20OR%20%23UnrealJam&amp;src=recent_search_click" target="_blank">sharing images</a> of cute cats in spacesuits, creepy characters in plague masks, and crowded control panels.

<div style="text-align: center;"> </div>
With hundreds of submissions coming in by the deadline, our judges had their work cut out for them. While they toiled away behind the scenes, community developer <a href="https://www.twitch.tv/shadowriver" target="_blank">Shadowriver</a>, well-known for his activity on AnswerHub, streamed over 40 hours of gameplay! <br />
<br />
The caliber of the entries in the 2019 Epic MegaJam was nothing short of impressive. From stunning graphics, to quirky gameplay elements, and moving storylines, it was clear that the Unreal community poured their heart and soul into their submissions. 
<div style="text-align: center;"><img alt="News_MegaJam-Winners_body-img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fcelebrating-the-winners-of-the-2019-epic-megajam%2FNews_MegaJam-Winners_body-img2-770x770-0f586689f541247d958c4c8094598ebac5d5d7c9.jpg" width="auto" /><br />
<em>Play all the entries on the official <a href="https://itch.io/jam/2019-epic-megajam" target="_blank">2019 Epic MegaJam Itch.io page!</a></em></div>

<div><br />
This year’s incredible event would not have been possible without the help of our generous sponsors: <a href="https://software.intel.com/en-us" target="_blank">Intel</a>, <a href="https://www.falcon-nw.com/" target="_blank">Falcon Northwest</a>, <a href="http://www.assembla.com/" target="_blank">Assembla</a>, <a href="https://www.unrealengine.com/marketplace/en-US/profile/Dekogon+Studios" target="_blank">Dekogon</a>, <a href="https://www.dxracer.com/" target="_blank">DXRacer</a>, <a href="http://gametextures.com/" target="_blank">GameTextures.com</a>, <a href="https://www.unrealengine.com/marketplace/en-US/profile/Gokhan+Karadayi" target="_blank">G&ouml;khan Karadayi</a>, <a href="http://www.igda.org/" target="_blank">IGDA</a>, <a href="http://lenovo.com/" target="_blank">Lenovo</a>, <a href="https://www.unrealengine.com/marketplace/en-US/profile/Project+Nature" target="_blank">Project Nature</a>, <a href="https://quixel.com/" target="_blank">Quixel</a>, <a href="https://www.unrealengine.com/marketplace/profile/SB" target="_blank">SB</a>, <a href="https://www.sidefx.com/" target="_blank">SideFX</a>, <a href="https://www.unrealengine.com/marketplace/profile/silvertm" target="_blank">SilverTM</a>, <a href="https://getsoundly.com/" target="_blank">Soundly</a>, and <a href="https://www.wholetomato.com/" target="_blank">Whole Tomato</a>.</div>
<br />
And thank you to the jammers. As always, you humble us with your talent, and support of one another. We hope you had fun and learned something along the way. <br />
<br />
Without further ado, the winners of the 2019 Epic MegaJam are...
<h2><strong>First Place: <a href="https://jestersheepy.itch.io/planted" target="_blank">Planted</a> | Pixel Collective</strong></h2>

<div style="padding:42.19% 0 0 0;position:relative;"><iframe allow="autoplay; fullscreen" allowfullscreen="" frameborder="0" src="https://player.vimeo.com/video/375008711" style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe></div>

<h2><strong>Second Place & Space Cats Modifier: <a href="https://ogniok.itch.io/cosmic-catastrophe" target="_blank">Cosmic Catastrophe</a> | Fireline</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/_rcrILi3j1w" width="100%"></iframe></div>

<h2><strong>Third Place: <a href="https://timergames.itch.io/careful-descent" target="_blank">Careful Descent</a> | Snake Rake</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/vLIchca0qCw" width="100%"></iframe></div>

<h2><strong>Army of One: <a href="https://vaei.itch.io/deltanian-invasion" target="_blank">Deltanian Invasion</a> | Vaei</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/mez86n8bHNs" width="100%"></iframe></div>

<h2><strong>Friends and Foes: <a href="https://schultzika.itch.io/escape-velocity" target="_blank">Escape Velocity</a> | Indecisive Raccoon</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/w7egQR0ZOzY" width="100%"></iframe></div>

<h2><strong>Is this real life?: <a href="https://slappy-inc.itch.io/slappy-board" target="_blank">Slappy Board</a> | Slappy Inc.</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/8W8saUYWaCw" width="100%"></iframe></div>

<h2><strong>Tiny Award: <a href="https://partlyatomic.itch.io/cat-earth-society" target="_blank">The Cat-Earth Society</a> | Nova Space Agency</strong></h2>

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/EfDYfgtOOFI" width="100%"></iframe></div>

<div style="text-align: center;">
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/EOaOWYSZTI8" width="100%"></iframe></div>
<em>Watch us play through the winning games!</em>

<div style="text-align: left;"><br />
Congrats to all of this year’s winners! See you for the next <a href="https://twitter.com/search?q=%23UnrealJam&amp;src=typed_query" target="_blank">#UnrealJam</a>!</div>
</div>
<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:3:{i:0;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:13:"Amanda Schade";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 13 Dec 2019 18:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 13 Dec 2019 18:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:82:"https://www.unrealengine.com/blog/celebrating-the-winners-of-the-2019-epic-megajam";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:82:"https://www.unrealengine.com/blog/celebrating-the-winners-of-the-2019-epic-megajam";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:2;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:65:"Interactive VR training improves construction site safety and ROI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:210:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_thumb_-375x275-37a7e4884bd56987845ba0c360e0eb275cee876f.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:242:"Digital platform TwinSite is a virtual interactive world set in and around construction sites. Providing immersive VR and display-based training, it’s estimated to be up to four times more cost efficient than traditional offsite training. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:12814:"Up until relatively recently, the construction industry has been conservative when it comes to change. With <a href="https://en.wikipedia.org/wiki/Industry_4.0" target="_blank">Industry 4.0 technologies</a> promising to enhance efficiency, quality, and safety while also reducing costs, many management consultancy firms predict the time is now ripe for rapid digitalization and disruption.<br />
<br />
Digital platform TwinSite is one of the innovations on the frontier of this shift. Launched by <a href="https://www.ramirent.com/" target="_blank">Ramirent/Loxam</a>, Europe’s largest rental construction equipment provider, TwinSite is a virtual world set in and around interactive construction sites.<br />
<img alt="Spotlight_Twinsite_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img3-1640x1000-bab925e4135c53dfb436e122e60c083f4f6672d1.jpg" width="auto" /><br />
Built in Unreal Engine by real-time media and production studio <a href="https://www.onereality.com/" target="_blank">One Reality</a>, the platform provides an immersive, interactive learning environment for construction site personnel. “TwinSite will grow over time to comprise many different types of construction sites in their different phases,” explains Magnus Arfors, Chairman at One Reality. “It will serve as a virtual marketing communication and innovation platform for a large number of brands, with a view to improving site safety, business efficiency, and sustainability within the construction industry.”
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/WRHFDBlXHao" width="100%"></iframe></div>

<h3><strong>VR learning to improve knowledge transfer </strong></h3>
Regulations that require rental companies to train on health and safety before renting equipment vary across Europe. But even in places where there is no law explicitly demanding it, many offer this service regardless in order to support their customers, who are obliged in their turn to meet tough safety standards. <br />
<img alt="Spotlight_Twinsite_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img1-1640x1000-a671c94ab0651885cf1c9773591c37bf396dd092.jpg" width="auto" /><br />
This is where the digital platform TwinSite is helping to reduce costs and boost knowledge transfer. “TwinSite increases the wider understanding of the risks, overall function, and design of what we call the ‘temporary factory,’ ” explains Anders Vikmyr, Business Development Manager at Ramirent. “The temporary factory is a combination of everything temporary needed to erect a building or structure, such as cranes, hoists, scaffolding, temporary heating, and locker rooms.”<br />
<br />
Rather than taking place at an off-site training facility, TwinSite can be set up and used at the construction site, either in 2D on a traditional flat screen or in virtual reality for a more immersive, realistic experience. <br />
<img alt="Spotlight_Twinsite_blog_body_img8.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img8-1640x1000-57681d38c739851a842660e4cea09ba489f86007.jpg" width="auto" /><br />
Site workers schedule in a time slot and take part in educational courses that include operational procedures and safety instructions. The immersive nature of the interactive VR environment, which accurately replicates real-word scenarios, has been found to <a href="https://phys.org/news/2018-12-vr-engaging-video-textbooks-classroom.html" target="_blank">improve knowledge transfer</a> compared to traditional teaching methods, while also providing a safe and cost-effective training ground for hands-on personnel.<br />
<img alt="Spotlight_Twinsite_blog_body_img11.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img11-1640x1000-4143215b9d9f81ea746a6cc4ae9ab6e163d5679a.jpg" width="auto" /><br />
There are currently two training courses available on TwinSite: Cutter VR and Silica Dust VR, which can be accessed via the Concrete Room on the platform’s main virtual construction site. The Concrete Room is a virtual environment that houses several stations to be completed for each course.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/CiZkFwJ1odc" width="100%"></iframe></div>
In Cutter VR, users learn the correct operational procedures and handling of Husqvarna concrete cutters. They’re taught how to pick the correct type of blade for each job and how to perform maintenance checks on the equipment. Concrete cutters can be dangerous in real life due to the risk that they might kick back. This is replicated virtually in the course, providing shock value without the danger. <br />
<img alt="Spotlight_Twinsite_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img7-1640x1000-c8b199ca977d7754fde5a9bb713250a086882d35.jpg" width="auto" /><br />
In the Silica Dust VR course, users are taken through a series of interactive lessons on silica dust—one of the <a href="http://www.hse.gov.uk/construction/healthrisks/cancer-and-construction/silica-dust.htm" target="_blank">biggest health hazards</a> to construction workers today. Part of the lesson involves being shrunk down to microscopic scale, and experiencing the drastic effect of silica dust on the <a href="https://en.wikipedia.org/wiki/Pulmonary_alveolus" target="_blank">alveoli</a> and the <a href="https://en.wikipedia.org/wiki/Cilium" target="_blank">cilia</a> of the lungs. This course has educated around 400 people to date about the dangers of silica dust and how to mitigate the risks, receiving overwhelmingly positive feedback from users.<br />
<img alt="Spotlight_Twinsite_blog_body_img5.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img5-1640x1000-7a8b9e4174b5d413812e66d4fc5d546dc11c4084.jpg" width="auto" />
<h3><strong>Real-time training for improved ROI </strong></h3>
The ROI benefits of real-time training over traditional methods can be significant. Traditional teacher-led training requires site personnel to be away from a construction project for half a day or more to complete a course. That’s without taking into account the travel time and expense to get there. With TwinSite, instead of sending 10 people at a time to a training facility, Ramirent can go straight to the customer and set up the VR kit, often at a building shed on the construction site. One Reality and Ramirent estimate that VR training on site can be up to four times more cost efficient than traditional offsite training. <br />
<br />
“Each trainee books a one-hour slot, just as they would for the dentist,” says Vikmyr. “This saves a huge amount of time and enables the day-to-day activities on site to continue virtually uninterrupted.” What’s more, immersive training has proven to be extremely efficient in comparison to traditional training. Ramirent has found that less than one hour is enough for both the learning element and the subsequent test element of the course. And it’s proven remarkably effective in transferring knowledge, with personnel achieving average scores of over 90% on tests.<br />
<img alt="Spotlight_Twinsite_blog_body_img12.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img12-1640x1000-c707d94c8dfe8aed78f79032cf468df4cc621682.jpg" width="auto" /><br />
What’s more, the benefits go beyond reduced training costs and increased knowledge. “In addition to training, TwinSite can reduce costs as a virtual hub for communication and innovation,” says Arfors. “For example, Husqvarna products get exposed over and over again in education and demos, without the need for Husqvarna’s representatives to even be present.”
<h3><strong>Higher output with fewer programmers thanks to Blueprint </strong></h3>
One Reality has been using Unreal Engine to create virtual worlds and experiences since 2016. “We use it because we appreciate its great performance and flexibility,” says Arfors. <br />
<img alt="Spotlight_Twinsite_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img4-1640x1000-c60ca0efedec2091ec8fd010b2675a86057fc2ed.jpg" width="auto" /><br />
The team at the studio built the TwinSite virtual environment in the engine, and are involved in developing new virtual learning modules for the existing virtual infrastructure. The work they’ve delivered is all the more impressive given the comparatively small size of the team. “We’ve managed to produce the content with relatively few C++ programmers due to Blueprint,” Arfors says.<br />
<br />
The <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprint visual scripting system</a> in Unreal Engine provides a fast and efficient way for designers to get their hands on the full range of tools usually only available to programmers. Instead of having to write code line by line, everything is done visually: drag and dropping nodes, setting their properties in a UI, and dragging wires to connect.<br />
<br />
As well as harnessing the power of Blueprint, the team also came up with an innovative use of motion capture on the project. “We’ve set up our own motion capture system in order to speed up the time it takes to produce animations,” explains Arfors. “We also put a tracker on a real concrete cutter in order to create a high-end experience involving a real machine, which was easy thanks to UE4.”
<h3><strong>Interactive visualization driving change in construction</strong></h3>
Vikmyr predicts immersive and interactive environments like TwinSite will have a transformative effect on construction. “The construction industry faces significant challenges in terms of overall efficiency,” he says. “It’s also one of the most dangerous industries to be employed in. Thanks to its ability to bring high-quality knowledge transfer to the masses in an efficient way, TwinSite will have a positive effect on these aspects, helping the industry to become more sustainable in the process.” <br />
<img alt="Spotlight_Twinsite_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Finteractive-vr-training-improves-construction-site-safety-and-roi%2FSpotlight_Twinsite_blog_body_img2-1640x1000-d109aa4cd44e6e9041582975eae1a57c4b25a469.jpg" width="auto" /><br />
Arfors also believes the platform has the potential to be a real driver for change across the industry. “We have reason to believe that we are actually changing attitudes and that people are starting to take risks seriously,” he says. What’s more, he credits the realism achievable in Unreal Engine as a key factor in this. “Some users even spontaneously start to cough when they see the dust coming from the concrete cutter,” he continues. “It’s the result of a quality experience built in UE4.”<br />
<br />
The adoption of digital strategies across the design, engineer, and build process will lead to even greater synergies in the future. Once you have a virtual representation of a product or project, the incremental work of using it for a different part of the process becomes significantly easier. The digital asset of the concrete cutter used for sales and marketing can become the digital asset used for training and maintenance. While we’re far from this being the common practice, the promise of using real-time assets across all these tasks is where the industry is trending.<br />
<br />
<br />
Want to create your own immersive environments for training? <a href="https://www.unrealengine.com/en-US/enterprise/contact-us" target="_blank">Get in touch</a> and we’d love to start that conversation.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:8:{i:0;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:12:"Architecture";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:5:"Mocap";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:8:"Ramirent";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:11:"One Reality";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:8:"TwinSite";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:12:"Ken Pimentel";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 13 Dec 2019 15:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 13 Dec 2019 15:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:105:"https://www.unrealengine.com/spotlights/interactive-vr-training-improves-construction-site-safety-and-roi";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:105:"https://www.unrealengine.com/spotlights/interactive-vr-training-improves-construction-site-safety-and-roi";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:3;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:72:"Unreal Engine: the open automotive platform and data model of the future";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:211:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_feed_thumb-1400x788-368c297c54f979340f6f78d1bb668712e1960605.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:245:"From testing, simulation, and validation in the design and engineering stages to VR showrooms and online car configurators, the automotive industry’s data model of the future is set to stay contained within a game engine—and be fully open. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:10274:"We’re currently living through the fourth industrial revolution, with technology blurring the lines between the physical, digital, and biological worlds. In the automotive industry, real-time technology is one of the threads of this transformation that has already brought about significant change. <br />
<br />
Now maturing as an innovation, it’s become commonplace to find interactive tools throughout the automotive workflow, from augmented driving research to AR-based service training. We’re on the cusp of the next phase in the real-time era, where this technology will consolidate and reach its true potential. We envision a supercharged automotive production pipeline leveraging tools that are based on an open platform, which is licensed for free and provides users with direct access to the source code.<br />
<img alt="Spotlight_AFG_Quote_v2B.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_Quote_v2B-1640x350-6aa07b54b37bb922b49027c65e0b854a1c445469.png" width="auto" />
<h3><strong>The data model of the future </strong></h3>
Today’s automotive data model is built on the concept of centralized design data that third-party tools access to analyze and display results. With multiple tools each producing their own data, your flexibility to bring together data from different sources is limited by the inability of tools to share it. <br />
<br />
Further compounding this restriction, the process of collaborating, experiencing, visualizing, and interacting with the data is limited by each tool’s capabilities. Ultimately, that means your ability to work effectively is determined by a mix of vendors who attempt to predict your needs. But what if you could control and manage how data works for your process and problems?<br />
<br />
That is our vision for where the automotive pipeline goes next. One holistic open platform that covers the entire pipeline from end to end, from visualizing the initial design, through to reviewing, testing, and training in the engineering stages, and finally to creating beautiful marketing renders and photorealistic configurators. With an open-data ethos, a new world of possibilities will be established, providing an opportunity for OEMs to transform the way we work in the automotive industry. <img alt="Spotlight_AFG_blog_body_img_Audi.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_blog_body_img_Audi-1640x1000-c59f7b3c42a476f330e9f86c35ba6ff812fdc52f.jpg" width="auto" />The data model of the future is to stay contained within a game engine, on a fully open platform where the features and tools that you need are already available without switching between different software packages, eliminating the necessity to redo data and meta tags all over again whenever you work on a particular use case. By replacing the process of pushing data through individual tools for tessellation, data repair, and modeling, an open-platform approach gives the freedom to break free of the restrictions of these conventional tools, offering an easier way of connecting them, and unlocking more ways of working.<br />
<br />
There are a number of trends shaping today’s industry that mean now is the right time for a platform that truly enables an open automotive digital twin—and several considerations that must inform any approach to its development. 
<h3><strong>Relevance</strong></h3>
For an end-to-end automotive workflow platform to be successful, every process and tool it provides must be relevant. The most important consideration behind the decisions taken in developing functionality should be “how does this empower the user to have an impact on the product?” Features on the roadmap will be directly informed by the needs of vehicle manufacturers. The driving influence on the features selected for development will be the day-to-day tasks and projects they are working on. We believe that keeping close proximity to the community that uses these tools has to be a guiding principle. <br />
<img alt="Spotlight_AFG_Quote_v1B.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_Quote_v1B-1640x250-eb985de0628954e75058a3b0bfe64f1a81581822.png" width="auto" />
<h3><strong>Synthetic realities</strong></h3>
In an era of <a href="https://trends.fjordnet.com/trends/synthetic-realities" target="_blank">synthetic realities</a>, there is an expectation that cutting-edge visualization tools will have immersive capabilities. Similar to how virtual production is increasingly pushing innovation across the various stages of filmmaking, interactive tools have the potential to change traditional workflows in the automotive production pipeline, disrupting the industry in a positive way and fundamentally changing how content is created. The photorealistic visualizations and interactive environments that real-time rendering enables puts the technology at the heart of this paradigm. 

<h3><strong>Post-digital tools</strong></h3>
The automotive industry has undergone a period of change unlike anything that has been seen before. Connected, autonomous, shared and electric <a href="https://www.daimler.com/case/en/" target="_blank">(CASE)</a> vehicles, and mobility-as-a-service (MaaS) solutions have arrived and are evolving at a breakneck pace. The industry is on the brink of the post-digital era. Key players will not only need recently acquired digital tools—they’ll also need new ones. Mastering technologies that include distributed ledger technology, artificial intelligence, extended reality, and quantum computing will be key to success. <img alt="Spotlight_AFG_blog_body_img_Lambo.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_blog_body_img_Lambo-1640x1000-53281712001d01d4615df757f9e8712a4a25945d.jpg" width="auto" />
<h3><strong>Industry 4.0</strong></h3>
Armed with a set of new AI-driven tools, a handful of key automotive partners will be the pioneers of <a href="https://www.forbes.com/sites/bernardmarr/2018/09/02/what-is-industry-4-0-heres-a-super-easy-explanation-for-anyone/#7bf92c749788" target="_blank">Industry 4.0</a>: data-led manufacturing where information from every stage of the product life cycle can be leveraged to build higher-quality, cost-efficient products at a faster pace. Game engine technology will drive the automotive digital twin to the next level, bringing together the key technologies of the Internet of Things (IoT), 3D simulation tools, and predictive analytics to provide analysis of data and monitoring of systems that solve problems before they even occur.

<h3><strong>Digital change and adoption </strong></h3>
These converging technological trends mean that players in the automotive industry are at a crossroads. Sweeping digital change is set to transform traditional pipelines and workflows, making them smarter, faster, and more cost-efficient. The core functionality of real-time game engine technology means it will be a key pillar of this digital transformation.<br />
<img alt="Spotlight_AFG_blog_body_img_McLaren.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_blog_body_img_McLaren-1640x814-c1bbda135bf7288f70ecaf8422f6cf924a583683.jpg" width="auto" />Production proven in the world of AAA Games, Unreal Engine is built for high performance, provides photorealistic visualization, and has interactive collaboration at its heart. Artist-friendly tools such as the <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprint visual scripting system</a> and the <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/Editor/index.html" target="_blank">Material Editor</a> open out workflows to non-technical personnel, enabling more people to bring their skills to bear. Public access to the technology’s source code and the fact that it’s free to use mean teams can adapt the technology to their specific needs and benefit from increased ROI straight off the bat. <br />
<br />
These innate capabilities mean Unreal Engine can play a key role as a standard data simulation and visualization platform for the automotive industry across digital transformation, extended reality, and digital collaboration. The work to build the industry&#39;s go-to automotive platform and data model is already underway. Focusing initially on collaboration, visualization, and simulation, we’re developing the tools that will replace conventional content pipelines.<img alt="Spotlight_AFG_blog_body_img_Daimler.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Funreal-engine-the-open-automotive-platform-and-data-model-of-the-future%2FSpotlight_AFG_blog_body_img_Daimler-1640x1000-2e141018071615ec47f9493ef3f48fd8e8f8e143.jpg" width="auto" />Initial efforts include a new <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/HDRIBackdrop/index.html" target="_blank">HDRI workflow</a> that provides a simpler way of lighting virtual vehicles with imagery taken from real-world environments, a <a href="https://docs.unrealengine.com/en-US/Studio/Datasmith/Variants/Overview/index.html" target="_blank">Variant Manager</a> that enables you to set up multiple different configurations of your asset and switch between them at runtime, and <a href="https://www.unrealengine.com/en-US/blog/pixel-streaming-delivering-high-quality-ue4-content-to-any-device-anywhere" target="_blank">Pixel Streaming</a> to online configurators that will provide a new way of delivering interactive applications.<br />
<br />
<br />
Intrigued? <a href="https://www.unrealengine.com/en-US/industries/automotive" target="_blank">Find out more</a> about how we’re helping to drive change across the automotive industry. <br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:6:{i:0;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:2:"AI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:13:"Visualization";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:14:"Heiko Wenczel ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 11 Dec 2019 16:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 11 Dec 2019 16:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:111:"https://www.unrealengine.com/spotlights/unreal-engine-the-open-automotive-platform-and-data-model-of-the-future";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:111:"https://www.unrealengine.com/spotlights/unreal-engine-the-open-automotive-platform-and-data-model-of-the-future";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:4;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:107:"MechWarrior 5 revamps the series with destructible environments, refined AI, and advanced procedural levels";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:273:"https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_THUMB_ALT-375x275-d40f5910ea122980aad1e94af4c8b0d542d8ee5a.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:144:"Developers of MechWarrior Online, Piranha Games explains what it’s been like switching to Unreal Engine to develop MechWarrior 5: Mercenaries.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:15906:"While Piranha Games is no stranger to the MechWarrior franchise, <a href="https://mw5mercs.com/" target="_blank">MechWarrior 5: Mercenaries</a> represents the Vancouver, Canada-based company’s first foray into a campaign-focused installment in the mainline series and is also the studio’s first Unreal Engine title. <br />
<br />
Speaking to how the roughly 50-person development team has transitioned to the engine, we interviewed company President Russ Bullock and Producer Alex Garden. With it being roughly 17 years since the last single-player MechWarrior game, the two talk about their goals for the long-awaited title and discuss what they learned developing MechWarrior Online that they’ve built off of for MechWarrior 5. <br />
<br />
The duo discuss how they built their component-based mech system, which allows them to create sophisticated and varying ‘Mech damage states. They also talk about how they created the game’s distinct particle effects, which not only look great, but allow players to identify what kind of firepower they’re going up against. In addition, the developers explain how they constructed destructible environments and talk about how they balanced procedural generation with thoughtful level design. 
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/E5FWZYuyeDY" width="100%"></iframe></div>
<strong>Considering this will be the first MechWarrior game since 2002 to feature a single-player campaign, what were some of Piranha Games’ goals for the project?<br />
<br />
President Russ Bullock:</strong> Our driving motivation was to give long-time MechWarrior fans the features they always dreamed about when those classic games were released. Back then, there were a lot more limitations on technology, and the notion of playing a MechWarrior game and traveling absolutely anywhere you wanted and freely managing your mercenary unit was a dream, along with the ability to truly destroy the entire environment while fighting in an urban setting. This is what we set out to deliver to MechWarrior fans—a classic feel with the delivery of dream features using modern technology.<br />
<br />
<strong>Were there any past ‘Mech games that had a particularly big influence on MechWarrior 5?<br />
<br />
Bullock:</strong> Both of the Mercenaries renditions, but also, in particular, the original MechWarrior from 1989, because it was the only one that had really let you select a location in the Inner Sphere and fly there to take on contracts from any of the Great Houses. In some ways, MechWarrior 5: Mercenaries is a successor to that great game.<br />
<img alt="DeveloperInterview_-Mechwarrior_5_002.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_002-1920x1200-c493a8bb6cc0d98f7d3e1d1b83d89a68bb1e0899.jpg" width="auto" /><br />
<strong>What have you learned from developing MechWarrior Online that you’re building off of for MechWarrior 5?<br />
<br />
Producer Alex Garden: </strong>First and foremost, all the technical complexities and design demands involved with the ‘Mechs and the gameplay built around them. It’s rare for games to use component-based damage systems at the level you see in MechWarrior 5: Mercenaries, and even in MechWarrior Online. Together with handling multiple independent weapons systems (all attached to different destructible components), the large scale of the ‘Mechs, and all the various attributes of the 50 plus chassis themselves—having already dealt with those elements in MechWarrior Online was a major benefit.<br />
<br />
One of the more visible improvements is in the per-chassis damage models featured in MechWarrior 5: Mercenaries, with each component on each of the 50 plus chassis now having multiple, uniquely modeled damage states. The consequences of a battle on the state of your ‘Mechs will be on display at a fidelity never before seen in a MechWarrior title, and rarely seen in games as a whole.<br />
<br />
<strong>Was it challenging supporting a four-player co-op campaign from either a design or technical perspective?<br />
<br />
Garden: </strong>Our experience with developing network systems and PvP ‘Mech combat for MechWarrior Online helped lay the groundwork for how we handled four-player co-op play for MechWarrior 5: Mercenaries from a technical perspective. Design-wise, once we opted for an approach that allows up to three other players to join a host’s campaign and play cooperatively as if they were pilots-for-hire, a lot of the elements fell into place.<br />
<br />
Alternatively, a group of four friends can go straight into co-op action outside the campaign by using the Instant Action system, which allows you to play generated missions at any level of difficulty using any of the hundreds of available ‘Mech variants, along with access to the ‘Mech loadout and appearance customization features.<br />
<img alt="DeveloperInterview_-Mechwarrior_5_007.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_007-1920x1200-b6095d01178be52991f1b0e0eb02a4cdf0fcb71f.jpg" width="auto" /><br />
<strong>MechWarrior 5 features great use of particle effects that include fire, laser, and smoke. Can you explain how you incorporated these visual elements into the game?<br />
<br />
Garden: </strong>With the large number of weapon types in MechWarrior 5: Mercenaries, it was important for us to provide a visual identity for each when seeing them on the battlefield, so that generally, most every weapon can be identified based on its projectile or effect. The battlefield comes alive when all of these elements are in play together, pushing that feeling of being in a warzone where every stray projectile, laser, or explosion might destroy a building, blow the arm off a ‘Mech, scorch the terrain, or set a tree on fire.<br />
<img alt="DeveloperInterview_-Mechwarrior_5_005.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_005-1920x1200-0f489173ad5443e8641a989b023fdf9fc9ba7401.jpg" width="auto" /><br />
<strong>For the first time in the series’ history, MechWarrior 5 will feature destructible environments. How did the studio incorporate this aspect into the game? <br />
<br />
Garden: </strong>There’s no quicker way to fulfilling the power fantasy of piloting a BattleMech than smashing through a building and reducing it to rubble to get at the enemy on the other side. Why go around it, when I can just go through it?<br />
<br />
As a core pillar of MechWarrior 5: Mercenaries, our approach to destructibility had a significant influence on how we designed our missions and handled combat encounters. On the technical side, we took a modular approach when building the systems, with the various building types that populate our mission spaces being comprised of individually destructible elements that we can swap out and utilize in different ways.<br />
<br />
We’re quite proud of what we’ve put together when it comes to destruction. There have been a few occasions just in the last year where, as I was playing them, I’d wished some games had what MechWarrior 5: Mercenaries offers.<br />
<br />
<strong>Considering the game allows players to target and destroy specific enemy weapons coupled with the fact that there are multiple stages of damage reflected on armor components, can you elaborate on how the studio handled damage modeling?<br />
<br />
Garden: </strong>Our artists have years of experience modeling, texturing, and animating ‘Mechs for MechWarrior Online, and thanks to the existing stable of art we’ve built up over that time, we were able to focus our resources on further refining the art and going the extra step with the per-chassis damage models. The pipeline here was much the same, with individual artists dedicated to modeling out the new damage states for a collection of ‘Mechs.<br />
<br />
From the player’s perspective, the result of all this is greater visual polish and feedback in the midst of combat and in the consequences of your engagements. Approaching an enemy ‘Mech, identifying that its most powerful weapon is attached to a specific component such as its right arm, focusing your fire on that arm, then seeing it visibly and naturally become damaged before finally getting blown off in a big explosion is really compelling. Making it to the end of a mission with your ‘Mech smoking, scorched, and barely holding together is really satisfying and stresses the feeling that you just survived some major [action].<br />
<img alt="DeveloperInterview_-Mechwarrior_5_015.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_015-1920x1200-763abf02561921ab45141fc57f0b7f8c1868ec88.jpg" width="auto" /><br />
<strong>With over 50 distinct ‘Mech chassis and hundreds of sub-variants, how did the studio approach designing and balancing all the ‘Mechs in the game?<br />
<br />
Bullock:</strong> Fortunately, we just spent nine years developing MechWarrior Online, which being a PVP game meant every ‘Mech was deeply scrutinized on balance. Although we have much more freedom with a single-player PvE game than MechWarrior Online, it still gave us a basis to start with.<br />
<br />
<strong>How did you leverage procedural generation to develop the level structure and various environmental biomes within the game?<br />
<br />
Garden:</strong> We knew early on that if we were going to provide the player with the entire Inner Sphere as their playground – an area comprised of hundreds of star systems each with multiple planets and biomes – we were going to need the ability to leverage a wide degree of variation, without vastly inflating the time it would take for us to accomplish it if we were to use traditional level design methods.<br />
<br />
With that in mind, and rather than using a purely procedural system for generating levels, we opted for a middle-ground system that would build levels using a large pool of hand-crafted terrain tiles. This approach gave our artists and level designers the ability to hit visual quality with real-looking terrain formations, and our design team the ability to generate a large number of environments and encounter areas that would play and feel different to the player.<br />
<img alt="DeveloperInterview_-Mechwarrior_5_003.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_003-1920x1200-fe9d5fe10ad05cf66026865c822687cab5f25d71.jpg" width="auto" /><br />
<strong>Can you elaborate on how you developed the <a href="https://docs.unrealengine.com/en-US/Gameplay/AI/index.html" target="_blank">AI</a> in the game? Was it a challenge getting the AI to navigate across your procedurally-generated maps?<br />
<br />
Garden: </strong>AI was approached from the perspective of the MechWarrior (the pilot) and their BattleMech. In the BattleTech universe, chassis are typically designed for specific purposes, whether as frontline assault ‘Mechs or nimble, lightly-armored scouts. ‘Mech designs have their strengths and weaknesses, which inform how a pilot would approach an engagement. Can they tank a lot of damage or should they constantly be on the move, avoiding fire as much as possible? Should they bridge the gap for short-range engagement, or stay at a distance and whittle the enemy down with long-range weaponry? How well does the pilot coordinate their attacks with their allies, and with which weapon platforms are they most experienced? All these considerations contribute to making the battlefield feel alive with thinking entities making the best choices according to their roles and capabilities.<br />
<br />
<strong>MechWarrior 5 will not only be the first Unreal Engine-powered game in the series, but the first title from Piranha Games to use UE4. Can you explain why Unreal Engine was a good fit for the game?<br />
<br />
Garden:</strong> At the start of the project, there was little question we’d be using UE4. Adopting a new engine always has its hurdles, but the transition was very easy. UE4 was ideal for what we wanted MechWarrior 5: Mercenaries to be, and the project only became stronger as additional updates to the engine were released. <br />
<img alt="DeveloperInterview_-Mechwarrior_5_008.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fmechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels%2FDeveloperInterview_-Mechwarrior_5_008-1920x1200-f033b00a22dec5ada16c40c4619cf1142e15c446.jpg" width="auto" /><br />
<strong>Does the team have any favorite UE4 tools or features?<br />
<br />
Garden: </strong>The Live Coding feature introduced in <a href="https://www.unrealengine.com/en-US/blog/unreal-engine-4-22-released" target="_blank">4.22</a> has been a useful tool for our engineers to quickly test isolated changes, and the Widget Reflector tool was very useful as we started to build some of our in-engine development tools that leveraged <a href="https://docs.unrealengine.com/en-US/Programming/Slate/Overview/index.html" target="_blank">Slate</a>. On the art side, <a href="https://docs.unrealengine.com/en-US/Engine/Editor/ScriptingAndAutomation/Python/index.html" target="_blank">Python support</a> was vital to our ‘Mech pipeline and optimization work, allowing us to automate and rapidly handle batch processing for tens of thousands of files.<br />
<br />
<strong>Do you have any development tips you can share with our UE4 community?<br />
<br />
Garden:</strong> Be vigilant when it comes to monitoring performance over time; the <a href="https://docs.unrealengine.com/en-US/Engine/Performance/Profiler/index.html" target="_blank">profiling tools</a> in Unreal Engine are your best friends. If you want to build something with multiplayer support, treat that decision as the highly-consequential decision that it is. It can be easy to lose focus on these two things if you’re in a state of rapid development, but losing that focus will make your life harder and the game less likely to achieve the goals you had in mind.<br />
<br />
Also, try not to reinvent the wheel. Over-engineering or over-designing a system that should be straightforward is unfortunate if you do it once, but potentially crippling if you make it a habit.<br />
<br />
<strong>Thanks for your time. Where can people learn more about MechWarrior 5: Mercenaries?<br />
<br />
Bullock: </strong>MechWarrior 5: Mercenaries is available on the <a href="https://www.epicgames.com/store/en-US/product/mechwarrior-5/home" target="_blank">Epic Games Store</a>. You can also check out the game at <a href="http://www.mw5mercs.com" target="_blank">www.mw5mercs.com</a>, along with on our various social channels including <a href="https://www.facebook.com/mw5mercs/" target="_blank">Facebook</a>, <a href="https://twitter.com/MW5Mercs" target="_blank">Twitter</a>, and <a href="https://www.youtube.com/channel/UCZFLqlJzvAMiEJjMGI-yWTA" target="_blank">YouTube</a>. <br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:6:{i:0;a:5:{s:4:"data";s:2:"AI";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:3:"Art";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:26:"MechWarrior 5: Mercenaries";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:13:"Piranha Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:11:"Jimmy Thang";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 10 Dec 2019 16:20:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 10 Dec 2019 16:20:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:155:"https://www.unrealengine.com/developer-interviews/mechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:155:"https://www.unrealengine.com/developer-interviews/mechwarrior-5-revamps-the-series-with-destructible-environments-refined-ai-and-advanced-procedural-levels";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:5;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:82:"Apollo 11 Mission AR Project Sample available now on the Unreal Engine Marketplace";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:210:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fapollo-11-mission-ar-project-sample-available-now-on-the-unreal-engine-marketplace%2FNews_Apollo11_THUMB-375x281-b234ae46ca6065f6683547d1117745caa42b7255.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:350:"Built for HoloLens 2, Apollo 11 Mission AR is an interactive experience that brings high-end PC visuals to mixed reality. Now released on the Unreal Engine Marketplace, users are able to witness a bird’s-eye view of many aspects of the historic Apollo 11 mission, and are able to gain insight into how Unreal can be used to create similar projects.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:2571:"Our recent demo built for the Microsoft HoloLens 2, “<a href="https://youtu.be/zfcnIrRlGy8" target="_blank">Apollo 11 Mission AR</a>” offers a bird’s-eye view of many aspects of the historic Apollo 11 mission, including the launch itself, an accurate model of the Saturn V, a detailed reenactment of the lunar landing, and a look at Neil Armstrong’s monumental first steps on the moon—all reconstructed based on data and footage from the actual mission.<br />
<br />
Today we’re excited to be releasing Apollo 11 Mission AR as a project sample on the <a href="https://www.unrealengine.com/marketplace/en-US/slug/missionar" target="_blank">Unreal Engine Marketplace</a>, so that anyone can see how our special projects team built the interactive experience from the ground up using the latest Unreal Engine features, and gain insight into how Unreal can be used to create similar projects; whether you’re an architect needing to visualize a building in the field, a designer building a next-gen car, an engineer producing real-world safety simulations, or more.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/C7QbR2d8RNI" width="100%"></iframe></div>
Using Holographic Remoting to bring high-end PC graphics to mixed reality, Unreal Engine enables the HoloLens 2 to display holograms of immense detail, far exceeding what is possible with edge compute and rendering alone. Apollo 11 Mission AR features platform-leading visuals, including 7 million polygons in a physically-based rendering environment with fully dynamic lighting and shadows, multi-layered materials, and volumetric effects–all streamed wirelessly in real-time from networked PCs running Unreal.<br />
<br />
Exploring and modifying this sample will help you learn how to:<br />
 
<ul style="margin-left: 40px;">
	<li>Create immersive narrative sequences and triggered events </li>
	<li>Implement touch-based input and interactivity </li>
	<li>Utilize Holographic Remoting to display content streamed from PC over Wi-Fi</li>
</ul>
<br />
Unreal Engine features production-ready support for HoloLens 2 for all developers, with tools such as streaming and native deployment, emulator support, finger tracking, gesture recognition, meshing, voice input, spatial anchor pinning, and more.<br />
<br />
Many thanks to our collaborators on this project, including ILM Chief Creative Officer John Knoll, space historian Andrew Chaikin, and our partners at Microsoft.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:6:{i:0;a:5:{s:4:"data";s:9:"Aerospace";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:2:"AR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:8:"HoloLens";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:11:"MicrosoftMR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:13:"Visualization";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:12:"Brian Sharon";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 09 Dec 2019 18:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 09 Dec 2019 18:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:116:"https://www.unrealengine.com/blog/apollo-11-mission-ar-project-sample-available-now-on-the-unreal-engine-marketplace";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:116:"https://www.unrealengine.com/blog/apollo-11-mission-ar-project-sample-available-now-on-the-unreal-engine-marketplace";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:6;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:69:"Cyclone Graphics turns comics into animation with real-time rendering";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:215:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_thumb-375x275-4cdbd7eca2a44b2fc3b48ae6758d6badecbeb8c4.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:292:"To create an animated version of the popular “No Guns Life” comic under a tight schedule, Japanese studio Cyclone Graphics tapped into Unreal Engine to render the backgrounds in real time. In the process, they not only met the deadline but discovered a real-time pipeline for future work.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:9034:"<em>No Guns Life</em> is a popular Japanese comic by Tasuku Karasuma about a cybernetic postwar world. The hero of the story, Juzo, went through an intense transformation during the war—his entire head was turned into a large gun, leaving him with no memory of his previous life. <br />
<br />
Juzo teams up with Mary, a sympathetic teenager, and takes on the role of both detective and vigilante. Together they fight against various enemies including the evil megacorporation behind his forced transformation. <br />
<br />
<em>No Guns Life</em> is full of rich visuals, social commentary, and plenty of dry humor. Recently, Tokyo-based <a href="http://www.cyclone-graphics.com/" target="_blank">Cyclone Graphics</a> was asked to turn the manga into an animated series, which is currently showing on broadcast networks in both Japan and the USA. <br />
<img alt="Spotlight_NoGunsLife_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img4-1640x1000-4b41c7552a0d7e0d501a928b608f632f1d5107c1.jpg" width="auto" /><br />
With just a few months to produce the series, the team decided to create the backgrounds with Unreal Engine. This enabled them to stay true to the detailed cyberpunk world of the comic while saving time in production. <br />
<img alt="Spotlight_NoGunsLife_blog_body_img12.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img12-1640x1000-e6d9b4ed3611284b3a7489794327e7f2c11bae4f.jpg" width="auto" /><br />
We caught up with Michiya Kato, Visual Effects Supervisor at Cyclone Graphics, to ask about this intriguing use of UE4.
<h3><strong>Tell us about turning “No Guns Life” into an anime.</strong></h3>
We were given this project by <a href="http://www.madhouse.co.jp/" target="_blank">Madhouse, Inc.</a> They’ve been around for nearly 50 years, and science fiction and hard-boiled detective stories are what they do best. <em>No Guns Life</em> has such a cool design and is so interesting that we thought it would make a great animated series.<br />
<br />
Madhouse asked me how I would make this anime. I noticed that the comics’ cyberpunk world view makes these comics really game-like, and I also saw that there were only a few kinds of objects in scenes throughout the story. Since we had very little time for pre-production and production, I considered that it would take detailed backgrounds to make it work. <br />
<br />
For this anime, we fused hand-drawn anime characters with CG backgrounds rendered out of Unreal Engine. Of course, we could have created everything in CG if we wanted to, but we aimed to keep the hand-drawn anime style unique to Japan.<br />
<img alt="Spotlight_NoGunsLife_blog_body_img13.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img13-1640x1000-833aa0d9b57149713c2a8e526f0663ec301ab314.jpg" width="auto" />
<h3><strong>Why did you choose Unreal Engine for the backgrounds?</strong></h3>
For backgrounds made with precise modeling, rendering time was going to be the bottleneck. So we decided to use Unreal Engine for its high-quality rendering and quick turnaround.<br />
<br />
Unreal Engine has a useful collection of functionalities. It’s easy to use, and it’s easy to set up CG elements. UE4 gave us flexibility in the production process. <br />
<br />
Our purpose was to express the sophisticated world view of the original comics in a short period of time. So Unreal Engine, which allowed for flexible customization and a high quality of expression, was the ideal tool. We also love that it’s so intuitive, we could all learn it quickly.<br />
<img alt="Spotlight_NoGunsLife_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img2-1640x1000-74ce807af82516066f85c71b4b9467c153d66887.jpg" width="auto" />
<h3><strong>Tell us about the process of producing anime backgrounds with Unreal Engine.</strong></h3>
In the comics, the world view had already been expressed in great detail, so we used the comics themselves as storyboards to save time. This also meant we could immediately list the objects that we needed to model while still at the script stage. <br />
<br />
As there was limited time for production, we started on the modeling tasks and scene setups with Unreal Engine right away, while our storyboarding staff worked out the production plan according to the modeling specifications. <br />
<img alt="Spotlight_NoGunsLife_blog_body_img10B.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img10B-1640x1500-213be9f24be27e018f51d38763615e20be78d65e.jpg" width="auto" /><br />
During the first stage of all our projects, we render original materials and do the color grading on composite software as image boards to show to the production staff. We had already finished the design of buildings and props based on the original comics before the image board stage, so all that was needed was to tweak the lighting and grading.<br />
<br />
Once we had scenes finalized and fixed, we set up dummy characters and a camera in Unreal Engine, and made cuts according to the storyboards. The production staff and the CG designers worked out the layouts and camera angles together. We found that with Unreal Engine, a single CG designer can set up the layouts and backgrounds for 300 cuts in a day.<br />
<img alt="Spotlight_NoGunsLife_blog_body_img6.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img6-1640x933-6b0b7084aac4f093e6a108c339c7bf74e28b9aa6.jpg" width="auto" /><br />
With all the camera angles set, we were ready for the animators to start drawing. In our pipeline, the animators draw on celluloid sheets laid over background images. The full intricacy of the <em>No Guns Life</em> backgrounds would have been too much for the animators to draw over, so instead we used shaders in Blueprints to output the backgrounds as line drawings just for them. To render the cuts, we developed an Excel-based batch rendering program. <br />
<img alt="Spotlight_NoGunsLife_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img7-1640x929-53fe3ebd5b76211f5224753d98327e7fc635db90.jpg" width="auto" /><br />
Once the hand drawings were done, we needed to composite the celluloid sheets over the CG backgrounds, which we did using compositing software. To adjust the feel and appearance of the CG backgrounds, we could output fog, occlusion, and color masks all at once from Unreal Engine, and adjust each of these elements in real time.<br />
<img alt="Spotlight_NoGunsLife_blog_body_img9.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcyclone-graphics-turns-comics-into-animation-with-real-time-rendering%2FSpotlight_NoGunsLife_blog_body_img9-1640x934-8373c32435db4c99cde332fd4c1c76e9b7ed3647.jpg" width="auto" /><br />
Just as with the traditional animation workflow with 2D backgrounds, animators can start to draw right after the layouts are determined. So this new workflow has made it possible for us to maintain the same quality level, where details are fully expressed, while saving an astonishing amount of time during production.<br />
<br />
For us, the main advantages of the Unreal Engine pipeline are streamlined organization and extremely high-quality graphics. Our CG designers created fully detailed backgrounds for 4,000 finished cuts in less than six months, which is really amazing.
<h3><strong>How do you see Unreal Engine affecting future projects?</strong></h3>
We feel like we haven’t yet learned all the ways we can use Unreal Engine. For future projects, we challenge ourselves to use even more real-time techniques. <br />
<br />
Years ago, animes had impacts on games. Now, technologies that sprung from game development, such as Unreal Engine, are influencing animes. As we watch the unique Japanese anime/game culture mature, it&#39;ll be exciting to witness the new fusions of expression that come from combining the best of both worlds.<br />
<br />
<br />
Want to speed up your production process with innovative real-time techniques? Download <a href="https://www.unrealengine.com/en-US/" target="_blank">Unreal Engine</a> and start exploring the possibilities.<br />
<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:5:{i:0;a:5:{s:4:"data";s:17:"Film & Television";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:3:"Art";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:12:"No Guns Life";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:16:"Cyclone Graphics";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 06 Dec 2019 20:00:46 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Fri, 06 Dec 2019 20:00:46 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:109:"https://www.unrealengine.com/spotlights/cyclone-graphics-turns-comics-into-animation-with-real-time-rendering";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:109:"https://www.unrealengine.com/spotlights/cyclone-graphics-turns-comics-into-animation-with-real-time-rendering";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:7;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:83:"Unreal Fest Europe just got even bigger—now taking non-games speaker submissions!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:228:"https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Funreal-fest-europe-just-got-even-bigger-now-taking-non-games-speaker-submissions%2FEvents_UnrealFestEurope2020_Thumbnail-375x275-25322b040c13467fd7069d6946ba9e3ec77db301.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:261:"In 2020, Unreal Fest Europe and Unreal Academy London will be rolled into one. Bringing together professionals from a whole range of industries to learn, get inspired, and network, we’re now looking for both games and non-games industry speakers. Apply today.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:2377:"We’ve got some big news! For 2020, Unreal Fest Europe and Unreal Academy London will now be rolled into one huge, action-packed event.<br />
<br />
Taking place in Prague from April 29 to May 1, 2020, Unreal Fest Europe will see professionals from games and non-games industries come together for three days of keynote presentations, hands-on sessions, and expert lectures. Whether you’re an experienced pro or just getting started with real-time workflows, Unreal Fest will have something for Unreal Engine creators of all levels and verticals.<br />
<br />
Game developers, architects, engineers, designers, producers, cinematographers, and artists are all invited to attend, providing a unique opportunity for cross-industry networking. That means that in addition to looking for <a href="https://www.unrealengine.com/en-US/events/unreal-fest-europe-2020-announced-speaker-submissions-now-open" target="_blank">speakers from the games industry</a>, we’re now also inviting non-games industry professionals to deliver presentations at Unreal Fest Europe. <br />
<br />
If you’d like to showcase innovative work you’ve created using Unreal Engine’s real-time technology in the architectural visualization, automotive and transportation, film and television, or other non-games fields, we’d like to hear from you! We’ve extended the deadline for session proposals until January 6, 2020 so there’s still plenty of time to get your submissions in.<br />
<br />
We’re particularly interested in sessions that cover:<br />
 
<ul style="margin-left: 40px;">
	<li>Compelling projects created in Unreal Engine</li>
	<li>Inspirational and thought-provoking content </li>
	<li>Case studies that demonstrate the ROI benefits of using Unreal Engine</li>
	<li>Innovative and imaginative uses of Unreal Engine </li>
</ul>
<br />
If you’re ready to step into the spotlight and join our lineup, fill out our <a href="https://www.cvent.com/c/abstracts/48b88156-ac0f-4987-ab17-bf3009bd66c5" target="_blank">Call for Proposals submission form</a>.<br />
<br />
Need more information on what’s required to submit a session proposal? Take a look at our <a href="https://cdn2.unrealengine.com/Unreal+Engine%2FblogAssets%2FUnreal-Fest-Europe---Call-for-Proposals-Final-68a32386e30a3ab8a43ce530c2de891288266cf3.pdf" target="_blank">Call for Proposals Guide</a>. <br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:9:{i:0;a:5:{s:4:"data";s:12:"Architecture";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:23:"Broadcast & Live Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:17:"Film & Television";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:21:"Unreal Academy London";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:8;a:5:{s:4:"data";s:18:"Unreal Fest Europe";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:15:"Shera D’Spain";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Thu, 05 Dec 2019 17:45:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Thu, 05 Dec 2019 17:45:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:116:"https://www.unrealengine.com/events/unreal-fest-europe-just-got-even-bigger-now-taking-non-games-speaker-submissions";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:116:"https://www.unrealengine.com/events/unreal-fest-europe-just-got-even-bigger-now-taking-non-games-speaker-submissions";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:8;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:67:"Build: Munich ’19 for Automotive: real-time workflows come of age";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:202:"https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_thumb-375x275-8c9ef4d234b84fa04c55cb6daeecb1f17dcd60a7.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:212:"Interactive tools for design and engineering, pixel streaming, and immersive UE4-powered VR dealership experiences were just some of the hot topics discussed at this year’s Build: Munich for Automotive event. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:13565:"On October 15, 2019, over 600 professionals from across the automotive industry descended on Paulaner Nockherberg, one of Munich’s oldest beer halls, for the third Build event to be held in the city. <br />
<br />
An impressive lineup of speakers from companies including Audi, Daimler, Mercedes, BMW, and McLaren took to the stage to give insights into the ways they’re harnessing real-time technology for everything from improved design collaboration to cost-effective marketing.<br />
<br />
The event showcased how interactive workflows have come of age across the automotive industry, with many presentations centered around real-time projects that have moved out of the development phase and into day-to-day use across automotive businesses.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/MVTvH9JtKQc" width="100%"></iframe></div>
The sheer speed at which real-time workflows are developing across the automotive industry had attendees talking. “I&#39;ve seen so much,” said Seamus Walsh, Global Account Manager at <a href="https://www.lg.com/global" target="_blank">LG Electronics</a>. “The pace of the development is really astounding. It just starts so many new conversations.”<br />
<br />
In tandem with innovative new use cases, the projects on display illustrated how rapidly the quality of real-time tools and workflows is advancing. “This is the third year in a row that we&#39;ve been here, and the bar is just getting higher and higher every year,” said Staffan Hagberg, CMO at <a href="https://animech.com/" target="_blank">Animech</a>.

<h3><br />
<strong>McLaren embraces real-time design and marketing pipelines</strong></h3>
A case in point is the presentation by <a href="https://www.mclaren.com/" target="_blank">McLaren</a>, which began by tracing the evolution of the company’s configurators. From a game-changing proof-of-concept <a href="http://configurator.mclaren.com/model/coupe570s" target="_blank">570S configurator</a> that was built in collaboration with Epic Games in 2016, McLaren is now leveraging real-time technology to improve ROI across its marketing funnel with the new <a href="http://configurator.mclaren.com/model/gt?_ga=2.258432716.73906350.1575281657-1227341994.1575281657" target="_blank">GT configurator</a>. <br />
<img alt="Events_BuildMunich_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img1-1640x1000-e36ad5e198af2e7259594333610775c30ecf8869.jpg" width="auto" /><br />
Whereas previously the company had two separate workflows for its 3D dealership and 2D online configurators, the GT configurator renders out of Unreal Engine with one workstream pipeline for everything. “It takes down costs, it takes down time, and it gives us more creative control,” said John Bulmer, Visualization Lead at McLaren. “This is how we&#39;re going to do our configurators from now on.”<br />
<br />
McLaren also gave an insight into how it’s using real-time workflows in the design process. As well as harnessing the power of tools like <a href="https://www.youtube.com/watch?v=mWaQfjEJIMQ&amp;feature=youtu.be" target="_blank">Vector Suite</a>, it has built a number of its own custom tools that empower designers and engineers to review designs in real time, enabling them to measure sections, add notes, or create an exploded view of car designs in an interactive environment. With the option to perform reviews in VR proving popular, the team has plans to explore further avenues for immersive review including mixed reality with Magic Leap. <br />
<br />
Other real-time applications the business has developed include interactive previz sessions to plan shots before a physical photoshoot of a new car takes place, and photoreal teaser renders to generate demand before a car is built. <br />
<br />
It’s just the start of a real-time transformation across the company, according to Mark Roberts, Head of Design Operations at McLaren. “We&#39;re going to start spreading out throughout the design and engineering side of the business with these Unreal tools,” he said.
<h3><br />
<strong>Audi looks to the future with Pixel Streaming </strong></h3>
Audi gave a fascinating look at how real-time workflows are at the heart of its vision for the future, thanks to the technology’s ability to create more marketing content for more channels. “The future is going to be different than today,” said Thomas Zuchtriegel, Head of AR/VR data, process and technology at Audi Business Innovation GmbH. “You&#39;re going to have AI-driven recommendations. You want to show personalized, location-based, and device-specific content, and the major factor for this is time to market.” <br />
<img alt="Events_BuildMunich_blog_body_img12.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img12-1640x1000-44a2b0f17cbecb056bf333e09f329d13ec8fd254.jpg" width="auto" /><br />
Zuchtriegel spoke about two innovations that play into this vision; cloud streaming and a new install updates system. Unreal Engine’s <a href="https://docs.unrealengine.com/en-US/Platforms/PixelStreaming/index.html" target="_blank">Pixel Streaming</a> is enabling <a href="https://www.audi.com/en.html" target="_blank">Audi</a> salespeople on the road to show customers the same high-fidelity visualizations on an iPad that they would normally have to be on a high-end PC to see. Connecting via a web browser to a packaged Unreal Engine application running on a server in the cloud, there&#39;s no need for users to install or download anything, and they can interact with the application using keyboard, mouse, and touch input. “Pixel Streaming has been a very smooth experience for us since we got it,” said Zuchtriegel. “It is more or less plug-and-play.” <br />
<br />
Audi has also discovered a fast and agile way to propagate updates across its fleet of CG vehicles showcased across dealerships. Leveraging the <a href="https://docs.unrealengine.com/en-US/Engine/Deployment/Patching/index.html" target="_blank">Build Patch Services system</a> that comes with Unreal Engine, Audi can patch fixes to individual materials without having to download the whole car, reducing demand on the often low bandwidth that dealerships have to work with. “It&#39;s super efficient and flexible. If you make only small changes, it&#39;s only delta update size,” said Zuchtriegel. “We&#39;re very happy with Build Patch Services. It&#39;s a great tool.”<br />
 
<h3><strong>BMW showcases a new interactive dealership experience </strong></h3>
BMW used its time on stage to showcase Eve, an Unreal-powered dealership experience for both VR and large screen that has been pushed out to thousands of dealers.<br />
<img alt="Events_BuildMunich_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img4-1640x1000-c3dfb3dc8dfa2c5f01ff304e675f7b0fff4c4d7f.jpg" width="auto" /><br />
Since 2012, <a href="https://www.bmw.com/en/index.html" target="_blank">BMW</a> has had an army of high-performance rendering machines across its dealerships that are either being under used, not used at all, or connected to a dated front-end system. Project Eve saw the company leverage the existing hardware it had in combination with the latest cutting-edge real-time software to provide a new solution of mind-blowing visual quality. <br />
<img alt="Events_BuildMunich_blog_body_img5.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img5-1640x1000-b769a9b485dc8262d9acabb070b748e635a86ef7.jpg" width="auto" /><br />
Built on Unreal Engine, Eve enables the user to swap different models of BMW instantly, interact with the car by performing actions such as opening the door or popping the trunk, change the environment, and do all this on any device, whether it’s a customer’s Android phone or iPad, or a sales advisor’s laptop.<br />
 
<h3><strong>Real-time workflows transform Daimler’s engineering review process</strong></h3>
<a href="https://www.daimler-protics.com/" target="_blank">Daimler Protics</a> showcased its multiplayer real-time platform for engineers that enables them to perform design reviews at full scale in a fully immersive environment. J&uuml;rgen Riegel, Project Lead and Principal Software Architect explained how the team collaborated with NetAllied Systems to <a href="https://uberengine.com/#" target="_blank">develop a plugin</a> to integrate technical 3D CAD renderer UberEngine into Unreal Engine.<br />
<img alt="Events_BuildMunich_blog_body_img13B.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img13B-1640x1000-6663896677ee5441659376ea60afc182cba0f2db.jpg" width="auto" /><br />
The manufacturer’s new solution, <a href="https://www.daimler-protics.com/landing-pages/index-2.html" target="_blank">Engineering Hub</a>, provides a way to load 3D CAD data directly from the PDM system at runtime and simultaneously leverage all the real-time, interactive functionality of a game engine. <br />
<br />
Design and engineering teams located in different parts of the world can now collaborate far more effectively than the traditional method of Skype or phone. They can inspect designs, make notes, adjust sizes and colors, reposition elements, and save files back to the PDM system for later use in the development process—all in a shared multi-user immersive environment that&#39;s accessible from anywhere.<br />
 
<h3><strong>Experiencing VR as car passenger with Mercedes </strong></h3>
<a href="https://www.mercedes-benz.com/en/" target="_blank">Mercedes</a> showcased an experimental project called “Lucid Dream.” The aim of the project is to marry the sensation of being in a moving vehicle with engaging visuals provided via a VR headset. <br />
<img alt="Events_BuildMunich_blog_body_img9.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img9-1640x1000-2f6bdf5748bf71a02a869aea7cc0b02e0a51bf0c.jpg" width="auto" /><br />
The presentation explained that the team had to overcome a number of challenges during the development of the prototype, including how to combat motion sickness and how to precisely match the visuals with the movement of the user’s head.<br />
<img alt="Events_BuildMunich_blog_body_img10.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img10-1640x1000-0b426d6a39f535cfedaa1e7ee388a52a58098d59.jpg" width="auto" /><br />
Developed with an eye on the coming era of ever-more comfortable (and potentially autonomous) cars, Lucid Dream is an example of how real-time technology could one day be harnessed beyond design, engineering, and marketing to enhance the experience of travelling in the car itself. <br />
 
<h3><strong>The open automotive platform and data mode of the future</strong></h3>
A recurring theme that ran throughout every presentation at Build: Munich ‘19 for Automotive was the enthusiasm for creative innovation at automotive companies. <br />
<br />
With key automotive players capitalizing on the open nature of UE4 to create cost-effective, innovative new tools, it’s clear that fast, creativity-fostering real-time workflows are going to continue to offer a world of possibilities for the industry. <br />
<img alt="Events_BuildMunich_blog_body_img15.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fbuild-munich-19-for-automotive-real-time-workflows-come-of-age%2FEvents_BuildMunich_blog_body_img15-1640x1000-c9da6d057d46a746f74a40c5fc80574266f14fb8.jpg" width="auto" /><br />
We believe the future lies in a consolidated, open automotive platform and data model that supercharges the production pipeline. At this year’s Build: Munich event, we caught a glimpse of this future beginning to emerge. “What I&#39;ve seen from a lot of companies is that they’ve built their whole pipeline<span style="font-size:11pt;font-family:Arial;white-space:pre;">—</span>engineering, design, marketing, on Unreal,” said Marc Eckel, Head of VR Exterior, Cubing at BMW Group. “It&#39;s not a multiplatform system anymore—it&#39;s just Unreal. And this, by the way, is where we’re also heading.”<br />
<br />
<br />
Want to start experimenting with real-time workflows in your own pipeline? <a href="https://www.unrealengine.com/en-US/" target="_blank">Download Unreal Engine</a> today for free. Interested in learning more about Unreal Engine training? <a href="https://www.unrealengine.com/en-US/classroom-training" target="_blank">Visit one of our training centers</a>, and <a href="https://ue.unrealengine.com/training-newsletter-sign-up.html" target="_blank">sign up</a> for our Unreal Engine training newsletter for the latest news and updates.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:5:{i:0;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:13:"Build: Munich";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:13:"Visualization";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:10:"Doug Wolff";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 04 Dec 2019 19:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 04 Dec 2019 19:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:98:"https://www.unrealengine.com/events/build-munich-19-for-automotive-real-time-workflows-come-of-age";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:98:"https://www.unrealengine.com/events/build-munich-19-for-automotive-real-time-workflows-come-of-age";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:9;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:91:"The Path of Calydra combines adventure and childlike whimsy to create a fantastical journey";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:261:"https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-and-childlike-whimsy-to-create-a-fantastical-journey%2FDeveloper-Interview_Path_of_Calydra_THUMB_ALT-375x275-f84211b69b7b047eec0fa52f2e0da2ec7a8f19b6.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:205:"Brazilian developer FinalBoss started working on The Path of Calydra half a decade go, and the creative process has taken them on a path that’s every bit as epic as the game’s otherworldly adventure. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:16730:"If you’re a longtime gamer, it can sometimes be easy to forget the sense of wonder you had when first discovering video games. Whether it was that first console for Christmas, or long Saturdays playing a co-op campaign with a best friend, there was a level of innocent excitement that came with exploring virtual worlds. As a lot of us get older and become more aware of the gaming industry and the developmental process, we risk losing this sense of wonder and bewilderment. However, that doesn’t mean we completely lack the ability to ignite that spark.<br />
 <br />
<em><a href="http://calydra.com/" target="_blank">The Path of Calydra</a></em>, an upcoming third-person adventure game from Brazilian developers <a href="http://finalboss.com/" target="_blank">FinalBoss</a>, looks to recapture this explorative spirit through its whimsical lands, quirky enemies, and sprawling lore. Matheus, the game’s protagonist, is just a simple boy from an idyllic suburban home who now finds himself lost in a foreign land, aided only by a mysterious creature named Calydra and its array of elemental powers.<br />
 <br />
FinalBoss were recipients of an Unreal Dev Grant in 2018, which allowed them to increase the size of their team and to put even more love and care into this adventurous title. Now, several years into its metamorphosis, <em>The Path of Calydra</em> is approaching its final incarnation. We chatted with Marcio Vivas, owner and founder of FinalBoss, about inspirations, exploration, and the Brazilian dev scene.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/FdbRsm6abeM" width="100%"></iframe></div>
<strong>How did being from Brazil influence the game and its world? Do you think that offered you a unique developmental perspective?</strong><br />
 <br />
<strong>Marcio Vivas: </strong>I cannot speak for everyone, but being Brazilian and having a childhood that was completely different from kids today left a huge emotional charge on me. I grew up playing with kites and marbles, spinning tops, and playing soccer. Back in the day, it was common, even as a toddler, to play outdoors with friends who lived on the same street or in the same condo building. This is still a reality in small towns, but everything is more limited in bigger urban centers due to factors like violence and lack of time, for example. Matheus, the game’s main character, represents this a bit: even while being addicted to games, he still shows some of these old-fashioned things in <em>The Path of Calydra.</em><br />
<br />
<strong>Having a child as a protagonist provides a sense of creativity and whimsy that wouldn’t exist otherwise. How does Matheus evolve and grow throughout the game?<br />
 </strong><br />
<strong>Vivas: </strong>Matheus is an ordinary kid who is being bullied at school. Although this is not the game’s main plot, it is important to note that this is something that pulls Matheus into his adventure with Calydra. He has no special abilities and does what a kid his age likes to do. He is smart, agile and very curious and, depending on the situation, these characteristics will help or undermine him. While it seems that he is the only human in [our fictional world] Calysgore, Matheus’ journey is assisted by a teenage girl named Joanna, whose diary pages are spread all over this ready-to-be-explored world. Joanna’s teenage perception of Calysgore mixes with Matheus’, and with all the dangerous situations he faces, Matheus soon realizes that he needs to grow up and stay strong to go back to his world. Facing giant monsters might be only another step in his growth.<br />
<img alt="Developer-Interview_ThePathofCalydra007.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-lore-and-childlike-whimsy-to-create-a-fantasy-journey-worth-taking%2FDeveloper-Interview_ThePathofCalydra007-1919x1079-9e97ae43a73e9f014f4c096e9b087198fab3ee53.jpg" width="auto" /><br />
<strong>When creating a fictitious world, the possibilities for lore-creation are almost endless. How deep do the stories behind Calysgore go, and how do you intend on revealing them to the player?</strong><br />
 <br />
<strong>Vivas: </strong>Behind <em>The Path of Calydra’s</em> visuals, we have a laid-out plot and detailed story that captivates the player in an interesting way. There are three stories: Matheus and Calydra’s as the main one that guides the player; Joanna’s diary entries; and the story of Alchemus, an ancient wizard from Calysgore, which will explain the creation of the universe and how it influences what we see in the present.<br />
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­<br />
These stories get intertwined throughout the adventure, which has dialogue between Calydra and Matheus written by award-winning writers Christopher Kastensmidt and Tiago Rech, who have made my original idea way more credible and fun.<br />
 <br />
Sometimes I think that us adults lose our capacity for abstracting things and dreaming, of letting our imagination flow and take us on a journey. I think we are way more literal. Many times a kid ends up dreaming and letting things happen more naturally, even in the most unusual moments. The narrative proposes growing up and improving without losing the ability to dream.<br />
<br />
<strong>The landscapes of Calygore appear to shift, move, and alter as the player progresses. How did you use UE4 to explore these types of level design?</strong><br />
 <br />
<strong>Vivas: </strong>One of the hardest things to do in <em>The Path of Calydra</em> is the level design. Some of the skills the player gets open many mobility possibilities. For example, if we do not pay attention, you could float from a higher place to another area of the game, which you initially could not reach before getting the “Float” skill. Our game is not an open-world one, but it has some really big scenarios, which forces us to double our attention towards skills that might mess with Matheus’ progression. UE4 eases level-blocking with its simple but powerful tools. We end up losing more time on scenario-idealization than on blocking and embellishing them.<br />
<br />
<strong>No fantasy land would be complete without some wacky creatures. What was the conceptualization process like for these baddies, and did Unreal Engine assist in bringing them to life?</strong><br />
 <br />
<strong>Vivas: </strong>I always drew a lot of monsters when I was a kid. Unfortunately, my drawing skills have always been bad, so I simply addressed my ideas to someone who could draw. Due to my background as a marine biologist, I end up applying the things I studied to the craziest ideas I have. In the 3D area, however, the whole team can give suggestions and everything ends up going smoothly.<br />
 <br />
We cannot compare ourselves with other companies who have dozens of modelers and animators. Having that in mind, we set goals that are reachable within our deadlines and capabilities. If something is good and within our creative vision, we move ahead to the next goal, always counting on Unreal’s ease to deal with shaders, textures, and <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/index.html" target="_blank">Materials</a> in an objective way, which is fantastic to our small team.<br />
<img alt="Developer-Interview_ThePathofCalydra011.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-lore-and-childlike-whimsy-to-create-a-fantasy-journey-worth-taking%2FDeveloper-Interview_ThePathofCalydra011-1919x1079-fdcd36f1bff00c5749243bd63c4c777e53980a44.jpg" width="auto" /><br />
<strong>Considering you’re a big movie fan coupled with the fact that protagonist Matheus has vintage movie posters in his room, would you say the game have a cinematic feel? And if so, were there any ways UE4 was able to enhance this aspect? </strong><br />
 <br />
<strong>Vivas: </strong>I am a big fan of movies indeed. Whenever I have time, I watch a bit of everything, from old classics to modern blockbusters. I tried to imbue a little of that in Matheus and, even being young, he really likes sci-fi and horror movies. I cannot say if we have a cinematographic feeling in <em>The Path of Calydra</em>, but I would say that we follow Matheus’ adventures with a close look on everything that happens, as if we are Matheus and Calydra’s companion on their journey. <br />
<br />
UE4 makes this process easy, allowing us to manipulate the animations through <a href="https://docs.unrealengine.com/en-US/Engine/Sequencer/Overview/index.html" target="_blank">Sequencer</a> in a relatively fast way. Since our team is small, spending too much time on cinematics would not be a good idea, and we probably would not have even half of what’s included if this tool did not exist.<br />
<br />
<strong>There appears to be lots of different abilities and items. Can you explain them a bit and name your favorites? </strong><br />
 <br />
<strong>Vivas: </strong>Yes. When Matheus ends up in Calysgore, Calydra’s universe, the entity is totally powerless. Our protagonist has to help it recover its powers so he can return to his world. Each ability is related to the four elements: fire, earth, wind and water. Every time he collects one of these elements, the backpack that Calydra embodies transforms, not only in its shape, but also in opening a range of element-related skills to be developed.<br />
 <br />
In Hyrus form (water), we have some of my favorite skills, like the one that changes the backpack into a SCUBA tank and allows Matheus to explore rivers and seas. Another interesting one is the “water drive,” which allows Matheus to traverse longer distances underwater in a very fast and fun way.<br />
 <br />
The Gyrus form (earth) has, among its skills, one that gives Matheus powerful arms to climb big magic walls, as well as a sword and shield that the character commands to face enemies. A wide variety of combos can be used depending on the need and on the size of the enemy.<br />
 <br />
There are many possibilities within every one of the elemental forms, and each of them has diverse options that can be accessed in a quick way.<br />
<img alt="Developer-Interview_Path_of_Calydra_FEED-THUMB.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-lore-and-childlike-whimsy-to-create-a-fantasy-journey-worth-taking%2FDeveloper-Interview_Path_of_Calydra_FEED-THUMB-1400x788-356f8dd59fe91e1922eeeb887aae850f8843bd40.png" width="auto" /><br />
<strong>You’ve previously spoken highly of the engine and its quick learning curve. What are your favorite tools and how have you used them to craft Path of Calydra?</strong><br />
 <br />
<strong>Vivas: </strong>We began developing the game in another language. Back in the day, I had trouble using some tools and software, so our programmer suggested UE4. At first glance I thought it would be even harder to deal with such a complex tool, which is normally used by bigger developers, but I was wrong. In a short time, I was already assembling the first scenarios and feeling way more comfortable with the tools granted by Epic.<br />
 <br />
As creative director in <em>The Path of Calydra,</em> I do a lot of things. More than visual direction and game design per se, I also take care of level design. After blocking the level, I use the <a href="https://docs.unrealengine.com/en-US/Engine/Foliage/index.html" target="_blank">Foliage</a> and <a href="https://docs.unrealengine.com/en-US/Engine/Landscape/Creation/index.html" target="_blank">Landscape</a> tools a lot. They simplify the finishing and embellishing of each scenario, and even though they are easy to use, they are extremely powerful. I learn something new to use in the game every day.<br />
<br />
<strong>The <a href="https://www.youtube.com/watch?v=rsXqfXXZmSw&amp;t=27s" target="_blank">first trailer</a> dropped almost four years ago. How has the game evolved since then and what have you learned as a developer and creator?</strong><br />
 <br />
<strong>Vivas: </strong>Back in the day, it was almost “just for fun.” I had no idea of where we would like to go with the game. We simply went by doing stuff and learned how to deal with the tools. After the second trailer, we got a real grasp of the game’s potential and, even with just a three-person team, started to work on basic stuff.<br />
 <br />
I come from a career making <a href="https://en.wikipedia.org/wiki/Category:Advergames" target="_blank">advergames</a>, where we developed smaller projects (to big companies, though) with smaller teams and a very short deadline. Switching to a project like <em>The Path of Calydra</em> is way more complex and bigger, requiring a lot of discipline and focus. You start to notice things you did not have to worry about before, trying to keep the project’s scope within what you know you can do, turning down ideas for being too complex, and simplifying what needs to be simplified. You learn how to deal with a bigger team, trying to get the best of each one. You learn how to listen more and, mostly, absorb all the knowledge you can, because that is going to help solve the problems that will surely show up along the way.<br />
<img alt="Developer-Interview_ThePathofCalydra008.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-lore-and-childlike-whimsy-to-create-a-fantasy-journey-worth-taking%2FDeveloper-Interview_ThePathofCalydra008-1919x1079-0db84ffed6e19340378f40fbb38414b9d58dc14e.jpg" width="auto" /><br />
<strong>Can you talk about what earning an <a href="https://www.unrealengine.com/en-US/blog/epic-games-announces-1-million-in-unreal-dev-grants" target="_blank">Unreal Dev Grant</a> has meant to the team?</strong><br />
 <br />
<strong>Vivas: </strong>Getting the Dev Grant was phenomenal. It boosted us up emotionally and psychologically, once we got the approval of people who consider hundreds of other projects and, despite this, chose ours.<br />
<br />
The team is now made of seven people besides me. With this growth, things started to shape up faster and game mechanics were implemented a bit easier. Visually, our improvements are also noticeable, and nowadays the project goes much swifter.<br />
<br />
<strong>Are there any other Brazilian games or developers that readers from North American, Europe, or elsewhere may not know about that you’d like to give a shout-out?</strong><br />
 <br />
<strong>Vivas: </strong>The Brazilian market has been expanding gradually over the past years, due to some of the government’s tender that boosted up some companies, allowing them to develop their projects with more resources (<em>The Path of Calydra</em> included).<br />
 <br />
With this [growth] in the market, lots of good games have been released across diverse platforms. Games like <a href="https://www.horizonchaseturbo.com/" target="_blank">Horizon Chase Turbo</a> (<a href="https://www.aquiris.com.br/en/" target="_blank">Aquiris Studio</a>) and <a href="http://www.chromasquad.com/" target="_blank">Chroma Squad</a> (<a href="https://www.beholdstudios.com.br/" target="_blank">Behold Studios</a>) became inspirations to other developers who seek quality products. Right now, just as <em>The Path of Calydra,</em> dozens of other good titles are being developed and will be on people’s radars by next year.<br />
<img alt="Developer-Interview_Path_of_Calydra_FEATURE-IMAGE.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-path-of-calydra-combines-adventure-lore-and-childlike-whimsy-to-create-a-fantasy-journey-worth-taking%2FDeveloper-Interview_Path_of_Calydra_FEATURE-IMAGE-1920x960-5a94a8efda79031efcea3b5fe152cdd7e856f273.png" width="auto" /><br />
<strong>If you want to learn more about <em>The Path of Calydra</em>, you can follow the game across multiple social platforms and the game pages below:</strong><br />
 
<ul style="margin-left: 40px;">
	<li><a href="https://www.facebook.com/ThePathofCalydra/" target="_blank">Facebook</a></li>
	<li><a href="https://twitter.com/finalbosscom" target="_blank">Twitter</a></li>
	<li><a href="https://www.youtube.com/channel/UCyrSp_9u0M7cIZV2XY-T43Q" target="_blank">YouTube</a></li>
	<li><a href="http://calydra.com/" target="_blank">Website</a></li>
</ul>
";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:9:"FinalBoss";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:19:"The Path of Calydra";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:9:"Sequencer";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:12:"Michael Luis";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 04 Dec 2019 15:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 04 Dec 2019 15:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:141:"https://www.unrealengine.com/developer-interviews/the-path-of-calydra-combines-adventure-and-childlike-whimsy-to-create-a-fantastical-journey";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:141:"https://www.unrealengine.com/developer-interviews/the-path-of-calydra-combines-adventure-and-childlike-whimsy-to-create-a-fantastical-journey";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:10;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:69:"Webinar: Achieving cinematic quality with post-process effects in UE4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:207:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fachieving-cinematic-quality-with-post-process-effects-in-ue4%2FEvent_WebinarPostProcessing_blog_thumb-375x275-adb62faff34d4e258ad1e9f2ee66feba4ee8b252.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:279:"<br />
Missed our webinar on enhancing the visual quality of a scene in Unreal Engine using post-process effects? Now you can watch it on demand! Learn how to work with depth of field, light bloom, exposure, tone mapping, color grading, ray-traced reflections, and more.<br />
 ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:1062:"We recently hosted the live webinar <strong>Achieving cinematic quality with post-process effects in UE4</strong>. If you missed it, no problem! The replay is available right here.<br />
<br />
In this webinar, Technical Artist Matthew Doyle goes through each of the different post-processing options. <br />
<br />
<strong>What you’ll learn:</strong>
<ul>
	<li> How to work with basic effects, such as bloom, lens flares, dirt maps, and more </li>
	<li> How to use the color grading tools, including the ACES film tone mapper</li>
	<li> How to use ray tracing features</li>
	<li> How to create and work with post-process materials</li>
</ul>
You can watch the full webinar below. Looking for more webinars? Check out the full series <a href="https://www.unrealengine.com/en-US/events/enterprise-webinar-series" target="_blank">here</a>.<br />
 
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/aGsUU_bvOgw" width="100%"></iframe></div>
";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:10:{i:0;a:5:{s:4:"data";s:12:"Architecture";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:23:"Broadcast & Live Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:17:"Film & Television";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:8:"Features";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:8:"Learning";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:8;a:5:{s:4:"data";s:11:"Ray Tracing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:9;a:5:{s:4:"data";s:7:"Webinar";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 22:05:38 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 22:05:38 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:102:"https://www.unrealengine.com/blog/webinar-achieving-cinematic-quality-with-post-process-effects-in-ue4";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:102:"https://www.unrealengine.com/blog/webinar-achieving-cinematic-quality-with-post-process-effects-in-ue4";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:11;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:70:" Air Canada uses VR to showcase its top-flight business class service ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:213:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_thumb-375x275-25fa348d52613cc61c0eb4acd54bfcea98fc83f4.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:271:"Air Canada used to rely on transporting a physical airplane seat to trade shows to demonstrate its business class service. Now it’s harnessing the power of interactive visualizations built in Unreal Engine to create a cost-effective VR marketing experience.  <br />
 ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:6225:"Air Canada is justifiably proud of its business class offering, having recently won Best Business Class in North America 2019 in the <a href="https://www.worldairlineawards.com/worlds-best-business-class-airlines-2019/" target="_blank">Skytrax World Airline Awards</a>. For years, however, it had to rely on taking a physical business class seat to trade shows in order to demonstrate this to prospective customers. <br />
<br />
That was until immersive content studio <a href="https://neutral.digital/" target="_blank">Neutral Digital</a> delivered a fully interactive solution that replicated the whole award-winning experience in VR. Now, instead of the logistical headache of transporting an airplane seat from country to country, <a href="https://www.aircanada.com/ca/en/aco/home.html" target="_blank">Air Canada</a> has a simple, easy-to-set-up system that fits into a Pelican case.<br />
<img alt="Spotlight_AirCanada_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_body_img1-1640x1000-f8a5818e31d0bf9c79e320d9f9cbb1743ebb6381.jpg" width="auto" />Not only is it easier and more cost-efficient to transport—it’s a more effective tool too. “Before, where we had hundreds of people trying out the seat in a day, now we have thousands,” says Jackie Harkness, Senior Director of Brand Marketing and Sponsorships at Air Canada. “We got a lot of extra customers and travel agencies we weren&#39;t expecting.”
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/MbBgqJrqnpU" width="100%"></iframe></div>

<h2>An engaging and cost-effective VR experience </h2>
Transporting a physical airline seat to trade shows around the world is logistically challenging and expensive. “The seat could only accommodate so many people in one day,” recalls Harkness. It had to travel with its own electrician, and required a special <a href="https://www.chamber-international.com/exporting-chamber-international/documentation-for-export-and-import/what-is-an-ata-carnet/" target="_blank">passport</a> to import it temporarily into the destination county. “These passports, and the fact that you had to ship these rather large seats, meant that it came with a quite a cost,” continues Harkness. <br />
<img alt="Spotlight_AirCanada_blog_body_img8.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_body_img8-1640x1000-aaad7dd14ecf1332cbb7257a8de97ffc0280f3bd.jpg" width="auto" />Air Canada began to explore more cost-effective and efficient ways of showcasing its business class service and found Neutral Digital. “They came to us and asked, ‘Well, how much can you do in virtual reality with this seat?’” says Sergio Irigoyen, Head of VR at Neutral Digital. “We created not only the seat, but also the whole passenger experience to show how great the service is.”<br />
<img alt="Spotlight_AirCanada_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_body_img4-1640x1000-c431af8e4fbadf9a9c604549a1dbaddff37c24d4.jpg" width="auto" />Given a free rein to develop the project, the team at Neutral Digital brainstormed ideas for user interactions that would not only be true to the real experience, but fun as well. “I think that if the fun element isn’t there, people get bored,” explains Matt Laverick, Lead VR Developer at Neutral Digital. <br />
<br />
Almost everything that you might interact with while sitting on the seat in real life is interactive in the VR experience. That includes adjusting the fans, turning the reading light on and adjusting its position, and putting on the headphones. <img alt="Spotlight_AirCanada_blog_body_img6.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_body_img6-1640x1000-85de91ddc0536e041ae0f46cf730b225ffa4857a.jpg" width="auto" />
<h2>Innovative VR airline marketing </h2>
To test out ideas and enable non-technical members of the team to contribute to the project, the team harnessed the power of the <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprint visual scripting system</a>. Providing the ability for designers and artists to use the full range of concepts and tools generally only available to programmers, Blueprint enables you to do everything visually, from dragging and dropping nodes to easily setting parameters in the UI. By leveraging Blueprint, the team also managed to sidestep a number of technical challenges on the project. <br />
<br />
“Around 97 to 98 percent of the project was done with Blueprint, and that allowed us not only to rapidly prototype things, but also to expose things for artists who weren&#39;t necessarily confident with Blueprint,” says Laverick. “We can drop a cinematic camera in, take some amazing-looking videos or stills with nice post-process effects, and then use them for marketing. Unreal gave us the ability to do that.”<br />
<img alt="Spotlight_AirCanada_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fair-canada-uses-vr-to-showcase-its-top-flight-business-class-service%2FSpotlight_AirCanada_blog_body_img3-1640x941-4cb9e5f469c30acf6294d2abfa79bbc18f80fe9d.jpg" width="auto" />The new and innovative solution they now have in place fits into part of a wider story at Air Canada. “This project very much aligned with our ambition to be one of the top 10 global airlines in the world,” says Harness. <br />
<br />
<br />
Want to create your own immersive, interactive visualizations for compelling marketing experiences? <a href="https://www.unrealengine.com/en-US/" target="_blank">Download Unreal Engine </a>for free today!";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:6:{i:0;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:11:"Advertising";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:10:"Air Canada";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:15:"Neutral Digital";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:10:"Keef Sloan";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 17:06:57 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 17:06:57 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:108:"https://www.unrealengine.com/spotlights/air-canada-uses-vr-to-showcase-its-top-flight-business-class-service";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:108:"https://www.unrealengine.com/spotlights/air-canada-uses-vr-to-showcase-its-top-flight-business-class-service";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:12;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:49:"Featured free Marketplace content - December 2019";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:181:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Thumb-375x281-28eacabc16623da06af29d646a9ad4969b04c5a2.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:205:"Paint beautiful environments with arctic terrain brushes and landscape stamps, rocket your scenes into space with modular kits, and teleport characters out of this world with this month’s free content. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:3976:"In an ongoing partnership with Unreal Engine Marketplace creators, select content will be available for free to the Unreal community each month to give artists, designers, and programmers access to even more resources at no additional cost.<br />
<br />
Check out this month’s great selection below!
<h2><strong>December&#39;s featured free content:</strong></h2>

<h2><a href="https://www.unrealengine.com/marketplace/en-US/slug/brushify-arctic-pack" target="_blank">Brushify - Arctic Pack</a> | <a href="https://www.unrealengine.com/marketplace/en-US/profile/JoeGarth" target="_blank">JoeGarth</a></h2>

<p style="text-align: center;"><img alt="News_UESC_DEC2019_Blog1.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Blog1-770x433-fe07f867ea0b4a78c5c358a1e91181d8a19a1b48.jpg" /><br />
<em>Send your characters into frozen tundras or pristine mountain ranges with this AAA-ready modular environment kit.</em></p>

<h2><a href="https://www.unrealengine.com/marketplace/en-US/slug/landscape-stamps" target="_blank">Landscape Stamps</a> | <a href="https://www.unrealengine.com/marketplace/en-US/profile/W3+Studios" target="_blank">W3 Studios</a> </h2>

<p style="text-align: center;"><img alt="News_UESC_DEC2019_Blog2.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Blog2-770x433-dc724dd63b8a9388786533651d082cf522e784fe.jpg" /><br />
<em>Quickly create a diverse terrain filled with mountains, plateaus, cliffs, craters and more with over 150 landscape stamps.</em></p>

<h2><a href="https://www.unrealengine.com/marketplace/en-US/slug/player-building-template" target="_blank">Player Build System</a> | <a href="https://www.unrealengine.com/marketplace/en-US/profile/Defuse+Studios" target="_blank">Defuse Studios</a></h2>

<p style="text-align: center;"><img alt="News_UESC_DEC2019_Blog3.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Blog3-770x433-9cad27ba82673cafda1e6c1aababab714401a0bd.jpg" /><br />
<em>Build, damage, repair, and upgrade your way through development with this multiplayer-compatible building system.</em></p>

<h2><a href="https://www.unrealengine.com/marketplace/en-US/slug/portals-blueprint" target="_blank">Portals Blueprint</a> | <a href="https://www.unrealengine.com/marketplace/en-US/profile/Alex+Petherick-Brian" target="_blank">Alex Petherick-Brian</a></h2>

<p style="text-align: center;"><img alt="News_UESC_DEC2019_Blog4.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Blog4-770x433-ffdd137167447e53774c48276eb3112eb79e03b8.jpg" /><br />
<em>Teleport characters and props across your maps with this easy-to-implement portal Blueprint.</em></p>

<h2><a href="https://www.unrealengine.com/marketplace/en-US/slug/zero-gravity-part-one" target="_blank">Zero Gravity Part One</a> | <a href="https://www.unrealengine.com/marketplace/en-US/profile/Henri+Juntunen" target="_blank">Henri Juntunen</a></h2>

<p style="text-align: center;"><img alt="News_UESC_DEC2019_Blog5.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ffeatured-free-marketplace-content---december-2019%2FNews_UESC_DEC2019_Blog5-770x433-800c3f3fdb08c9658c4ebd8133fa392a07ca7c71.jpg" /><br />
<em>Create an out-of-this-world zero-gravity set with this collection of high-quality meshes and materials!</em></p>
Download these beautiful assets and expedite your production before the end of the year. Come back in 2020 for more free Marketplace goodies! <br />
<br />
Are you a Marketplace creator interested in sharing your content for free with the community? Visit <a href="https://www.unrealengine.com/uesponsoredcontent" target="_blank">unrealengine.com/uesponsoredcontent</a> to learn how you could be featured!<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:5:{i:0;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:11:"Marketplace";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:13:"Amanda Schade";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 03 Dec 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:83:"https://www.unrealengine.com/blog/featured-free-marketplace-content---december-2019";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:83:"https://www.unrealengine.com/blog/featured-free-marketplace-content---december-2019";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:13;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:68:" Explore nDisplay technology: limitless scaling of real-time content";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:199:"https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_thumb-375x275-e800cb1a80527bed9f7d8970f3498179b927b3a8.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:279:"More and more industries are using multiple large displays to immerse participants in a real-time environment. In this new white paper, learn how nDisplay technology was developed to meet the need for real-time rendering distribution and network management for scaled displays. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:7159:"With new advances in real-time technology, industries from entertainment to defense are using large, immersive displays to engage participants in custom real-time experiences. These displays, which can range from enormous projection domes to complex, high-density arrays of LED screens, can present a real-time scene at virtually any resolution. <br />
<br />
Today, it isn’t uncommon to have display systems of various shapes and physical sizes at resolutions exceeding many times the highest of industry standards, such 8K. These aggregated displays often require live and synchronous content to refresh at rates of 60 fps and beyond.<img alt="nDisplay_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_body_img1-1640x1000-9515f0e803d14430efd9fb9438d96ce9716c1559.jpg" width="auto" />To display such a large volume of real-time pixels, the rendering of each frame needs to be distributed over a network of machines—with each machine rendering just a section of a frame—and then each frame must be displayed with precise matching of section edges, all at exactly the same time.<br />
<img alt="nDisplay_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_body_img2-1640x1000-f6a5d1f58e28f8c50d1334aa0ae1e6ffa874de75.jpg" width="auto" />To facilitate such a complex process, Epic Games has introduced nDisplay technology for Unreal Engine. nDisplay combines network configuration data, details about display mechanisms, distribution of rendering, and image display for large surfaces and screens.<br />
<br />
In the new white paper <a href="https://cdn2.unrealengine.com/Unreal+Engine%2FnDisplay-Whitepaper-V1.8B-9d99c6448fbd96bcd5a8d0770c12c22387683778.pdf" target="_blank">nDisplay Technology: Limitless scaling of real-time content</a>, we explore the history and research behind nDisplay, and take a look at types of displays along with network configurations, testing, and syncing. We dive in deep to the nDisplay configuration file, the heart of nDisplay technology.<img alt="nDisplay_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_body_img3-1640x779-b5537ae26edc5e2fb791faadae468e3bdc4a4d47.jpg" width="auto" />The paper also discusses the implementation of the MPCDI standard and Scalable EasyBlend technology, both of which nDisplay uses to facilitate displaying content on arbitrary and odd-shaped surfaces of all kinds. 
<h2>Who uses large displays?</h2>
In the white paper, we mention several use cases for nDisplay including live events, architectural visualization, and virtual production. Here’s a closer look at these and other applications for scaled real-time content.  

<h3><strong>Live events</strong></h3>
With real-time projection onto the inside of the world’s largest inflatable dome, <a href="https://www.unrealengine.com/spotlights/childish-gambino-mesmerizes-fans-with-real-time-animation" target="_blank">hip-hop performer Childish Gambino teamed up with Weta Digital and 2n Design</a> to create a real-time fantasy world for concert attendees.<br />
<br />
2n used a 5.4K by 5.4K image rendered by five frame-locked machines powered by NVIDIA Quadro P6000 graphics, then split into a fisheye and sent to 12 projectors. “Using nDisplay to be able to distribute the real-time rendering, and keep the resolution and the frame rate where it needed to be for this project, was key,” says Jeremy Thompson, Art Director at 2n.
<h3><img alt="nDisplay_blog_body_img_Weta.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_body_img_Weta-1640x913-769077cd9d9b64f67002008f65fbde4497e63ed3.jpg" width="auto" /><strong>Military training applications</strong></h3>
The military and defense sector was among the first to embrace large-scale real-time content for immersive training, giving trainees the sensation of reality without the dangers of live hostile situations.<br />
<br />
“Immersion is key to learning transfer in virtual training,” says S&eacute;bastien Loz&eacute;, Industry Manager for Simulations at Epic Games. He adds that immersive dome projections provide environments where trainees can remain both immersed and connected to their peers, enabling them to develop the kinds of skills they need for high-tempo operations.
<h3><img alt="nDisplay_blog_body_img_military.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexplore-ndisplay-technology-limitless-scaling-of-real-time-content%2FnDisplay_blog_body_img_military-1640x1000-4d3d03adc2e98545dcee916b273e4000e16fdc54.jpg" width="auto" /><strong>Immersive real-time sets for filmmaking</strong></h3>
In August 2019, Epic joined industry partners Lux Machina, Magnopus, Profile Studios, Quixel, ARRI, and DP Matt Workman to <a href="https://www.unrealengine.com/en-US/spotlights/unreal-engine-in-camera-vfx-a-behind-the-scenes-look" target="_blank">test-drive a virtual production setup featuring live LED walls</a>. The walls provide both the environments and the lighting, with the displayed scene illuminating actors and props and providing reflections. nDisplay controlled the live real-time background on three LED panels, each with a 4K image.

<h2>Scalable Display Manager on Unreal Engine Marketplace</h2>
In the spirit of extending nDisplay functionality to a wider audience, Scalable Display has released <a href="https://www.unrealengine.com/marketplace/en-US/slug/scalable-display-manager-for-unreal" target="_blank">Scalable Display Manager for Unreal</a>, a free version of its calibration tool. With this watermarked version of Scalable Display Manager, you can test and experiment with projecting real-time content on dual-screen configurations of various shapes and sizes using nDisplay. The fully featured version of the Scalable Display Manager, which supports unlimited projectors, is available for purchase directly from Scalable Display Technologies.

<h2>The future of scalable real-time content</h2>
With the ongoing developments around nDisplay, new and exciting opportunities are now within reach. Imagine projection mapping or massive LED canvases at never-before-seen sizes and resolutions delivering seamless, fully live and engaging 3D content—closing the gap between pre-rendered and real-time content. Complex and expensive setups that were once only accessible to a few are now within reach. The world is changing, and we want Unreal Engine users to be ahead of the wave.<br />
To start on your journey into the new era of large displays, download the white paper <a href="https://cdn2.unrealengine.com/Unreal+Engine%2FnDisplay-Whitepaper-V1.8B-9d99c6448fbd96bcd5a8d0770c12c22387683778.pdf" target="_blank">nDisplay Technology: Limitless scaling of real-time content</a>.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:9:{i:0;a:5:{s:4:"data";s:12:"Architecture";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:23:"Broadcast & Live Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:17:"Film & Television";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:8:"Learning";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:8:"nDisplay";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:18:"Virtual Production";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:8;a:5:{s:4:"data";s:7:"Defense";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:13:"Sevan Dalkian";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 02 Dec 2019 18:47:05 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 02 Dec 2019 18:47:05 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:105:"https://www.unrealengine.com/tech-blog/explore-ndisplay-technology-limitless-scaling-of-real-time-content";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:105:"https://www.unrealengine.com/tech-blog/explore-ndisplay-technology-limitless-scaling-of-real-time-content";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:14;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:71:"HTX Labs delivers immersive VR training simulations using Unreal Engine";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:214:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fhtx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine%2FSpotlight_HTXLabs_blog_thumb-375x275-a75e4e36275cc852e7233bbda94e2719f64849c0.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:199:"To reduce costs, remove risks, and speed up training, the military is looking at innovative uses for VR. Find out how HTX Labs is moving along these initiatives in the Air Force and other industries.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:8707:"Three years ago, Scott Schneider, Chris Verret, and several other colleagues formed <a href="https://www.htxlabs.com/" target="_blank">HTX Labs</a> with a goal of bringing VR-based training simulations to highly regulated industries—such as defense, petrochemical, and oil and gas—where comprehensive live training can be both costly and dangerous.<br />
<br />
They started with a handful of Unreal Engine-based demos. Just 18 months later, they found themselves providing VR Emergency Procedure (EP) training to student pilots as part of the US Air Force’s <a href="https://www.aetc.af.mil/About-Us/Pilot-Training-Next/" target="_blank">Pilot Training Next (PTN)</a> program. And this year, they’ve secured a <a href="https://www.prnewswire.com/news-releases/us-air-force-awards-sbir-phase-ii-to-virtual-reality-technology-innovator-htx-labs-300892737.html?tc=eml_cleartime" target="_blank">Small Business Innovation Research (SBIR)</a> Phase II award from the Air Force to expand EMPACT<sup>®</sup>, a next-generation VR training platform, to support authoring, managing, and distributing immersive content to deliver training to the point of impact—the worker and the warfighter.<br />
<br />
The response from PTN has been nothing short of enthusiastic. “HTX has provided us an immersive emergency procedure trainer that filled an essential gap in our pilot training program,” says Paul "Slew" Vicars, Lead for the PTN Program, U.S. Air Force. 
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/j84kmTn_uHE" width="100%"></iframe></div>
With EMPACT, an instructor pilot can set up an emergency scenario in VR and use it to test and train new pilots. “For example, you are at 10,000 feet and suddenly a fire erupts in the engine, or there is smoke in the cockpit, or you have a hydraulic malfunction,” explains Schneider, CEO of HTX Labs. “The trainee has to react to that emergency with a very specific procedure, which he needs to know like the back of his hand. And he needs to do it, not just talk through it, just as he would have to do in the real situation.”<br />
<br />
The Air Force has many such emergency procedures, most of which would be difficult or impossible to demonstrate in real life without endangering the trainee. Such scenarios are perfect candidates for VR training. <br />
<img alt="Spotlight_HTXLabs_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fhtx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine%2FSpotlight_HTXLabs_blog_body_img1-1640x770-cb475cefeb04e05b437073fcc829db7a855f70a8.jpg" width="auto" /><br />
“The Air Force wanted to get the next best thing to actually having your plane set on fire, which you never want to see in real life,” explains Schneider. <br />
<br />
“Our military customers, and actually all our customers, want our VR training to be as real and immersive as possible,” says Verret, CTO at HTX Labs. “Unreal Engine gives us the ability to deliver on that expectation.”
<h3><strong>Bridging enterprise and military</strong></h3>
In 2016, software engineers Schneider and Verret developed a deep interest in the potential of immersive technology to reduce time, costs, and risks in enterprise training. They began showcasing demos at conferences, where they eventually caught the eye of an Air Force Colonel from <a href="https://www.afwerx.af.mil/" target="_blank">AFWERX</a>, an Air Force organization that fosters innovation and collaboration with the private sector. <br />
<img alt="Spotlight_HTXLabs_blog_body_img9.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fhtx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine%2FSpotlight_HTXLabs_blog_body_img9-1640x1000-4f5e5a6d74adb889d95b2915eedb3028a608762f.jpg" width="auto" />This led to HTX Labs’ initial work with Pilot Training Next, and ultimately to securing the SBIR Phase II to expand their EMPACT VR training solution. SBIR has the multi-faceted goal of providing the granting agency with innovative R&D, tools, and services, while also giving the recipients the means to develop a commercial product.<br />
<br />
Verret credits the team’s experience in enterprise software with making them a good fit for SBIR. “We’re enterprise, we’ve always been enterprise, and that attitude is behind everything we do,” he says. He adds that while much of his team has the skill set to work at a studio, “the culture that we have instilled here is very focused on commercial software and the methodologies and the processes that go with that.”<br />
<br />
Because of this approach, every aspect of EMPACT is designed to fit into a platform that can support multiple types of training across a variety of industries. “We don’t do anything with a one-and-done mindset,” explains Verret. “Architecture is critical for us. We focus on reusability, APIs, and layers.”<br />
<img alt="Spotlight_HTXLabs_blog_body_img8.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fhtx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine%2FSpotlight_HTXLabs_blog_body_img8-1640x1000-bc7e126815e2e79dcc193dfc73476e1e3088f35f.jpg" width="auto" />Scenarios for safety and preparedness training are just part of the overall package. HTX Labs aims to provide a full platform that includes data tracking and tools for post-training analysis in a variety of industries. “Whenever we’re building a new simulation, we think about what information we need to capture,” says Schneider. “What data do want to be able to look at over time, to truly determine whether the student is progressing? Can we track enough things to compare this student to another student, or this student to an expert, or this student to the entire cohort?”<br />
<br />
“The more data that we can compile—and not just compile, but expose in a meaningful way so someone can make sense of it and visualize it—the more beneficial VR becomes for training.”
<h3><strong>Choosing Unreal Engine</strong></h3>
HTX Labs chose Unreal Engine as the basis for their work not only for its rendering quality, but also for its broad capabilities in creating specific scenarios for emergency training.<br />
<br />
“We didn’t want to build each and every emergency procedure from scratch,” says Schneider. “There are so many different emergency procedures—fire in flight, electrical fire, generator inoperative. There are scenarios in the air, scenarios on the ground.”<br />
<br />
Using the <a href="https://docs.unrealengine.com/en-us/Engine/Blueprints" target="_blank">Blueprint visual scripting language</a> as a framework, HTX Labs created a reusable foundation for building emergency scenarios. “Unreal Engine gave us the means to reuse a lot of our content, and to build scenarios much more quickly,” says Schneider.<br />
<img alt="Spotlight_HTXLabs_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fhtx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine%2FSpotlight_HTXLabs_blog_body_img7-1640x1000-4489a750b24b97ece46ca9a7b9d755bdd631ef96.jpg" width="auto" />HTX Labs uses a variety of DCC packages to build environments and props, including Modo, Maya, and Houdini. “When we are going to virtualize someone&#39;s facility, whether it’s a hangar, a refinery, or an office building, we have a very defined, efficient process that we have developed over time,” says Verret. “Unreal Engine is at the center of it all.”<br />
<br />
He adds that Unreal Engine&#39;s integration with Perforce source control repository is a huge boon to productivity. “It’s all about speed and iterations for our developers, which translates to faster building overall,” Verret says.
<h3><strong>Looking to the future of VR-based training</strong></h3>
HTX Labs sees a bright future for VR-based training across all heavy industries, and in the military in particular. “Excitement about the technology has proliferated to just about every major base,” says Verret. “They all have virtual reality capabilities now. The missing link is just a more coordinated effort. There’s no turning back from it now. It’s momentum that just continues to build.”<br />
<br />
<br />
To find out what Unreal Engine can bring to simulation training in your industry, <a href="https://www.unrealengine.com/en-US/enterprise/contact-us" target="_blank">contact us</a> and we’ll get that conversation started.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:7:"Defense";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:16:"Sébastien Lozé";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 02 Dec 2019 18:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 02 Dec 2019 18:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:111:"https://www.unrealengine.com/spotlights/htx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:111:"https://www.unrealengine.com/spotlights/htx-labs-delivers-immersive-vr-training-simulations-using-unreal-engine";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:15;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:81:"Tips for submitting your Unreal Engine project for the annual student sizzle reel";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:217:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ftips-for-submitting-your-unreal-engine-project-for-the-annual-student-sizzle-reel%2FNews_StudentReel_blog_thumb-375x275-9a98ead122e3a757fa27d17932164142058c4339.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:126:"Want to have a video clip of your UE4 project considered for inclusion in the 2020 student sizzle reel? Here are our top tips.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:7238:"Students around the world are learning Unreal Engine and real-time technology to enhance their portfolios and land amazing jobs across a wide range of industries including games, film and TV, automotive, architecture, and training and simulation.<br />
<img alt="News_StudentReel_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ftips-for-submitting-your-unreal-engine-project-for-the-annual-student-sizzle-reel%2FNews_StudentReel_blog_body_img2-1640x929-f23a76e67f6166ed1f1a34a5c51f2505daa83375.jpg" width="auto" /><br />
Every year, hundreds of individual students and student teams submit video clips and trailers of their best Unreal Engine projects in the hope of getting featured in the annual, GDC-premiered <a href="https://www.youtube.com/watch?v=GAmt-J9v5eA" target="_blank">Unreal Engine student sizzle reel</a>. <br />
<br />
Want your beautiful Unreal Engine project to be considered for inclusion in the 2020 student sizzle reel? Here are our top tips:
<ol>
	<li>
	<h3><strong>Give your project a unique title</strong></h3>
	</li>
</ol>
In order to stand out, give your project a unique and creative name, and avoid labels like “Untitled” and “Environment Art." Remember, this project name will be the title that appears in the lower third graphic of the student sizzle reel.  

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/GAmt-J9v5eA" width="100%"></iframe></div>

<div style="text-align: center;">  <em style="text-align: center;">2019 Student Sizzle Reel</em></div>
 

<ol start="2">
	<li>
	<h3><strong>Less is more, and quality over quantity</strong></h3>
	</li>
</ol>
Capture attention by making sure your best work is presented at the beginning of your submission. In terms of video length, we prefer clips under 60 seconds for review purposes, but we do accept longer pieces such as a short film or game trailer.

<ol start="3">
	<li>
	<h3><strong>Don’t put titles or logos over the video</strong></h3>
	</li>
</ol>
For the official Unreal Engine student sizzle reel, we cannot use footage that has text, titles or logos overlayed on the video. Save those for the beginning and end of your footage. Please submit clean video footage only.

<ol start="4">
	<li>
	<h3><strong>Record at a high resolution and stable frame rate</strong></h3>
	</li>
</ol>
Strive to reach either a locked 30 or 60 frames per second and a minimum resolution of 1920x1080 for your video. If you don&#39;t have one, consider borrowing a powerful computer to capture footage.<br />
<br />
For more details, find out about <a href="https://docs.unrealengine.com/en-US/Engine/Performance/index.html" target="_blank">performance and profiling</a> on our documentation page.

<ol start="5">
	<li>
	<h3><strong>Make gameplay footage shine</strong></h3>
	</li>
</ol>
If your project is a game, try out screen recording software like <a href="https://www.nvidia.com/en-us/geforce/geforce-experience/shadowplay/" target="_blank">NVIDIA Shadowplay</a> or <a href="https://obsproject.com/" target="_blank">Open Broadcaster Software (OBS)</a> for direct gameplay capture. Again, using powerful hardware will help guarantee smooth, clear footage. <br />
 
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/iSegRQy1CGA" width="100%"></iframe></div>

<div style="text-align: center;"><em>En Garde! Supinfogame RUBIKA gameplay</em></div>

<h3><img alt="News_StudentReel_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Ftips-for-submitting-your-unreal-engine-project-for-the-annual-student-sizzle-reel%2FNews_StudentReel_blog_body_img1-1640x923-dabb2ee6dfe2d8c7526dc12535493a38af871203.jpg" width="auto" /></h3>

<ol start="6">
	<li>
	<h3><strong>Explore cinematics with Sequencer</strong></h3>
	</li>
</ol>
Gameplay is important and so is cinematography. Well-chosen camera angles, composition, and movement can make good art look great. If you use <a href="https://docs.unrealengine.com/en-US/Engine/Sequencer/index.html" target="_blank">Sequencer</a> to build your cinematics, you can <a href="https://docs.unrealengine.com/Engine/Sequencer/HowTo/RenderMovies/index.html" target="_blank">export high-quality footage directly from the Editor</a> for the best quality.<br />
<br />
Here’s an example of great camera work:
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/SJCzv0F72dA" width="100%"></iframe></div>

<div style="text-align: center;"><em>E-751, New York Institute of Technology</em><br />
 </div>

<ol start="7">
	<li>
	<h3><strong>Submit one project at a time</strong></h3>
	</li>
</ol>
If you have multiple projects you would like us to consider, please submit them separately with unique names and with individual YouTube or Vimeo links.

<ol start="8">
	<li>
	<h3><strong>Avoid default textures, characters, and other assets</strong></h3>
	</li>
</ol>
Relying on the models, textures, and other assets that ship with Unreal Engine will make your project feel unfinished and it might not be chosen because of this. For example, we typically choose not to use footage featuring the generic Unreal Engine mannequin, so you’ll want to keep this in mind.

<h3><br />
<strong>How to submit your project</strong></h3>
<br />
Simply upload a video of your project to YouTube or Vimeo and send the link to <a href="mailto:student.reel@unrealengine.com">student.reel@unrealengine.com</a> along with the information requested below. As a reminder, please make sure your video has a minimum resolution of 1920x1080. <br />
 <br />
Please include the following details in the body of your email:<br />
 
<ul style="margin-left: 40px;">
	<li><strong>Project name:</strong> The title of your game, short film, or visualization.</li>
	<li><strong>Your name: </strong>The first and last name of the student submitting the project.</li>
	<li><strong>Team members: </strong>All team members involved in the project, if applicable.</li>
	<li><strong>Team name: </strong>Your team name, if applicable.</li>
	<li><strong>School name:</strong> The name of your university or college.</li>
</ul>
 <br />
You can also include the <a href="https://www.unrealengine.com/en-US/branding" target="_blank">Unreal Engine logo</a> on the title screen or in the credits of your video. Here is a great example:

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/7zd205xL5MQ" width="100%"></iframe></div>

<div style="text-align: center;"><em>The Resistance, University of Hertfordshire</em></div>
<br />
<br />
Thanks for reading through all of the recommendations above, which we hope you&#39;ll follow once you&#39;re ready to share your work with us. And remember that while we can’t use every video that is sent our way, we always love to see your imagination come to life through Unreal!";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:2:{i:0;a:5:{s:4:"data";s:9:"Education";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:16:"Melissa Robinson";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 21:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 21:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:115:"https://www.unrealengine.com/blog/tips-for-submitting-your-unreal-engine-project-for-the-annual-student-sizzle-reel";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:115:"https://www.unrealengine.com/blog/tips-for-submitting-your-unreal-engine-project-for-the-annual-student-sizzle-reel";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:16;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:62:"Efficient police virtual training environment in VR by V-Armed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:205:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-Armed_blog_thumb-375x275-56462b9f913a8aec93988e18ed1af6becf0358e0.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:259:"From de-escalation to fast tactical response, police officers need to train for a variety of sensitive scenarios. V-Armed specializes in creating customizable, repeatable, and reviewable VR training that makes officers feel as though they’re really there. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:11914:"Virtual reality has seen many implementations in the Training & Simulation sector, from <a href="https://www.unrealengine.com/spotlights/helping-brain-surgeons-practice-with-real-time-simulation" target="_blank">brain surgery</a> to <a href="https://www.unrealengine.com/en-US/spotlights/offworld-industries-brings-realistic-infantry-training-to-the-simulation-community" target="_blank">military operations</a>. Now, VR-based law enforcement training is available to police officers to quickly and safely train them for a variety of situations.<br />
<br />
One of the most exciting emerging players behind this surge is <a href="https://www.v-armed.com/" target="_blank">V-Armed</a>, creators of VR simulations for large-scale multi-participant training. Participants move around in a large, mostly empty space and, with the help of head-mounted displays, body sensors, proxy weapons, and strategically placed doorways, experience tactical scenarios as if they and their fellow officers were actually there.<br />
<img alt="Spotlight_V-armed_blog_body_img6.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-armed_blog_body_img6-1640x902-93cf277ff59670e5ab290551618cd9aa8fea68bf.jpg" width="auto" /><br />
The VR experiences, developed using Unreal Engine, feature realistic visuals of the environment and people, sound effects, and other sensory cues designed to induce the same mental and physical challenges as the real thing, down to the adrenaline rush the participants feel as the scenario unfolds. As with a real-world situation, participants are free to call out and gesture to one another. Command personnel can view the session from any angle as it’s happening and can also replay the session later for review. <br />
<br />
“The vision of V-Armed is to help people train better,” says Elad Dabush, Chief Technology Innovation Officer at V-Armed. “For law enforcement, training at real-life locations can be very limiting. For example, in some training environments you can’t shoot above a certain height or in certain directions because the bullet might land outside the safety boundary. In VR, it doesn’t matter. It’s a complete 360/6DOF environment, and the bullets are virtual.”
<h3><strong>Making a believable virtual environment</strong></h3>
Before starting V-Armed three years ago, the team had worked for many years in film and video production, creating numerous TV commercials. This experience shows through in the visceral response from participants. “After telling stories on TV, we instinctively know the right kinds of elements to include, the ones that will create the stress and tension that would be present in the real-life scenario,” says Rotem Shiffman, Head of Development at V-Armed. “That tension is absolutely necessary for an effective training experience.”<br />
<br />
Shiffman explains that when a user can forget that he’s in VR, his body starts to react as it does in real life. The VR scenario has to be realistic enough on several levels—visually, emotionally, physically—to fool the trainee’s brain into thinking he or she is actually there. Real-world physics and lighting, realistic weapons and uniforms, and true-to-life sound effects are just a few of the tools they use to accomplish this goal.<br />
<img alt="Spotlight_V-Armed_blog_body_img4(1).jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-Armed_blog_body_img4%281%29-1640x1000-af24d1ee191c887b288bdf6eb6420fafcf427224.jpg" width="auto" /><br />
Creating such experiences isn’t simply a matter of recreating an environment down to the tiniest detail with high-resolution 3D models—in fact, doing so would be a hindrance to VR playback speed. With virtual reality, a vital part of making it real is keeping the frame rate high enough for fast updates and smooth motion, which means picking your battles with regard to levels of detail. <br />
<img alt="Spotlight_V-Armed_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-Armed_blog_body_img1-1640x1000-0c933228e02c59e5a304e4de7dff4aa28fe750c2.jpg" width="auto" /><br />
“It&#39;s not just visual fidelity and realism, it&#39;s authenticity,” says Dabush. “We found that texturing, lighting, shading, and overall mood has much higher importance than poly count, especially with our target audience. If a wall or piece of furniture isn’t 100% realistic, this won’t register with most trainees. But it’s important that the gun they’re holding be exactly right, and that their uniforms be accurate. These are the kinds of things that make it real to them.”<br />
<br />
With the right balance of realistic detail and playback speed, V-Armed’s scenarios hit the sweet spot for immersive training. “We see trainees coming out the end with elevated heart rates, and out of breath,” says Shiffman. “You can tell by their voice that they are acting as if they were really in that environment.”<br />
<br />
One of V-Armed’s training sessions was recently featured on ABC news, where senior law enforcement praised the effectiveness of the training and also the value of reviewing officer performance after the fact. They also recognized the convenience of being able to train hundreds of officers at any virtual location without the hassles of real-world logistics.
<h3><strong>Evolving the training with the Scenario Editor</strong></h3>
Late last year, V-Armed had rented a space in Brooklyn, NY when by chance, an NYPD detective saw their sign and stopped in for a visit. This auspicious beginning led to V-Armed offering the VR training to NYPD for free. The training was made possible with support from the Department of Homeland Security and the Academy of Counter-Terrorism Education at Louisiana State University (<a href="https://www.ncbrt.lsu.edu/" target="_blank">LSU NCBRT/ACE</a>).<br />
<br />
V-Armed built Scenario Editor, their own scenario authoring tool, on top of Unreal Engine, so training leaders themselves can customize the experience and create completely new scenarios within the environments. For example, specific types of civilians can be added to make the scenario more realistic, such as children for a school environment or a mix of ages and genders in an outdoor park.<br />
<img alt="Spotlight_V-Armed_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-Armed_blog_body_img2-1640x1000-246f7ec62e68fb55a73bffaa846084e2250c8735.jpg" width="auto" /><br />
Shiffman wrote Scenario Editor to satisfy NYPD’s requirement of having trainees go through a wide variety of scenarios—rather than V-Armed creating the scenarios themselves, they enabled users to create and modify them at will. Starting with a basic layout such as a school, warehouse, or park, a trainer can drag-and-drop furniture, props, avatars, audiovisual stimuli, and action triggers into the layout, building it up until the scenario is complete.<br />
<img alt="Spotlight_V-armed_blog_body_img3(1).jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-armed_blog_body_img3%281%29-1640x902-5e114e666e8065864021e67437c403609bba3068.jpg" width="auto" /><br />
“The Scenario Editor enables trainers, even someone with no development experience, to create a training scenario from scratch,” says Shiffman. “For example, the user can place an adversary and civilians in room A, and add a trigger such that when a participant enters room B, the adversary starts shooting, directing the participants’ attention to that room. It&#39;s very flexible, and it allows them to create a lot of scenarios for a varied array of training goals. On top of that, the operator can control and trigger actions in real time as the scenario is unfolding.”<br />
<br />
The analysis tools included in the system provide law enforcement with opportunities they’ve never had with live training. For example, a senior officer can replay a session from an overhead view and evaluate the performance of a specific officer or the entire team. With live training, this simply isn’t possible. And after they’ve run dozens or hundreds of officers through the training, command can analyze patterns and identify areas for improvement.<br />
<img alt="Spotlight_V-armed_blog_body_img8.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-armed_blog_body_img8-1640x902-67a89de8e7b2b23553cd36b833dbce766b557301.jpg" width="auto" /><br />
V-Armed has also produced a more mobile version of the system that can be shipped and installed within a few days. All that’s required is a location with sufficient space.<br />
<br />
“Our vision is to get this amazing training tool to every agency that needs it,” says Dabush.
<h3><strong>Choosing Unreal Engine for the job</strong></h3>
Dabush and Shiffman started working with real-time technology even while still working in the entertainment sector. “We tried some other engines, but we just started getting better results much faster inside of Unreal,” says Dabush.<br />
<img alt="Spotlight_V-Armed_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fefficient-police-virtual-training-environment-in-vr-by-v-armed%2FSpotlight_V-Armed_blog_body_img3-1640x1000-465bd8d7977e2e110c989f308a1d58de96691780.jpg" width="auto" /><br />
For training and simulation solutions, the team likes the fact that they can use C++ for all their low-level code alongside <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprint</a> scripts for scenario-specific code. The fact that the code is open source gives them the opportunity to debug much more quickly. V-Armed implements all their base code as a series of plugins over the standard Unreal Engine build, and attaches the plugins to all the projects they create.<br />
<br />
“We usually prototype using Blueprint, and extract all reusable pieces into our shared C++ libraries, leaving only a minimal amount of high-level Blueprint work we need to do for each specific project,” says Shiffman. “Unreal’s two-tiered development environment is very helpful in this regard.”<br />
<br />
It was these features, plus the visual fidelity and playback speed they were able to achieve, that sealed the deal for their selection of a real-time engine. “Without Unreal,” says Shiffman, “we couldn&#39;t make it happen.”
<h3><strong>Looking to the future</strong></h3>
These early successes has V-Armed excited about the use of VR for the police training of the future. “Learning from PowerPoint presentations is the way of the past,” says Dabush. “Once you put on a headset and see a virtual avatar teaching you and showing you something, and you have a recollection or a memory that you were in a certain situation, it has an impact and it teaches you better.”<br />
<br />
Shiffman concurs, with a specific takeaway for law enforcement. “What we do isn’t just teaching marksmanship. There are a lot of decisions involved in when to shoot. And more importantly, when not to shoot.”<br />
<br />
<br />
Want to explore the use of real-time technology for your own training needs? <a href="https://www.unrealengine.com/en-US/enterprise/contact-us" target="_blank">Get in touch</a> and we’ll be happy to start that conversation.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:5:{i:0;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:7:"Defense";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:7:"V-Armed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:16:"Sébastien Lozé";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 20:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 20:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:102:"https://www.unrealengine.com/spotlights/efficient-police-virtual-training-environment-in-vr-by-v-armed";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:102:"https://www.unrealengine.com/spotlights/efficient-police-virtual-training-environment-in-vr-by-v-armed";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:17;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:72:"Exploring SculptrVR’s efficient lighting solution for the Oculus Quest";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:212:"https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTechBlog_SculptrVR_THUMB_ALT-375x275-b4519eddd3766ade6843fe4ecc958054dcc50f75.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:110:"SculptrVR creator Nathan Rowe shares how he optimized the VR app’s lighting solution for the Oculus Quest. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:9907:"Hi, I’m Nathan Rowe and I’m the creator of <a href="http://www.sculptrvr.com/" target="_blank">SculptrVR</a>, which is a multiplayer voxel sculpting application for virtual reality. The app has been released on SteamVR, Oculus Rift, PlayStation VR, and recently, mobile standalone VR headsets like the Oculus Quest and Oculus Go. Comparatively speaking, the Quest has a limited graphical computing budget and, as a result, a new, efficient lighting solution had to be made to achieve optimal performance.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/_GEUa6_NKk4" width="100%"></iframe></div>
Voxel sculpting is notorious for high-poly-count models. SculptrVR’s octree system produces reduced triangles, but it’s still a large number. To have a good experience, SculptrVR needs to be able to push a lot of triangles on screen. On Quest, I get up to 350,000 triangles and maintain a rock steady 72 fps stereoscopic. Unfortunately, this makes the default UE4 lighting model a bit too expensive. 

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_Mobile-Lighting-Liz-Bust.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_Mobile-Lighting-Liz-Bust-1000x1000-19904ad511e9f90fd8e1c7aee92cf1800db254fe.jpg" width="auto" /></div>

<div style="text-align: center;"><em>A model created in SculptrVR and rendered using the efficient mobile lighting described in this article.</em></div>
<br />
The simple default lit shader that just takes a color and drags it into <a href="https://docs.unrealengine.com/en-US/Resources/ContentExamples/MaterialNodes/1_1/index.html" target="_blank">Base Color</a> is hundreds of operations. Even with “fully rough” checked, a default lit <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/index.html" target="_blank">Material</a> can only afford to render about 50,000 triangles on screen on the Quest. This was not enough to get a good experience sculpting.<br />
<br />
So, instead of using the default UE4 lighting, I built my own phong lighting by using unlit <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/HowTo/EmissiveGlow/index.html" target="_blank">Emissive Materials</a>. This Material looks expensive, but is only 17 operations.

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial-1395x839-2571085d48861071662a791b710dafc3247ccf5c.png" width="auto" /></div>
Want to see how this works and perhaps use it yourself? Here&#39;s a pastebin link: <a href="https://blueprintue.com/blueprint/1gp1z-xh/" target="_blank">https://blueprintue.com/blueprint/1gp1z-xh/</a> <br />
<br />
Let’s go through what’s happening here:<br />
<br />
First, notice that three different Material types are supported: clay, metal, and glowing. Clay is emulating a fully rough Material, metal is shiny and reflective, and glowing is clay plus a constant glow amount. The Material type is encoded in the 8-bit ambient channel of each vertex color.<br />
<br />
The world is lit by a single directional light and an ambient skybox (the skybox in SculptrVR is actually using the same ambient section code, but with slightly different constants). I am using <a href="https://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_reflection_model" target="_blank">Blinn-Phong lighting</a> to get diffuse lighting with a specular highlight, and to that I’m adding ambient light from the analytical skybox.<br />
<br />
The result of this gets multiplied by a vertex color and a per-vertex <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/AmbientOcclusion/index.html" target="_blank">ambient occlusion</a> (AO) term. The AO term is computed on the CPU for each vertex using a custom variant of voxel cone tracing.<br />
<br />
Let’s go through each of the lighting components:
<h3><strong>Diffuse:</strong></h3>

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial_Diffuse.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial_Diffuse-1049x387-c59eb86f807c53aa0c4e25e4983d9cd421982ef1.png" width="auto" /></div>
Diffuse lighting is independent of camera position, and is completely determined by the sun position. So all we do here is dot product the sun direction with the surface normal. The final result here ranges from 0.2 to 1.0 for clay, and .05 to 0.25 for metal. Theoretically, purely metallic surfaces shouldn’t have any diffuse lighting, but adding a bit of diffuse light helps the eye to better understand the shape, which is important in a sculpting application.

<h3><strong>Specular: </strong></h3>

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial_Specular.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial_Specular-1128x448-0d77d1f2ae2b7a49b82e70cbc40591fddc4d05a2.png" width="auto" /></div>
Specular light just shows the reflection of the sun on the surface of objects. The sharpness of the highlight is usually based on roughness, and with Blinn-Phong lighting, you simply raise the dot product to different powers to adjust sharpness. Here the power is 6 for clay and 64 for metal. We also adjust the max specular brightness up and down for metal/clay.

<h3><strong>Ambient: </strong></h3>

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial_Ambient.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial_Ambient-1455x804-2c462a616df16d25f0fe64c8734be6bd0c583dcb.png" width="auto" /></div>
The ambient lighting is my attempt at adding an efficient “skylight” equivalent to the shader. The top three comment boxes are interpolating between the sky color and the ground color based on the Z coordinate of either the surface normal (for clay) or the reflection vector (for metal). The interpolation is sharpened by multiplying that Z coordinate by a constant. The fourth comment box is adding in a horizon line when that Z coordinate is near zero. The horizon line is absolutely crucial for giving a sense of shape to metallic shiny objects.

<h3><strong>Emissive: </strong></h3>

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial_Emissive.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial_Emissive-536x272-e0fd27cc75c57ac3ea68dc33fc14f4a8c674afb4.png" width="auto" /></div>
Emissive light is completely view independent and simply adds a base amount to every glowing pixel. In SculptrVR, the “GlowMultiple” parameter is oscillating to provide a blinking look. That oscillation is controlled by the CPU in a <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprint</a>. Doing it on the CPU once saves a few operations that would have been redone on millions of pixels.

<h3><strong>Total Lighting:</strong></h3>

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_LightingFunctionMaterial_Combining.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_LightingFunctionMaterial_Combining-675x388-a89657579809d6e1e986a2262f9d5a7cdfa83b07.png" width="auto" /></div>
Diffuse, Specular, and Ambient light get summed together and multiplied by the sun color to control brightness for day/night, and then Emissive light gets added in after that.

<h3><strong>Adjusting the Parameters for a Dynamic Sky</strong></h3>
The Sun Position, Sun Color, Zenith Color, Horizon Color, and Ground Color are all dynamically changed as you move around the sun as seen below

<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/x-GW5JWNkj4" width="100%"></iframe></div>
The colors are all stored in curve tables based purely on the z-component of the sun’s direction. Those tables were hand tuned to provide good brightness and contrast with SculptrVR’s color palette.

<div style="text-align: center;"><img alt="Tech-Blog_ScupltVR_Mobile-Lighting.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Ftech-blog%2Fexploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest%2FTech-Blog_ScupltVR_Mobile-Lighting-1347x720-b8d48fc8443c854539f8f04acdd6d32e5d9ee00f.jpg" width="auto" /></div>

<div style="text-align: center;"><em>Seen above: White metal, green glowing, and cyan clay Materials. Note how much shape information you can perceive despite the objects being solid colors.</em></div>
<br />
In SculptrVR, every single Material is emissive and uses this Material function to multiply in lighting. Some Materials/models use vertex colors, some are textured, but they all get consistent lighting.<br />
<br />
I hope you found this useful and can either make use of it directly or make your own variant with this as a starting point. Thanks for reading.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:9:{i:0;a:5:{s:4:"data";s:3:"Art";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:8:"Learning";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:6:"Mobile";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:14:"Product Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:7;a:5:{s:4:"data";s:13:"Visualization";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:8;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:33:"Creator of SculptrVR Nathan Rowe ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 19:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 19:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:109:"https://www.unrealengine.com/tech-blog/exploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:109:"https://www.unrealengine.com/tech-blog/exploring-sculptrvr-s-efficient-lighting-solution-for-the-oculus-quest";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:18;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:75:"A family bands together to develop pirate battle royale game Blazing Sails ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:241:"https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fa-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails%2FDeveloper-Interview_BlazingSails_Thumb-Alt-375x275-65da08865055827e9109af78d00819dfd0433f97.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:134:"With a highly experimental approach, Get Up Games sharpens their Unreal Engine skillset to develop a pirate-themed battle royale game.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:11690:"While many small studios are tight knit and consider employees members of the family, Get Up Games literally consists of developers who are all related to each other, specifically four cousins who are two sets of brothers. After a lot of iterating with Unreal, the pair stumbled upon a unique blend that they thought would be compelling: pirates and battle royale games. Thus, the idea for <a href="https://www.blazingsails.com/" target="_blank">Blazing Sails</a> was born. <br />
<br />
In Blazing Sails, players will team up with other players to sink other ships on their quest to be the last pirate crew standing. Whether playing solo or with a crew of a variety of sizes in different types of ships, you’ll be able to respawn and keep fighting as long as your ship isn’t destroyed. To give themselves a better shot at victory, players navigate sea and land as they seek out resources, weapons, and upgrades for their vessels.<br />
<br />
The ragtag Get Up Games crew hit some rough waters along the way and had to iterate on their project multiple times. They took some time to discuss how they got a better grasp of Unreal Engine throughout the process, share the inspiration behind the project, and elaborate on the landscaping tools that allowed them to build their environments.
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/-HWdXgemTuE" width="100%"></iframe></div>
<strong>How did the team learn to use UE4 when starting the development process?<br />
<br />
Technical Artist Gaetan Thibaut:</strong> First of all, Unreal Engine was well taught to us at Digital Arts and Entertainment in Kortrijk, [which was] the school the three developers went to a few years ago. Next to that, we learned a lot as well by making our own prototypes. A general curiosity motivated us to keep messing around in Unreal. The engine allowed us to easily convert ideas into real-time game concepts. While learning and working with Unreal, we constantly pushed the limits of what we thought was possible. The engine keeps amazing us with how far you can actually go with a modern game. We realize that without the current engine technology, we wouldn’t have been able to make Blazing Sails. Especially with only three developers. It’s really assuring to know that game ideas aren’t held back anymore by a lack of accessible, powerful engine software.<br />
<br />
<strong>What was a key moment in Blazing Sail’s development or conceptualization that made the team believe they had something really appealing with the game?<br />
<br />
Game Designer Frederic Degraeve: </strong>Before we started on Blazing Sails, we made a few prototypes. One of these prototypes was called “Skulls and Timber.” This prototype was created by the initial main developers/brothers, which include Programmer Frederic Degraeve and Artist Christophe Degraeve. The game was originally meant to be a pirate survival game (kind of like Rust in a pirate universe). After half a year of developing this prototype, it became clear that the idea was just too labor-intensive with only two developers. One thing we did learn from playtesting this prototype was that naval pirate combat was very fun. This was a key realization. So, we decided this would be the main focus of our final product. Next, we looked at the new battle royale trend that was then booming. We immediately realized this would be a great fit for Blazing Sails. So, the concept that we’re currently developing was born.<br />
<img alt="Developer-Interview_BlazingSails_image04.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fa-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails%2FDeveloper-Interview_BlazingSails_image04-1920x1080-1a91a1bf260a9f6ee5c3e658b15ee1c424aac9fa.jpg" width="auto" /><br />
<strong>What Unreal tools helped the team create Blazing Sails’ environments?<br />
<br />
3D Artist Christophe Degraeve: </strong>By using Unreal, we had access to the handy <a href="https://docs.unrealengine.com/en-US/Engine/Landscape/Creation/index.html" target="_blank">landscaping tools</a> where we could easily make independent islands. By isolating all our islands in sublevels, we could effortlessly work on the world with multiple people at a time. Unreal allows us to make well-optimized maps, but also keeps everything modular without sacrificing performance. Combine this with the easy-to-use <a href="https://docs.unrealengine.com/en-US/Engine/Foliage/index.html" target="_blank">foliage tools</a> and you have everything you need to build the base of a typical Blazing Sails island.<br />
<br />
<strong>How did you use Unreal Engine for cloud and wind generation? Will clouds impact gameplay?<br />
<br />
Gaetan: </strong>The clouds are purely visual. And just a panning skybox texture which really fits well in the stylized setting. We experimented a bit with 3D clouds, but it didn’t really fit the look and feel of Blazing Sails. However, there is a dynamically changing wind. Players have to adjust the angle of their sails to catch as much wind as possible in order to gain speed. The wind direction is also visually represented by translucent lines when manning the sails.<br />
<img alt="Developer-Interview_BlazingSails_image10.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fa-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails%2FDeveloper-Interview_BlazingSails_image10-1920x1080-6ec5b538a8a3e63e2f1c97fdf08061e1894f6ef7.jpg" width="auto" /><br />
<strong>What inspired the team to create a battle royale pirate game as opposed to something focused on exploration?<br />
<br />
Frederic:</strong> One thing we all agreed upon after making the first prototype is that we wanted to make Blazing Sails a pure multiplayer PvP game. Mainly because we, ourselves, as gamers enjoy online multiplayer games the most. The four people currently working at Get Up Games (three developers and one community manager) are all cousins and/or brothers. We grew up playing lots of multiplayer games together like: Counter Strike, Halo CE, Battlefield Heroes, etc. With Blazing Sails, we wanted to make a game we would like to play ourselves. Also, exploration type games are really content driven. This takes a lot of manpower or time to develop. Considering we’re a team with only three developers, that’s not really an option. The reason we eventually decided to go with battle royale was because the naval combat and island looting fit perfectly within this game mode. We played and enjoyed battle royale games quite a bit and know we can’t just make another BR game and expect [it to stand out]. Blazing Sails refreshes the genre in a positive way. It’s a concept you’re familiar with and yet feels like something completely new.<br />
<br />
<strong>What type of research and development process results in a weapon as curious as the fish launcher? Is there a level of wacky the team won’t go?<br />
<br />
Community Manager Gauthier Thibaut: </strong>Blazing Sails is set in a pirate fantasy world. This, of course, opens up a lot of possibilities for crazy weapon ideas. The fact that we’re also going for a more cartoony, stylized look also works really well with the fantasy pirate genre in our opinion. Next to that, we thought it was important to have a lot of weapons in Blazing Sails. Mainly because this adds replay value and makes the game just overall more fun. We received some really good weapon ideas from our <a href="https://discordapp.com/invite/2D5CQNH" target="_blank">Discord</a> community and recently even added the “sword of the sea,” a vampiric sawfish inspired sword a community member recently suggested. The only rule [we have] is that the weapons need to stay “piraty.” Other than that, there isn’t really a level of wacky we won’t go.<br />
<br />
<strong>How much did prior experience with the engine shape some of the decisions made for Blazing Sails?<br />
<br />
Frederic: </strong>As mentioned before, we built all our prototypes in UE4. We basically started the whole project three times. So, a lot of lessons were learned along the way. The main lesson being structure and know-how. In the early prototypes, we used a lot of workarounds which ended up causing problems in the long run. At this point, we can say confidently that we know Unreal Engine quite well. All <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprints</a> are well structured and modular, which is important if you want to make changes and add new things in the future.<br />
<img alt="Developer-Interview_BlazingSails_image05.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fa-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails%2FDeveloper-Interview_BlazingSails_image05-1920x1080-218a9df25cdfb5c0caa3e3b44bcb460a25d967d2.jpg" width="auto" /><br />
<strong>In a pirate game like Blazing Sails, the water itself can essentially be its own character. Were there any Unreal Engine tools that were helpful here?<br />
<br />
Gaetan: </strong>We’re actually reworking the water at the moment. The ability to write <a href="https://docs.unrealengine.com/en-US/Programming/Rendering/ShaderDevelopment/index.html" target="_blank">shaders</a> visually is an amazing asset to the engine and helped us a ton in creating the stylized water. The ability to iterate quickly and the extensive library of shader nodes was an essential part for creating something as complex as our water shader. Next to this, the ability to easily transfer variables to shaders with the help of parameter collections and dynamic <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/index.html" target="_blank">Materials</a> was important as well.<br />
<br />
<strong>What classic pirate tales, across any media format, did the team take inspiration from when conceptualizing Blazing Sails?<br />
<br />
Frederic: </strong>We’ve always been a huge fan of the Pirates of the Caribbean movies. Whenever the newest part of the franchise came out, we went to watch it together in the theatre. Also, Cutthroat Island, Master and Commander, but even The Goonies, Peter Pan, and Sinbad were movies we really enjoyed. We also drew some inspiration from the series Black Sails.<br />
<img alt="Developer-Interview_BlazingSails_image02.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fa-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails%2FDeveloper-Interview_BlazingSails_image02-1920x1080-4362e866ec94acd87481c112e4e3df05c5be8306.jpg" width="auto" /><br />
<strong>If you want to learn more about Blazing Sails, you can follow the game at:</strong><br />
 
<ul style="margin-left: 40px;">
	<li><a href="https://www.facebook.com/getupgamesofficial" target="_blank">Facebook</a></li>
	<li><a href="https://twitter.com/get_up_games" target="_blank">Twitter</a></li>
	<li><a href="https://www.youtube.com/channel/UCwGOn0dHC9poK-7w8NhyPwg?view_as=subscriber" target="_blank">YouTube</a></li>
	<li><a href="https://www.instagram.com/getupgames/" target="_blank">Instagram</a></li>
	<li><a href="https://www.reddit.com/r/BlazingSails/" target="_blank">Reddit</a></li>
	<li><a href="https://discord.gg/blazingsails" target="_blank">Discord</a></li>
	<li><a href="https://store.steampowered.com/app/1158940/Blazing_Sails_Pirate_Battle_Royale/" target="_blank">Steam</a></li>
</ul>
";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:6:{i:0;a:5:{s:4:"data";s:3:"Art";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:10:"Blueprints";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:13:"Blazing Sails";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:12:"Get Up Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:22:"Charles Singletary Jr.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 27 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:124:"https://www.unrealengine.com/developer-interviews/a-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:124:"https://www.unrealengine.com/developer-interviews/a-family-bands-together-to-develop-pirate-battle-royale-game-blazing-sails";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:19;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:67:"Real-time visualization transforms Daimler’s engineering pipeline";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:211:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Buildmedia_blog_thumb-375x275-373030e4c7e1e0405e14d95d1fd673638edef6a2.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:173:"Daimler creates a multi-user, online environment for engineers, providing virtual reality walkthroughs and real-time 3D visualizations that slash development time and costs.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:7794:"The automotive industry has long been using game engine technology for visualization. Many of the key players have harnessed it to <a href="https://www.unrealengine.com/en-US/spotlights/creating-a-digital-showroom-audi-and-mackevision-choose-ue4" target="_blank">power their digital showrooms</a>. But the configurators used by car salespeople to demonstrate different paint finishes and interiors only appear at the very end of the automotive pipeline. There’s an untapped ocean of potential for real-time technology earlier on, during the design and engineering phases.  <br />
<br />
And we’re not just talking Cave Automatic Virtual Environments (CAVEs) here—the physical projection spaces that some manufacturers have previously used for VR testing of design and safety. Today’s design and engineering teams at forward-thinking automotive manufacturers are visualizing, iterating, and collaborating on vehicle designs in VR, from anywhere in the world. <br />
<br />
German car giant <a href="https://www.daimler.com/en/" target="_blank">Daimler AG</a> is a place where the future of automotive engineering is playing out right now. Its 3D and digital data arm, <a href="https://www.daimler-protics.com/" target="_blank">Daimler Protics</a>, has created a multi-user, online environment for engineers, built on Unreal Engine. This innovation is already being used across the company to provide virtual reality walkthroughs and real-time 3D visualization, slashing development time and costs, and helping to deliver higher-quality product. <br />
<img alt="Spotlight_Daimler_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Daimler_blog_body_img1-1640x1000-27fc89e7857b94eeca09db2889d77680b49b8718.jpg" width="auto" />
<h3><strong>A multiplayer real-time game for engineers</strong></h3>
Daimler Protics is a subsidiary of Daimler AG, employing over 600 people across three locations in the fields of product data management (PDM) and software development. It supports and advises the corporation on everything from design and optimization to processes and systems, leveraging complex product data to create digital innovations that lay a path for the business’s future.<br />
<br />
Daimler had been using UberEngine, a technical 3D CAD renderer created by NetAllied Systems, to give engineers a quick look at large CAD datasets and make inspections of vehicle designs. Daimler Protics had the idea of leveraging the core functionality of a game engine to open up the engineering visualization process, and asked NetAllied to <a href="https://uberengine.com/#" target="_blank">develop a plugin</a> to integrate UberEngine into Unreal Engine.<br />
<br />
“Basically, we’ve created a multiplayer online game for engineers,” says J&uuml;rgen Riegel, Project Lead and Principal Software Architect on the company’s UE4-based VR collaboration environment called <a href="https://www.daimler-protics.com/landing-pages/index-2.html" target="_blank">Engineering Hub</a>. “We needed a solution that would enable an engineer to load CAD data directly into a game session. We used a tool developed by NetAllied to inject a CAD render into the Unreal Engine render pipeline. That lets us have a fully Unreal network game and load 3D data directly from the PDM system at runtime—no data prep necessary.”<br />
<br />
The results have been transformational. Whereas previously Daimler’s engineers merely had a fast way to see CAD data, now they have that and all the real-time, interactive functionality of a game engine on top.<br />
<img alt="Spotlight_Daimler_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Daimler_blog_body_img2-1640x1000-0860c84f3ba33252c538cf720082aad41db0a146.jpg" width="auto" /><br />
Relying solely on 2D screens to communicate and visualize designs has become a thing of the past. Engineers have the option to put on a VR headset and interact with the design at full scale in a fully immersive environment. 
<h3><strong>Fixing engineering problems using real-time visualization</strong></h3>
The innovation has not only had an impact on accuracy, but also on output. “Engineers love to see the data in an HMD,” says Riegel. “It’s much easier to judge sizes and assess problems if you see them with your own eyes. Also the ability to do an ad-hoc collaborative session with your data increases productivity.”<br />
<img alt="Spotlight_Daimler_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Daimler_blog_body_img3-1640x1000-a9c2c7af71b9241877e467d5698325ed0fbae6ff.jpg" width="auto" /><br />
With design and engineering teams located in different parts of the world, having this means of multi-user collaboration in a shared immersive environment that&#39;s accessible from anywhere has been a huge win.<br />
<br />
Teams no longer have to wait for feedback via email or phone calls. Reviewing work, sharing ideas, and fixing issues can now happen on the spot, collaboratively in real time. As well as supercharging creativity and efficiency, this also has a significant effect on the bottom line. “There are massive timesaving and ROI benefits from taking this approach to visualization,” says Riegel. “We have such a diverse design process around the world. Reducing travel costs and removing barriers to fast problem solving with 3D data is a big time and cost saver.” <br />
<img alt="Spotlight_Daimler_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Daimler_blog_body_img7-1640x1000-061cf5f5adfd80149d1d11d1eb346512038e19f4.jpg" width="auto" /><br />
With production facilities and R&D teams spread across the world, complex technical conversations about 3D data often have to be held via Skype. “But that’s a poor medium for discussing 3D data,” says Riegel. “So we aim to become ‘Skype for 3D’ ”.<br />
<br />
Now, Daimler teams in 30 locations around the world have the capability to collaborate, review, and provide feedback in real time, with an increasing number of VR review sessions taking place across Germany, USA, India, and China. Since January 2019, Engineering Hub has been directly integrated with Daimler’s PDM system, and there have been discussions around rolling out the solution for <a href="https://youtu.be/11I5Ryz4Ce8" target="_blank">Spectator Screens</a>, which could put these visualizations in front of tens of thousands of the company’s PDM users. <br />
<img alt="Spotlight_Daimler_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Freal-time-visualization-transforms-daimler-s-engineering-pipeline%2FSpotlight_Daimler_blog_body_img4-1640x1000-4ce9ee56fc4ace6318b2ce415f14dcfdafa9271f.jpg" width="auto" /><br />
The power of real-time technology has enabled Daimler to remove the silos and guesswork that can hinder productivity, driving them towards a more agile and collaborative engineering process. Their Engineering Hub is already productively used in many cases across the corporation—and it’s just the beginning.<br />
<br />
<br />
Want the latest news on real-time automotive projects sent straight to your inbox? Take a look at our most recent articles and <a href="https://www.unrealengine.com/en-US/industries/automotive" target="_blank">sign up</a> for our automotive newsletter today. <br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:7:{i:0;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:7:"Daimler";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:6:"Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:13:"Manufacturing";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:4;a:5:{s:4:"data";s:14:"Product Design";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:5;a:5:{s:4:"data";s:2:"VR";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:6;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:10:"Doug Wolff";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 26 Nov 2019 17:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 26 Nov 2019 17:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:105:"https://www.unrealengine.com/spotlights/real-time-visualization-transforms-daimler-s-engineering-pipeline";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:105:"https://www.unrealengine.com/spotlights/real-time-visualization-transforms-daimler-s-engineering-pipeline";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:20;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:60:"Enjoy up to 70% off during the Marketplace Black Friday Sale";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:195:"https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fenjoy-up-to-70-off-during-the-marketplace-black-friday-sale%2FNews_BlackFriday_blog_thumb-375x275-3a2a5f911b75cf63b50abdcecb3945cabcc5b8a1.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:102:"Treat yourself with up to 70% off thousands of Unreal Engine Marketplace products this holiday season!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:896:"‘Tis the season of savings and we’re ready to kick off the festivities! Starting today, take up to 70% off on just under 5,000 Unreal Engine Marketplace products during this year’s <a href="http://epic.gm/eventsale" target="_blank">Marketplace Black Friday Sale</a>! 
<div style="text-align: center;"><img alt="News_BlackFriday_blog_body_img1.jpg" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fblog%2Fenjoy-up-to-70-off-during-the-marketplace-black-friday-sale%2FNews_BlackFriday_blog_body_img1-1640x1000-f53e73ab1a6807f9e75335526c548eb009f707a3.jpg" /></div>
The Marketplace Black Friday Sale runs now through December 4 at 11:59 PM EST. <br />
<br />
We would like to extend our thanks to all of the Marketplace creators that have supported the Unreal community throughout the year and helped to make 2019 our best year yet.<br />
<br />
Happy holidays and happy shopping!<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:4:"News";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:13:"Amanda Schade";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 26 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Tue, 26 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:93:"https://www.unrealengine.com/blog/enjoy-up-to-70-off-during-the-marketplace-black-friday-sale";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:93:"https://www.unrealengine.com/blog/enjoy-up-to-70-off-during-the-marketplace-black-friday-sale";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:21;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:103:"CM Labs links best-in-class real-time toolsets for highest-fidelity engineering and training simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:245:"https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_thumb-375x275-1e1ae7fc5f26624bf9d7380602bbe856e5ee4f99.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:239:"When CM Labs wanted to take its vehicle and equipment training simulators to the next level in terms of VR support, graphics, and gameplay, it developed an integration between Vortex Studio, its high-fidelity simulation, and Unreal Engine.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:11415:"Vehicles, heavy equipment, logistics machines, deep-sea robots, and even planetary rovers are all mechatronics systems—integrated mechanical and electronic equipment, typically mobile, that interacts with its environment and workspaces in complex ways. Because this type of machinery is expensive to build, often deployed in hazardous situations, and potentially dangerous to use, it’s paramount that its design is fully optimized for safety and that operators have comprehensive training. One way to reduce costs and the time it takes to design machines and train operators to use them is through ultra-realistic real-time simulations.<br />
<br />
Developing some of the most trusted land and sea simulators in the industry, <a href="https://www.cm-labs.com/" target="_blank">CM Labs Simulations</a> provides capabilities for training, mission rehearsal, <a href="https://en.wikipedia.org/wiki/Serious_game" target="_blank">serious games</a>, virtual prototyping, and product testing.
<h2>Providing both pre-built simulators and simulation software for custom solutions</h2>
Over the past two decades, CM Labs has built a name for itself in the simulation industry by creating highly accurate, ready-to-go interactive simulators for engineering and operator training purposes. As such, CM Labs has provided over 1,000 simulators to customers in over 30 countries.<br />
<br />
However, what may not be immediately obvious is that all of CM Labs’ simulators are built on a common, powerful platform, Vortex Studio. This advanced suite of real-time simulation and visualization software is used by the CM Labs team and customers alike to create and deploy simulators of their own.<br />
<img alt="Spotlight_CMLabs_blog_body_img2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img2-1640x1000-ffd014e895c69710289b16b64bb86a857bdc8ba8.jpg" width="auto" /><br />
Off-highway engineers use simulations built in Vortex Studio to visualize heavy equipment in real time. Marine engineers have developed simulators that solve the challenges of designing and testing equipment for offshore and subsea operations. Robotics engineers test and refine real-time simulation of grasping, access, and other task-based robotic applications. The software is also widely used in the defense industry for high-fidelity training for vehicle, heavy equipment, and maritime operations.<br />
<br />
“Vortex Studio is powered by a validated multi-body dynamics engine. It simulates machines in real time and at a very high fidelity,” says Arnold Free, Chief Innovation Officer and Co-Founder of CM Labs. “In training situations, you can build real skills, because the training simulator is based on a very realistic representation of how that real machine performs. Those skills are then transferable to the physical equipment.”
<h2>High-fidelity physics modeling and simulation </h2>
The simulators that CM Labs produces achieve such a high fidelity because they simulate the fundamental physics of the machine and its environment, accurately predicting its behavior. This produces a much more realistic representation of how the machine will act in real life. <br />
<br />
“We model the machine in engineering terms. For example, with a vehicle like a truck, we know the engine has a torque curve and a powertrain, and there are wheels, which have particular properties and contact with the terrain,” says Free. “Or if it&#39;s a crane, it has winches and cables and each cable has specific engineering properties. The simulation is constructed based on those properties, and any behavior in the simulation emerges based on the model built, just like the real machine. So there&#39;s nothing pre-scripted—it&#39;s emergent behavior based on the engineering model.”<br />
<img alt="Spotlight_CMLabs_blog_body_img3.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img3-1640x901-9c60becb24dda1a5a4ed1fed7be3f35001edae47.jpg" width="auto" />
<h2>The growing demand for VR-based engineering and training </h2>
The mechatronic models for CM Labs’ simulators are created in Vortex Studio’s integrated editor application. This editor is used to create and test the models of the vehicles, robotics, or heavy equipment to be simulated. The software comes with a built-in visualization engine, but this engine is focused on specific applications and therefore lacks some features that could be useful for both customers and for the development of the team’s own simulators—including for specific VR devices.<br />
<br />
“We&#39;re seeing more and more interest in the industry for VR-based engineering and training solutions,” says Free. “It&#39;s faster to build an immersive environment around a VR headset than using lots of monitors.<br />
<img alt="Spotlight_CMLabs_blog_body_img8.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img8-1640x931-e99e968d3f79b9f74440f5f9c56b4a7772466e34.jpg" width="auto" /><br />
“We wanted to build a VR-based training solution with rich visuals, and the fastest and easiest way we thought to do that was with Unreal Engine,” he continues.
<h2>Leveraging the respective strengths of different best-in-class toolsets</h2>
To achieve this, the team at CM Labs developed a plugin that connects the powerful high-fidelity data coming from Vortex Studio to Unreal Engine using Blueprint as a gateway. From here, all the gameplay, graphics, and VR capabilities of Unreal Engine could be tied to Vortex Studio’s mechanical engineering workflow.<br />
<br />
By linking the technologies, CM Labs provides a solution that leverages the strengths of each. “We didn&#39;t want to completely replace our engineering-driven workflow, but we wanted to access this great workflow in Unreal—we wanted to bring together the best of those two worlds,” says Free. <br />
<br />
The well-established workflow in Vortex Studio enables mechanical engineers to build high-fidelity simulations of machines. Vortex Studio also provides essential pieces to integrate other simulation engines, hardware-in-the-loop, as well as a networking framework to connect hardware, software, consoles, and databases. Combined with the gameplay and visualization workflows in Unreal Engine, CM Labs can provide best-of-class tools to develop simulation solutions and implement them in VR or with conventional displays. <br />
<img alt="Spotlight_CMLabs_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img1-1640x878-c8f5492c60649de9e3d73f0c93f5413f2d4913b4.jpg" width="auto" /><br />
This ability to connect together the leading tools on the market addresses one of the top priorities for CM Labs’ customers. “If you look at either the engineering market or the training market, what our users want to do is bring together the best-of-class tools needed to build a best-in-class solution,” says Free. “Vortex Studio makes it very easy to connect the pieces.”<br />
<br />
Those pieces range from 1D tools like <a href="https://www.mathworks.com/products/simulink.html" target="_blank">MathWorks Simulink</a> to simulate a control system, to physical controls like OEM joysticks, and networking protocols like UDP. “That&#39;s really where we see Vortex Studio adding a lot of value, by making it easy to plug all these pieces together and build simulations on the desktop or deploy a physical simulator,” says Free. 

<h2>Building a next-generation vehicle assessment simulator for NATO</h2>
The fidelity and realism achievable in Vortex Studio has caught the attention of some high-profile organizations. CM Labs has been collaborating on a NATO program called the <a href="https://www.youtube.com/watch?v=JxZAMUZE37k" target="_blank">Next Generation NATO Reference Mobility Model</a> (NG-NRMM), the objective of which is to find the next generation of simulation tools to be used for mobility assessments of military vehicles across vastly different terrain types. <br />
<img alt="Spotlight_CMLabs_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img7-1640x875-17bc22af85e0f50f3bcf7e43b4aad42de676cce8.jpg" width="auto" /><br />
“This is an essential program. If a vehicle can’t maneuver, then missions are jeopardized, and lives can be lost,” recalls Free. “NATO actually instrumented the vehicle, drove it through standardized tests, collected that data, and then used that to compare it to a simulation of the vehicle.”<br />
<br />
Tools from around half a dozen vendors were tested to find out how useful they were for assessing a vehicle&#39;s performance and mobility, including Vortex Studio. “All the other tools took hours to compute a minute or two of simulation data, whereas we were simulating everything in real time, and we’re proud to say, we still came either first or second in terms of matching NATO test data,” says Free. “That&#39;s our strength—interactive real-time—which is why there&#39;s a logical connection with visual engines such as Unreal to create immersive simulations.”<br />
<img alt="Spotlight_CMLabs_blog_body_img5.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fspotlights%2Fcm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation%2FSpotlight_CMLabs_blog_body_img5-1640x905-f95b146fed0f8be358d68a148f0922d353d531d0.jpg" width="auto" />
<h2>Making an open, extendable connection engine integration</h2>
CM Labs plans to make the plugin that integrates Vortex Studio with Unreal Engine freely available in the coming months through the <a href="https://www.unrealengine.com/marketplace/en-US/store" target="_blank">Unreal Engine marketplace</a>, along with its source code—an idea that’s a great fit with Unreal Engine’s open philosophy.<br />
<br />
“It’s a good example of how to integrate Vortex Studio into another engine,” says Free. “By providing the plugin as an open source download, it could be also extended if someone has software engineering skills.”<br />
<br />
Interested parties can <a href="https://info.cm-labs.com/vortex-studio-unreal" target="_blank">register to be notified</a> when the source code and plugin are available to download. The Vortex Studio for Unreal Engine integration requires both the plugin and an active Vortex Studio license (2019c or greater).<br />
<br />
<br />
Are you interested in finding out what Unreal Engine can bring to simulation training in your industry? <a href="https://www.unrealengine.com/en-US/enterprise/contact-us" target="_blank">Contact us</a> and we’ll get that conversation started.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:27:"Automotive & Transportation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:7:"CM Labs";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:13:"Vortex Studio";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:16:"Sébastien Lozé";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 25 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Mon, 25 Nov 2019 15:00:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:143:"https://www.unrealengine.com/spotlights/cm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:143:"https://www.unrealengine.com/spotlights/cm-labs-links-best-in-class-real-time-toolsets-for-highest-fidelity-engineering-and-training-simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:22;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:49:"The Coalition dives deep into the tech of Gears 5";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:194:"https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FTHUMBNAIL_Gears5Tech-375x275-31290e96983a26e01acf6fc6427d520fb92c7bcd.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:188:"The Vancouver-based studio reveals how they delivered Gear 5&#39;s state-of-the-art-graphics and open-world segments while providing tips on how to maintain smooth, consistent performance.";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:40748:"While <a href="https://gearsofwar.com/games/gears-of-war-4" target="_blank">Gears of War 4</a> was <a href="https://thecoalitionstudio.com/#Home" target="_blank">The Coalition’s</a> first game in the long-running franchise, it wasn’t until the developer’s second installment, <a href="https://www.gears5.com/" target="_blank">Gears 5</a>, that the studio was able to effectively make it their own. Interviewing several members from the Vancouver, Canada-based company, they talk about how Gears of War 4 allowed them to lay the foundation to achieve Gears 5’s monumental goals, which improves upon its predecessors with refined graphics, new open-world sections, revamped AI, and more. The culmination of their hard work has resulted in great reviews and <a href="https://www.unrealengine.com/en-US/events/e32019/unreal-e3-awards-2019---eye-candy" target="_blank">one of the best looking games</a> made yet. <br />
<br />
We caught up with the studio to discuss how they leveraged Unreal and source-code access to deliver best-in-class post-processing effects, particles, and volumetric lighting while achieving 60 fps on the Xbox One X. Speaking to how they achieved smooth and consistent performance across a wide variety of hardware platforms, they share how they elegantly leveraged tools like HLOD to allow more draw calls, which enabled them to develop the game’s highly detailed and diverse environments. <br />
<br />
Considering Gears 5 features some of the highest fidelity character models seen in a game to date, we also discuss how they used dual lobe specularity, backscattering, and sophisticated eye rendering features coupled with leading animation techniques to deliver highly believable <a href="https://docs.unrealengine.com/en-US/Resources/Showcases/DigitalHumans/index.html" target="_blank">digital humans</a>. The Coalition also discuss some of the challenges they faced developing the game’s open-world segments, which are new to the franchise, and explain how they overcame these hurdles. 
<div class="embed-responsive embed-responsive-16by9"><iframe allowfullscreen="true" class="embed-responsive-item" frameborder="0" src="https://www.youtube.com/embed/KL3rSV-IJ20" width="100%"></iframe></div>

<div style="text-align: center;"><em>Watch "The Visual Technology of Gears 5" presentation from Unreal Dev Days 2019.</em></div>
<br />
<strong>With this being The Coalition’s second Gears game, how has development changed with Gears 5 compared to Gears of War 4?<br />
<br />
Campaign Design Director Matt Searcy: </strong>Gears of War 4 was really focused on proving we could make a great Gears game. It was important to us that fans saw The Coalition carrying the torch for the world, characters, and gameplay. A lot of our focus on that game was around gameplay hitting parity with Gears [of War] 3 (with a few tweaks) and developing new Gears combat, enemies, and modes around that core experience. <br />
<br />
In that sense, Gears of War 4 was really pre-production for Gears 5. We had confidence in our ability to make a great Gears game, and from the reviews and feedback we received, it was clear we hit that goal, and that the community wanted to see it pushed further.<br />
<br />
On Gears 5, we started with a directive to challenge expectations. It still needed to feel like a great Gears game, but our pre-production was focused on exploring new experiences and how they could fit with Gears. Features like Jack, the Skiff, and Escape pushed the design of the game to new places, while other disciplines were able to invest in new techniques and technology from the start. Without the foundation and expertise we developed on Gears of War 4, we could never have explored these in the time we had. <br />
 <br />
<strong>Gears 5 features an impressive array of visual effects that include per-object motion blur, screen space reflections, sophisticated depth-of-field effects, tessellation, and more. How did the team employ the elegant use of these <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/index.html" target="_blank">post-process effects</a>? <br />
<br />
Studio Technical Art Director Colin Penty:</strong> We employed these post-process effects very tactfully as we didn&#39;t want to compromise visual quality but still wanted to maintain 60 fps on Xbox One X. We integrated all the post-process effects we could from Epic&#39;s latest UE4 release into our own version of the UE4 engine, with the new Diaphragm <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/DepthOfField/CinematicDOFMethods/index.html" target="_blank">DOF</a> being the last post-process integration we did. <br />
<br />
In terms of how we used these post-process effects, we generally used the non-glossy high quality SSR in campaign wherever we could afford it on Xbox One (PC does glossy SSR). For <a href="https://docs.unrealengine.com/en-US/Resources/ContentExamples/MaterialProperties/1_8/index.html" target="_blank">tessellation</a>, we had our own custom async tessellation shader we created that we used almost exclusively on our snow and sand <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/index.html" target="_blank">Materials</a>. If you want to deform sand and snow dynamically around the player, tessellation is almost required to do that realistically unless you&#39;ve pre-tessellated your mesh extremely high. <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/Bloom/index.html" target="_blank">Bloom</a> was used liberally throughout the game, though we generally tried to avoid the tightest Bloom kernel as that one is quite expensive on GPU performance. We incorporated more camera exposure swing than Gears of War 4, allowing the camera to adjust to bright and dark areas of the map, though again being mindful of performance if we had areas of the game that didn&#39;t have a wide range of lighting values, we would lock the camera exposure to improve performance. Finally, we did a tuning pass across the game near the end for <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/PostProcessEffects/LensFlare/index.html" target="_blank">lens flares</a> and lens dirt.<br />
<br />
We also set up our post-process chain to run asynchronously over the next frame, which allowed us to claw some performance back. This made a lot of sense given our post-processing pass was quite expensive due to always outputting at native resolution. We leaned on UE4&#39;s temporal upscaling to scale the internal resolution of our base pass/lighting/translucency/etc. to maintain GPU performance.<br />
<img alt="Developer_Interview_Gears_5_004.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_004-3840x2160-398cbc866bfaf29e637861ed57b0d93ecd4fff4a.jpg" width="auto" /><br />
<strong>Gears 5 uses impressive lighting with volumetric lights and fog coupled with dynamic shadows. How did the team incorporate this?<br />
<br />
Penty:</strong> Our team was a big fan of the <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/VolumetricFog/index.html" target="_blank">Volumetric Fog</a> system added to UE4 and used it wherever we could. We created a <a href="https://docs.unrealengine.com/en-US/Engine/Blueprints/index.html" target="_blank">Blueprints</a> system that allowed us to place volume fog primitives throughout the level, which we will be discussing more in-depth at GDC 2020. I&#39;m proud of the volume fog quality we were able to achieve in the campaign while maintaining 60 fps on Xbox One X. <br />
<br />
For lighting, we made the decision to get away from using stationary lights, which we used a lot of on Gears of War 4. This allowed us to stop using shadow map textures for shadows saving us texture memory, speeding up our shader rendering, and allowed us to have full real-time shadows. We instead used <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/LightMobility/DynamicLights/index.html" target="_blank">Moveable Lights</a> for all of our lights in the game, with a small tweak where we allowed Moveable Lights to bake out indirect data using <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/Lightmass/index.html" target="_blank">Lightmass</a>. This all gets stored in our lightmaps, which are different than shadow maps in that they store all the color GI data, not shadows.<br />
<br />
Beyond our <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/LightingAndShadows/LightTypes/Directional/index.html" target="_blank">Directional Light</a> shadow cascades, we used distance field ray traced shadows to shadow the environment. This is where the lighting system used a distance field representation of the mesh as the shadow caster. Since this was only seen in the distance for us, we could afford to have the distance field representation not be super accurate to save some memory.<br />
<br />
Of course, it takes a talented lighting team to pull together all these technical elements and deliver some great looking visuals, which our team did an amazing job of.<br />
 <br />
<strong>The game features fantastic particle effects. How did The Coalition deliver on this front?<br />
<br />
Penty: </strong>Our VFX team delivered some amazing effects on Gears 5. This was especially challenging as consoles don&#39;t have the strongest CPUs, and VFX can really be taxing on a CPU. To get around this limitation, we created a new VFX system using the <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/Editor/index.html" target="_blank">Material Editor</a> called Swift Particles that allowed us to create VFX using vertex offsets in a shader that didn&#39;t have any CPU overhead. We primarily used Swift Particles for environmental VFX [such] as snow, dust, and rain. <br />
<br />
We made use of GPU particles wherever we could as well, though for certain more complicated effects, that was difficult to pull off. We added a "GPU Spawn" ability to UE4&#39;s particles that would allow the particles to spawn on the GPU as well. <br />
<br />
To keep our CPU performance in-check, our tech art team spent a lot of time working with VFX to ensure the particle counts and emitter counts were reasonable while also making sure we used Particle LODs. We essentially had to go back through our Gears of War 4 character and weapon VFX and re-optimize everything for Gears 5 as Gears of War 4 was a 30 fps game.<br />
<img alt="Developer_Interview_Gears_5_012.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_012-4096x2160-c0ae9312dc4101a2a09a6583b7ccdddffc69965e.jpg" width="auto" /><br />
<strong>The character faces in Gears 5 are fantastic with elegant uses of <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/HowTo/Subsurface_Scattering/index.html" target="_blank">subsurface scattering</a> and dual lobe specularity. Increasing fidelity even further, eyes also feature realistic light scattering. How did The Coalition manage to create the game’s beautiful digital human faces?<br />
<br />
Penty: </strong>Our character rendering and performance is probably one of the larger visual jumps over Gears of War 4. Once development on Gears 5 began, we immediately went to work on our character skin, eyes, and hair. <br />
<br />
For our skin, we implemented dual lobe specularity like you mentioned, which greatly improved the quality of our skin "sheen." We also refined our skin backscattering using photographic reference for ground truth. We added detail normals for pore detail as well.<br />
<br />
For the hair, we created a better tool for generating hair AO using Houdini Engine in Maya to better ground the hair. We did some tuning of the hair Material but kept the shading model the same for the hair as what Gears of War 4 used, which was a Disney Marschner shading model.<br />
<br />
We probably spent the most amount of time on the eyes. We added the Paragon bump offset to the Iris, we switched the eyes to using SSSSS (screen space subsurface scattering) so they looked much more natural in the socket (Gears of War 4 did not use SSSSS on the eyes). We added a lot of additional eye geometry such as eye water, tear duct, and eye AO geometry, which much improved the realism. As a finishing touch, we added in a dynamic Iris Caustic system inspired by Jorge Jimenez and Javir von der Pahlen&#39;s GDC 2013 talk. The faces were also re-worked to have much more accurate bone and face structures, which helped the believability a lot.<br />
<br />
<strong>Art Director Aryan Hanbeck: </strong>We really wanted to make a significant improvement on character faces from Gears of War 4. The very first few seconds of the game feature a very closeup shot of Kait&#39;s face waking up from her nightmare. We had a small strike team working on Kait’s face for most of the project and they used that close up shot as the proving ground to show progress. Every once in a while, we would see a big jump and would be happy with the results until we would find something else to improve. The nice thing was that as improvements were made to Kait, we would then be able to carry those changes over to the other characters, so the entire cast made a quality jump.<br />
 <br />
<strong>Gears 5 is being <a href="https://www.youtube.com/watch?v=9BiQaRO2oco&amp;feature=emb_title" target="_blank">praised</a> as arguably the best game to take advantage of <a href="https://docs.unrealengine.com/en-US/Engine/Rendering/HDRDisplayOutput/index.html" target="_blank">HDR</a>. Can you elaborate on how the studio leveraged machine learning to pull this off? <br />
<br />
Penty: </strong>We used a machine learning algorithm that was developed by Redmond&#39;s ATG group to train an inverse tone-mapper for color-space conversion. We then blended this 50 percent with a Reinhard buffer to allow maximum control. <br />
<br />
The technology behind the HDR is only part of the equation though. There was a lot of tuning needed on the content side to ensure muzzle flashes and skyboxes were in the proper luminosity band for example. Also, there is a lot of tuning from myself, working with the art director and engineers, on exposed parameters to ensure the HDR looks proper. Sometimes you can tune it to look "great" for one level but then the next level looks awful with those tuning values, so you need to be very careful to have global HDR values setup that still look great but also can handle a wide range of scenarios and maintain the artist’s intent.<br />
<br />
Finally, we spent a good amount of time ensuring we had a robust calibration screen that represented a range of lighting scenarios. We implemented the ability to hide the calibration image while tuning the HDR sliders and also exposed a curve to represent your HDR output. Finally, adding controls like an HDR contrast and max brightness really helped empower the player to get the look they wanted.<br />
<img alt="Developer_Interview_Gears_5_008.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_008-1920x1080-b7f51cfd4b5de561aab4efe4f0d597ce641024ff.jpg" width="auto" /><br />
<strong>Gears 5 features top-notch animations coupled with beautiful real-time cutscenes. Can you elaborate how you captured the game’s excellent performances?<br />
<br />
Penty: </strong>We made the switch to FaceWare to process all of our cinematic performances on Gears 5, which really helped with the fidelity. We, of course, have our talented team of animators that work on top of that data to bring the performance to life.<br />
 <br />
Our facial animation is primarily blend shape based, with joints used as "tuners" to allow us to modify the blendshapes. We went back and cleaned up all of our facial shapes to improve the facial animation quality as well as re-built our compression and expansion normal maps for the face from Gears of War 4. We then drive the blending of the expansion and compression <a href="https://docs.unrealengine.com/en-US/Engine/Content/Types/Textures/NormalMaps/Creation/index.html" target="_blank">normal maps</a> as well as blood flow to the face with 19 different wrinkle regions. Bringing all these improvements together combined with the character shader improvements really brought the characters to life.<br />
 <br />
<strong>The environments in the game are more detailed and diverse than ever before. Can you speak to how you designed them? <br />
<br />
Penty:</strong> From a technical point of view, it was really important for us to have a tight pixel density given we knew from the beginning this was going to be an Xbox One X product, so we added a detail texture pass to most objects in the game. We also put in a lot of effort to speeding up our environment Materials on the GPU so we could push more object density in Gears 5 despite it being a 60 fps game. Finally, we combined this with a <a href="https://docs.unrealengine.com/en-US/Engine/HLOD/index.html" target="_blank">HLOD</a> pass to allow us more draw calls.<br />
 <br />
<strong>Hanbeck:</strong> Gears 5 features the most diverse set of environments ever in a Gears game. As such, it was important to us to make sure that each Biome had a distinct visual signature and left a lasting impression. A lot of attention was paid to this from an art direction standpoint, making sure we pushed the colors, tone and atmosphere as far as we could.<br />
<img alt="Developer_Interview_Gears_5_009.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_009-1919x1080-7e50502ceb68f889717d0401394668265b534a62.jpg" width="auto" /><br />
<strong>Considering Gears 5 introduces open-world segments, a first for the series, can you talk about what it was like implementing those sections?<br />
<br />
Hanbeck:</strong> The larger spaces in the game that feature open-world elements posed a significant challenge on the art side. There was a very tight balancing act between performance and being able to put enough objects in the world to make sure it felt alive. At the end of the day, we had to come to grips with the fact that we would not be able to have the same density we were used to from our more linear levels. The bottom line is that you really don’t need as much density when you are going through the world at 10 times the speed you normally would when travelling on the Skiff. I think we found the right level of detail to make the world look not empty and be somewhat believable.<br />
<br />
<strong>Searcy: </strong>The whole idea of including more open, exploration areas was to evolve the "palate cleanser" vehicle sections from past games to include more player choice. The first step was to build the Skiff, a new wind-based vehicle. It was key that it was fun to drive on its own. After that, we went through many iterations of the open areas trying to get the right distance, speed, and shape for exploration. The last piece of the puzzle was actually Jack&#39;s progression. Once we had the loop of finding parts for Jack, we were able to build pockets of interesting combat that rewarded you with elements that affected the core game loop, allowing players to explore and pace out their experience between story missions however they wanted.<br />
<br />
<strong>Penty:</strong> Overall, I&#39;m really happy with the visual quality bar we were able to hit while achieving 60 fps in the overworld areas. It was a tight collaboration between, art, design, and tech to ensure the Xbox stayed in memory and had minimal pop-in. We leveraged the HLOD systems very heavily for the open-world segments due to the sight lines, as well as Unreal&#39;s landscape system. Artists would generate the landscape height and texture maps initially in World Machine then import those into the <a href="https://docs.unrealengine.com/en-US/Engine/Landscape/Creation/index.html" target="_blank">landscape system</a> in Unreal and continue to sculpt from there. All the landscape shaders ran tessellation shaders for the highest possible geometry density. The open-world areas were also a big incentive for us to move away from baked shadow maps and move to real-time cascades and ray-traced distance field shadows, as we really didn&#39;t want to store shadows maps for these huge spaces.<br />
 <br />
<strong>Gears 5 features impressive destruction set pieces that include destructible cover, and breakable ice. How did the studio implement that into the game?<br />
<br />
Penty: </strong>Similar to our particle investigations, we found that destructible cover had a really intense CPU overhead on Gears of War 4 and we needed to address that to go to 60 fps on Xbox One X. We extended our Swift Particle System into a Swift Destruction System, which was essentially a vertex offset based system built using the Material Editor. We tied Swift Destruction tightly to our Houdini Engine fracture tool, which would bake out all the data needed for the simulation into the UV sets (example: fracture points). For our shattering ice grounds, we had a vertex shader setup for that effect that would recognize if the ice had been just cracked or completed shattered. We would then have to work with design to setup a Blueprint to properly update the player collision when the ice had hit the damage threshold. We also used Alembic Cache simulation to drive vertex streamed destruction that was created offline in Houdini. This was great for set-piece destruction moments outside of the play-space.<br />
<img alt="Developer_Interview_Gears_5_010.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_010-3840x2160-cb04f3e458c0527317ffc6b89551aafbf71e923e.jpg" width="auto" /><br />
<strong>Gears 5 introduces new inventive enemies and gruesome bosses. How did you approach designing them?<br />
<br />
Searcy: </strong>Our enemy process is something we really worked on in Gears of War 4. We start with the role we want the enemy to have against the player. Should they flush the player? Pin them? Do they alternate through roles? Once we prove out the core effects it will have on the player in prototypes, we start to layer it with other enemies to see how it can be used in different combat encounters. With the design requirements in mind, Concept Art starts exploring the look and silhouette. Eventually a rigged proxy model is added to the functional prototype and we put the enemy through its paces in Campaign and Horde encounters to iterate on its behaviors and shape before we finish things like audio, VFX, and animation. One of the great things about working on Gears is that each enemy has a specific combat role and presence on the battlefield. Getting to conceive of new monsters and layer them into Gears is one of the best parts of the design process.<br />
 <br />
<strong>The multiplayer maps are varied in size and offer fantastic layouts. How did the team approach designing these stages?<br />
<br />
Multiplayer Design Director Ryan Cleven: </strong>In Gears of War 4, we wanted to make maps that felt like they belonged comfortably within the legacy of the previous Gears games. In Gears 5, we wanted to push the boundaries of what it meant to be a Gears of War map. We wanted to push further out of our comfort zone and try things that we hadn&#39;t done before. We broke the axis of symmetry on a few maps, making them rotationally similar instead of simply symmetric. We added a lot more dynamic elements that have significant gameplay impact. We pushed verticality further than ever before. We tried more organic shapes with terrain meshes that don&#39;t normally work in the Gears cover system. <br />
 <br />
Beyond the regular 5v5 maps, we added a completely new system with our modular tile system. We modified the game to load a recipe of tiles to create a layout for PvE or PvP modes. We used procedural systems in combination with a map builder made specifically for Gears 5 to make our new Escape mode.<br />
<br />
<strong>Considering Gears 5 features new AI, can you talk about what has been improved upon here since Gears of War 4?<br />
<br />
Studio Technical Director Mike Rayner:</strong> We added support for flying creatures and volume-based pathfinding, which was used to good effect by the new swarm flock enemies in Gears 5.<br />
 <br />
Player-initiated combat was a new addition to Gears 5 and to support that we enhanced our sensing systems [to] support a more robust idle state with idle behaviors, and introduced a new alert sensing state with dead body detection, investigating noises, and more.<br />
 <br />
We also added a number of new AI systems to support our game&#39;s needs:<br />
 
<ul style="margin-left: 40px;">
	<li>Influence maps (used when pathfinding and searching for cover)</li>
	<li>We replaced the Environment Query System (EQS) by a line of sight caching scheme (similar to our cover-based LOS caches), which allowed non-cover based enemies to efficiently use the space around them.</li>
	<li>Smart AI Objects for idle interactions with the world (replaces many scripted moments)</li>
	<li>A Tactic system to allow for coordination between characters
	<ul>
		<li>Dynamic combat zone tactic to distribute enemies around larger combat spaces</li>
		<li>Flanking tactic, Banzai tactic</li>
	</ul>
	</li>
</ul>
 <br />
Navigation Tools and Systems - we provided an expanded tool set for designers that included:<br />
 
<ul style="margin-left: 40px;">
	<li>Moving navmesh platforms with navigation between the platforms</li>
	<li>Rotating and stitching navigation meshes and volumes to support our procedural game modes (e.g., Escape)</li>
	<li>Dynamic open-world navigation mesh building</li>
</ul>
<img alt="Developer_Interview_Gears_5_011.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_011-3840x2160-f6ea8e5a16f19a5b59350bb0d8ee6996a888083d.jpg" width="auto" /><br />
<strong>Gears 5 is a visual showcase that not only looks great but runs well across a variety of platforms. How did the studio optimize the game so well?<br />
<br />
Rayner:</strong> From the outset of the project, we targeted 60 fps against a fairly low-spec CPU (Xbox One and equivalent min-spec PC CPU). We knew the CPU was going to be our primary bottleneck, so we invested to keep our simulation as lean as possible. We took advantage of UE4&#39;s multi-core <a href="https://docs.unrealengine.com/en-US/Programming/Rendering/ParallelRendering/index.html" target="_blank">parallel rendering</a>, parallel animation and physics support along with our own custom multi-core optimizations to leverage multiple cores and scale performance across a wide range of CPUs. We also invested in some custom simulation LOD management, which would dynamically adjust local client simulation fidelity of characters and VFX to fit a fixed time-budget. While we embraced Blueprints for prototyping, we carefully monitored performance and moved heavier systems and common patterns into <a href="https://docs.unrealengine.com/en-US/Programming/Introduction/index.html" target="_blank">C++</a> code to keep the simulation lean. <br />
 <br />
For engine performance and visual settings, we leveraged Unreal&#39;s <a href="https://docs.unrealengine.com/en-US/Engine/Performance/Scalability/ScalabilityReference/index.html" target="_blank">scalability options</a>, properties, and console variables to good effect to ensure the game is optimally tuned for each platform. We defined clear budgets for content which we validate on development PCs. This along with UE4&#39;s Static Mesh LOD and HLOD systems, and using dynamic temporal upscaling allows us to scale our content to look good and perform across a wide range of PC hardware from min and recommended to ultra spec PCs as well as consoles [like] Xbox One S up to Xbox One X. <br />
 <br />
We chose a reasonable minimum spec for PC and console to ensure memory and performance was kept in-check across all devices, we validated this through automated testing and telemetry from play-sessions. <br />
<strong> <br />
Penty: </strong>We daily tracked our percent at 60 fps for all of our levels in our QA playthroughs (example: 85 percent at 60 fps). Our performance reports would also include stats like "Bound by Render Thread: five percent of the time," so we knew what threads would be holding up performance. This allowed our technical art and engineering teams to jump into a level with an idea as to what had to be brought down (example: Render Thread bound might imply we have too many shadow casters or too many objects drawing). While we were focusing on the content optimizations daily, I would usually be tuning the global scalability settings per platform/per game mode/per split screen setup, massaging the performance profile.<br />
<br />
<strong>How important was it to have access to Unreal Engine’s <a href="https://docs.unrealengine.com/en-US/GettingStarted/DownloadingUnrealEngine/index.html" target="_blank">source code</a> for the development of the game?<br />
<br />
Rayner:</strong> Having access to the source code was crucial to the optimization, debugging, and agility of AAA game development. The ability to diagnose game issues though engine source level debugging is critical to solving subtle issues in our game&#39;s implementation. Source access allows us to back-port bug fixes and improvements from Epic without requiring a full-engine upgrade and allows us to fix and make improvements to the engine directly (often contributing these changes back to Epic). Reading source code, and engine developer comments enables our team to understand the engine at the same level that Epic does, which gives us confidence we are using it effectively, and when absolutely necessary a pathway to extend and evolve the engine directly to meet our needs. We rebuild the engine from source ourselves, which enables us to work with newer versions of compilers, and leverage runtime/game specific compiler and linker optimization like performance guided optimization. <br />
<img alt="Developer_Interview_Gears_5_007.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_007-1920x1080-a8ad8e8de8f4846c42d838b927cda7cd573a10b7.jpg" width="auto" /><br />
<strong>Gears 5 features both three-player local and online co-op. Was this a technical challenge to implement?<br />
<br />
Rayner:</strong> Unreal Engine supports multiple viewports and has split-screen support, so a lot of the low-level support is in place. We invested in input/focus management to support multiple user sign-in to ensure this was a good user experience. Performance is always a challenge with multiple view ports. On Xbox One S, we needed to hold the same fps in split-screen as we did in full-screen models. We approached this by defining different scalability settings and visual options for split screen modes, as well as by introducing some detail tags, which allowed us to turn off high detail objects on lower-spec hardware. For Xbox One X, we opted to drop from 60 fps (full screen) to 30 fps (split-screen). This allowed us to retain the highest quality visual settings and native resolutions in split-screen modes, which we think was a good trade off. <br />
 <br />
Online co-op is also something UE4 supports with minimal effort provided you have implemented networking replication thoughtfully. For co-op, one of the up to three players is a client hosted listen-server, while the others are clients. Thought and effort is required to ensure co-op experiences were replicated correctly, the best approach here is to ensure level designers and engineers are testing standalone co-op to ensure everything is replicating and working as expected as part of the local review process before submitting changes. We had technical level designers and engineers that worked with our level designers to assist with replication (often handled in C++) and to create common reusable systems that abstract away replication and support save/load and checkpoints. <br />
 <br />
Allowing players to join games in progress over the network also presents its own challenges, particularly since we have few restrictions around when a player can join. They can join as the game is loading, in the middle of a fire-fight, while we’re playing cinematics or transitioning levels, which presents a number of challenges. For example, keeping the experience as seamless as possible, synchronizing our real-time cinematics and transitioning smoothly into gameplay for multiple players is difficult on its own. Adding in join-in-progress and bad networking conditions greatly increases the complexity. We avoid showing loading screens as much as possible, but had to keep them as a stop-gap for the most difficult moments. The key is to have technical content creators in cinematics, animation, and design that can focus on fixing and mitigating those edge cases, while having engineers create a system that is strong and flexible for the many ways that content comes together.<br />
<img alt="Developer_Interview_Gears_5_002-2.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_002-2-1920x960-6065b8c3dd65eb5f2959f8e362e69b3e1c539ba6.jpg" width="auto" /><br />
<strong>Considering the game introduces a new multiplayer Escape mode that forces players to escape from the Hive, can you talk about what inspired this mode?<br />
<br />
Cleven: </strong>As fans of Horde mode, we really wanted to create a shorter co-op experience that we could play when we didn&#39;t have a full squad together. The original idea was to create a photo-negative of Horde that could stand next to it. Horde is about making a base where the enemies come to you. Escape is about destroying an enemy hive, i.e. You go to the enemy. It still had to be a survival mode just like Horde. The main objective had to still be “survive,” but the twist is you had to find the exit in a maze or dungeon.<br />
 <br />
The concept drove the need for a new fiction wrapping. We wanted something that got right to the point, with ultra-high stakes that would make sense in the savage world of Sara. The characters still needed to be highly trained like the rest of the Gears, but they needed a different circumstance. Starting with no ammo, with a bomb strapped to their chest, voluntarily getting snatched and waking up deep underground at the heart of a Swarm hive sounded bad ass. It was crazy enough that it felt like it could sit next to a mode where you destroy hundreds of enemies with thousands of bullets.<br />
<img alt="Developer_Interview_Gears_5_001.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_001-2304x1296-1346efcd55a066ddc6f6b82d4d7e7a10cc11709a.jpg" width="auto" /><strong>Was it hard to implement cross-platform support across PC and Xbox One? <br />
<br />
Rayner: </strong>On the whole, cross-platform development with UE4 is fairly straightforward; provided you follow best practices and stay on top of min-spec memory and baseline performance, everything just works. <br />
 <br />
Unreal Engine is designed to work cross-platform out of the box and is by and large a device/platform agnostic game engine. For Gears 5, we targeted Xbox One, PC (Steam and Windows Store) and dedicated servers all from the same cross-platform code base. You do have to stay on top of warnings and errors generated by the editor and compiler, which will help ensure your content and code will work across all platforms. Beyond that, if it works in editor, it will generally run without issues on other platforms.<br />
 <br />
As a cross-platform networked game engine supporting variable time-steps (Delta Time), it is worth noting that cross-platform multiplayer worked out of the box. We did make changes to add Xbox Live cross-platform match-matching and worked on few load-time and extreme framerate scenarios differences causing some timing issues between low and highest spec hardware. In the end, cross-platform development with UE4 is one of its key strengths.  <br />
<img alt="Developer_Interview_Gears_5_005.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fdeveloper-interviews%2Fthe-coalition-dives-deep-into-the-tech-of-gears-5%2FDeveloper_Interview_Gears_5_005-1920x1080-ba6d881d6f4decd5d477446894153b1fd5c6220b.jpg" width="auto" /><br />
<strong>How important was it for the team to implement robust settings options for the PC version of the game?<br />
<br />
Rayner: </strong>With UE4, we are able to detect a player’s hardware and choose appropriate defaults across a wide range of features and scalability settings to ensure players have an excellent experience out of the box no matter what hardware they are running on. <br />
 <br />
We believe PC players expect to be able to tune a game to their preferences, which could be ultra-high frame rates, extreme visuals, or any custom combination based on their preference. We have over 35 settings that users can adjust. We believe in helping users understand what they are changing so each setting comes with a detailed description of what the setting does as well as the impact it will have on CPU, GPU and VRAM. In addition, settings that are directly visual come with a preview image for each quality level so users know exactly what they are changing. <br />
<br />
We also have a variety of controls to manage resolution and frame rate. All of the expected controls are there, including resolution, VSync, and field of view. In addition to these, we&#39;ve added ways to manage the maximum frame rate of gameplay and cinematics independently so users can play at an unlimited framerate and then enjoy the cinematics (which are all real time) at a lower frame rate but with higher detail. We&#39;ve also added a minimum frame rate option that will dynamically keep the game running at a specified frame rate (or greater). <br />
<br />
<strong>Penty: </strong>Overall, Gears 5 is quite a scalable game, especially compared to Gears of War 4. So it scales up beautifully to high-end PCs, or can scale down to low-end hardware.  I&#39;m especially a fan of our Ultra spec shadows, volume fog, and reflections, which look amazing.<br />
 <br />
<strong>Did the development team have any favorite Unreal Engine tools or features?<br />
<br />
Penty:</strong> It is hard to pick a single feature, but for me personally, I&#39;d probably have to go with the temporal upscaling as my favorite feature. It allowed us to really push the visual quality and not worry about the frame getting soft with resolution scaling in-play. My close second would be the Volumetric Fog system and the level of atmosphere it allowed us to add to the game.<br />
 <br />
<strong>Mike Rayner:</strong> The <a href="https://docs.unrealengine.com/en-US/Engine/Replay/index.html" target="_blank">Replay System</a> formed the basis for which we implemented our Kill Cam feature for dedicated multiplayer servers. The Replay system is a powerful addition to the engine, and through it we were able to add this long requested contemporary multiplayer feature to Gears 5 with far less effort than if we were to build the feature from the ground up.<br />
<br />
<strong>For more information on Gears 5, visit:</strong><br />
 
<ul style="margin-left: 40px;">
	<li><a href="https://twitter.com/gearsofwar?lang=en" target="_blank">Twitter</a></li>
	<li><a href="https://discordapp.com/invite/gearsofwar" target="_blank">Discord</a></li>
	<li><a href="https://www.facebook.com/pages/category/Video-Game/Gears-of-War-5-182893705704020/" target="_blank">Facebook</a></li>
	<li><a href="https://www.youtube.com/channel/UC3E8iPQGBdAnOQR_cmkEbsw" target="_blank">YouTube</a></li>
</ul>
";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:7:"Gears 5";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:12:"Gears of War";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:13:"The Coalition";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:5:"Games";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:11:"Jimmy Thang";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Thu, 21 Nov 2019 16:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Thu, 21 Nov 2019 16:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:99:"https://www.unrealengine.com/developer-interviews/the-coalition-dives-deep-into-the-tech-of-gears-5";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:99:"https://www.unrealengine.com/developer-interviews/the-coalition-dives-deep-into-the-tech-of-gears-5";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}i:23;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:10:{s:5:"title";a:1:{i:0;a:5:{s:4:"data";s:44:"Join the Unreal Engine team at I/ITSEC 2019!";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"icon";a:1:{i:0;a:5:{s:4:"data";s:178:"https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IITSEC_blog_thumb-375x275-c70ee04005fff345aba97fe8a1d9f0b111d4860a.jpg";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"summary";a:1:{i:0;a:5:{s:4:"data";s:231:"I/ITSEC 2019 is just around the corner! Come and explore how innovative real-time training and simulation solutions built on Unreal Engine are improving realism, safety, and performance across the defense and security industries. ";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"content";a:1:{i:0;a:5:{s:4:"data";s:14367:"It’s not long now until <a href="https://www.iitsec.org/" target="_blank">I/ITSEC 2019</a>, and we’re excited to share our plans with you. This year’s conference will be held at the Orange County Convention Center in Orlando, Florida from December 2-6. The event will showcase the latest innovations in modeling, training, and simulation, and we’re thrilled to share our technology expertise in this area. Unreal Engine will be on the show floor in <strong>booth #2161</strong>, so be sure to stop by and check out what we have in store for you.
<h2>In-booth demonstrations</h2>

<h3><img alt="Events_IISTEC_blog_body_img5.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IISTEC_blog_body_img5-1640x1000-7e6eaee308e7c6dd83720a4245b4f066e8420925.jpg" width="auto" /><br />
<strong>A first look at nDisplay: Simulation multi-channel projections made easy with the new native blending and warping capability in Unreal Engine</strong></h3>
In collaboration with Scalable Display, Barco, Immersive Display, and Simthetiq, this is a demonstration of nDisplay in a dome. Using traditional simulation pipelines, users can generate visualization solutions based on Unreal Engine able to deploy from a cell phone to a dome passing by XR HMDs. Additionally, in this interactive demo visitors will discover Simthetiq simulation 3D assets specially produced for Unreal Engine for the first time.<br />
<br />
<img alt="Events_IISTEC_blog_body_img4.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IISTEC_blog_body_img4-1640x1000-2743cc920308e13d937526317f683c8bd9661bac.jpg" width="auto" />
<h3><strong>Driving training innovation: A high-fidelity VR military vehicle full-motion simulation showcasing the advantages of CM Labs’ Vortex combined with Unreal Engine</strong></h3>
Vortex, the high-fidelity multibody dynamics simulation engine from CM Labs, has recently been integrated with Unreal Engine. The capabilities of this new Unreal Engine plugin will be demonstrated in this driver training simulation, with D-BOX motion cueing system generating the kinesthetic cues.<br />
<br />
<img alt="Events_IISTEC_blog_body_img1.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IISTEC_blog_body_img1-1640x1000-aa651c3bd5f46f900c0c2828d9f9e1701626d9b5.jpg" width="auto" />
<h3><strong>Introducing an interactive and open infantry training framework: Offworld Industries and Aperium present an innovative infantry training alternative to the simulation community</strong></h3>
Offworld Industries’ framework is an Unreal Engine-based set of plugins, assets, vehicles, and human representations dedicated to defense applications, a true-to-life sound effects generation system, and map terrains representative of field operation stages. All are geared toward creating an applicative software layer that can be used to create training exercises. The framework is built on top of Unreal Engine, which is Offworld’s core platform. Offworld couples Unreal Engine’s realistic graphics output with its Blueprint visual scripting system to handle any body of data that needs to be incorporated into the training. <br />
 
<h2>Innovation showcase - Booth #2588</h2>
We’ll be showcasing Unreal Engine in the 2020 Innovation Spotlight in booth #2588 on Wednesday, December 4 at 2:45 PM. Join us as Sebastien Loze, Epic Games’ Simulations Industry Manager, presents Unreal Engine’s Training and Simulation vision. This innovation showcase session will be an opportunity to learn about how Epic Games is supporting industry collaborations and existing open standards.<br />
 
<h2>Unreal Engine on the show floor</h2>

<h3><strong>ARA - Booth #2572</strong></h3>
Applied Research Associates (ARA) is an international research and engineering company that specializes in defense technologies, civil engineering, computer software and simulation, systems analysis, environmental technologies, and blast testing and measurement. ARA will be demonstrating projects built with Unreal Engine technology, including:<br />
 
<ul style="margin-left: 40px;">
	<li>A joint terminal attack controller VR platform</li>
	<li>Synthetic terrain generation from DoD sources into an Unreal Engine format</li>
	<li>Rapid conversion of drone data into Unreal Engine VR platforms</li>
	<li>A portable Air Force Virtual Trainer combined PC and VR platform </li>
</ul>
 

<h3><strong>Bionatics - Booth #2320</strong></h3>
Bionatics provides real-time, large-scale procedural terrain to the training and simulation community. Its middleware solution enables the community to reach the highest resolution possible from very coarse GIS datasets.<br />
<br />
Visitors will experience the world premier demo of Blueberry3D integration in an Unreal Engine context. In collaboration with B-Design3D, Bionatics have produced the first version of the Baka geographic virtual environment, which is UE4-ready and supports Physic Based Rendering (PBR) materials. A copy of this demo will also be available on demand at the Unreal Engine booth #2161.<br />
 
<h3><strong>CESI - Booth #2084</strong></h3>
<br />
Cole Engineering Services, Inc. (CESI) will be showcasing a number of its Unreal Engine applications built for simulation and training using its EDGE platform, including: <br />
 
<ul style="margin-left: 40px;">
	<li>A First Responder Sandbox (FRS) training tool for the Department of Homeland Security (DHS)</li>
	<li>An Attack the Network (AtN) training tool for the US Army</li>
	<li>Several other pilots, prototypes and proofs of concept for US military, customs, and law enforcement agencies</li>
</ul>
<br />
A multiplayer tank shooter game will be available to play at the booth, and there will be an official announcement of CESI’s recent agreement with Epic Games related to licensing and support of Unreal Engine technology.<br />
 
<h3><strong>Inlusion: Booth #775</strong></h3>
Inlusion is a VR/AR company that specializes in delivering a wide range of immersive solutions across many different industries, including manufacture, transport, energy, healthcare and more. It will showcase a number of VR and AR projects, including:<br />
 
<ul style="margin-left: 40px;">
	<li>An award-nominated Boeing 737 Thrust Reverse Opening Procedure for Oculus Quest (Mobile VR)</li>
	<li>A de-icing and anti-icing procedure in VR</li>
	<li>An augmented reality Boeing 737-800 Engine </li>
	<li>Its AR catalog</li>
</ul>
 

<h3><strong>SimCentric Technologies - Booth #1259</strong></h3>
<br />
SimCentric Technologies develops simulation software to facilitate safe, effective and realistic combat training in specialized, safety-critical domains. At this booth, visitors will see its simulation platform built on Unreal Engine that is:<br />
 
<ul style="margin-left: 40px;">
	<li>Optimized for team-based VR training</li>
	<li>Standards-based, HLA/DIS/CIGI capable</li>
	<li>Designed to enable mission rehearsal, collective training, and part task training</li>
	<li>Integratable with SAF-FIRES to provide accreditable joint fires training</li>
</ul>
 

<h3><strong>TrianGraphics - Booth #980</strong></h3>
Trian3DBuilder is the data integration and editing tool for the automated generation of large scenarios that focuses not only on flight, rural, and nautical databases, but also on the generation of urban scenes. At this booth, TrianGraphics will showcase new and existing functionality in Trian3DBuilder, including:<br />
 
<ul style="margin-left: 40px;">
	<li>Integration with Datasmith, enabling any environment to be easily exported and integrated into Unreal Engine</li>
	<li>Expanded capabilities for building creation and automatic road generation, with a worldwide highly accurate road database</li>
	<li>Powerful GIS data processing capabilities for generating simulation environments</li>
</ul>
 

<h3><strong>Offworld Industries - Booth #2580</strong></h3>
Offworld Industries’ framework, built on top of Unreal Engine, provides plugins, assets, vehicles, and human representations that can be used to create defence training exercises. They will be showcasing projects built on this framework that include: <br />
 
<ul style="margin-left: 40px;">
	<li>An immersive operational readiness training environment that provides a platform for remote communication and orientation of NATO forces from remote bases around the world. (Presented on NATO booth #2173)</li>
	<li>A collaboration with Vigilante Designs showcasing Unreal Engine’s ability to drive high-fidelity experience into the training realm by showing a complex operation environment in mid-battle between two modern army forces employing remote-operated vehicles to locate and eliminate enemy units.</li>
</ul>
<img alt="Events_IISTEC_blog_body_img8.png" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IISTEC_blog_body_img8-1600x976-e55188d19103c2ee057ecb8e6e85aecd37f99744.png" width="auto" />
<h3><strong>Presagis - Booth #2848</strong></h3>
Presagis delivers simulation and graphics software to defense and aeronautic organizations around the world. It will be showcasing projects that include: <br />
 
<ul style="margin-left: 40px;">
	<li>AI-Driven Pattern of Life: Watch a fascinating demo of how entities are assigned behaviors in a geolocalized hostile combat environment using AI. </li>
	<li>Dismounted Immersive Ground Motion VR Trainer: No joysticks. No teleporting. Real walking. Walk with unprecedented freedom of movement in a VR pod trainer. </li>
	<li>Unreal and Ondulus NVG: A next level, ultra-realistic NVG simulation running within Unreal Engine using a VR headset.</li>
	<li>ORB ViewR: Launched last year at I/ITSEC, the free ORB ViewR is an Unreal Engine-powered viewer for large-scale CDB environments.</li>
	<li>OpenFlight Importer: This new OpenFlight importer allows users to use all of their .OFT assets in Unreal Engine.</li>
</ul>
 

<h3><strong>Quantum3D - Booth #1049</strong></h3>
Quantum3D provides training and simulation technologies, and integrated solutions and services for the commercial, civil, and defense markets worldwide. It will be showcasing its parachute simulator, providing an insight into how the system helps to:<br />
 
<ul style="margin-left: 40px;">
	<li>Train paratroopers in VR environments</li>
	<li>Decrease the number of real jumps and classroom training sessions</li>
	<li>Make paratroopers more aware of the geographical environment, which increases the success of each operation</li>
</ul>
<img alt="Events_IISTEC_blog_body_img7.jpg" height="auto" src="https://cdn2.unrealengine.com/Unreal+Engine%2Fevents%2Fjoin-the-unreal-engine-team-at-i-itsec-2019%2FEvents_IISTEC_blog_body_img7-1640x892-b69094739047bd0bf49b3f8c84d4df9c72a5d776.jpg" width="auto" />
<h3><strong>HTX Labs - Booth #1392</strong></h3>
HTX Labs will be demonstrating its EMPACT XR content authoring, management, and distribution platform built on Unreal Engine. It will showcase two high-fidelity immersive training simulations developed in collaboration with the US Air Force:<br />
 
<ul style="margin-left: 40px;">
	<li>A T-6A/B Emergency Procedure (EP) training simulation developed as part of the Air Force - Pilot Training Next initiative</li>
	<li>A C-130 transport aircraft wheel and tire change simulation being developed as part of the Maintenance Next initiative</li>
</ul>
 <br />
These demonstrations will show integration with the Oculus Quest and Varjo VR-2 headsets, as well as use of the BeBop data gloves. In addition, HTX Labs will be providing an early look at its EXEMPLAR content creation tool that enables subject matter experts to create original, high-value content in a fully-interactive, 6-DOF synthetic environment.
<h3><strong> <br />
CUBIC - Booth #1948</strong></h3>
Cubic is a worldwide provider of training systems that deliver the critical warfighting skills necessary to achieve mission success, no matter the conditions or adversary. Cubic’s industry-leading, next-generation training solutions include: multi-domain live, virtual and constructive (LVC) training, immersive simulation, game-based learning, air combat training, and high-fidelity combat training systems. <br />
 
<ul style="margin-left: 40px;">
	<li>Game-based learning studio
	<ul>
		<li>LIDAR-fed high-fidelity interior environments delivered through Unreal Engine </li>
		<li>Ties Cubic Global Defense’s industry-leading learning science to Unreal Engine immersive game environments to train personnel on complex systems with high retention</li>
	</ul>
	</li>
	<li>SYN-ISR
	<ul>
		<li>Uses Unreal Engine to create an H.264 ISR video feed that replicates UAS feeds for training exercises (including platform/sensor telemetry)</li>
		<li>Allows full LVC scenarios to render on operational systems for analysts, warfighters, and command decisions with excellent fidelity</li>
	</ul>
	</li>
</ul>
  <br />
*This list is not intended to be comprehensive of all places where Unreal Engine will be demonstrated on the show floor.
<h2><br />
Iron Dev Challenge</h2>
Teams will be asked to solve an Air Force training problem by developing a prototype training solution. The solution may be a game, an AR/VR system, a simulator, or a combination of these. The Air Force training problem will be to develop a solution which will be of high value to airmen, pilots, maintainers, or others in the Air Force. Unreal Engine will be one of the tools available to use, along with other simulation software products. Epic Games Support team leader, Martin Sevigny, will be working with the four teams as a non-biased mentor to help them with the programming and integration challenges they will face.  <br />
<br />
<strong>When: </strong><br />
Kickoff event: Monday, December 2 | 10 AM <br />
Ends: Thursday, December 5 | 10 AM<br />
<br />
<strong>The teams:</strong>

<ul style="margin-left: 40px;">
	<li>Army</li>
	<li>Naval force graduates (representing Navy and Marine Corp)</li>
	<li>Air Force</li>
	<li>Bohemia Interactive sponsored team  </li>
</ul>
 <br />
We look forward to seeing you at I/ITSEC 2019.<br />
 ";s:7:"attribs";a:1:{s:0:"";a:1:{s:4:"type";s:4:"html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:8:"category";a:4:{i:0;a:5:{s:4:"data";s:21:"Training & Simulation";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:1;a:5:{s:4:"data";s:7:"Defense";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:2;a:5:{s:4:"data";s:9:"Community";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}i:3;a:5:{s:4:"data";s:6:"Events";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:6:"author";a:1:{i:0;a:6:{s:4:"data";s:0:"";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";s:5:"child";a:1:{s:27:"http://www.w3.org/2005/Atom";a:1:{s:4:"name";a:1:{i:0;a:5:{s:4:"data";s:14:"Sebastien Loze";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}s:9:"published";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 20 Nov 2019 19:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:7:"updated";a:1:{i:0;a:5:{s:4:"data";s:29:"Wed, 20 Nov 2019 19:30:00 GMT";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:4:"link";a:1:{i:0;a:5:{s:4:"data";s:0:"";s:7:"attribs";a:1:{s:0:"";a:3:{s:4:"href";s:79:"https://www.unrealengine.com/events/join-the-unreal-engine-team-at-i-itsec-2019";s:3:"rel";s:9:"alternate";s:4:"type";s:9:"text/html";}}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}s:2:"id";a:1:{i:0;a:5:{s:4:"data";s:79:"https://www.unrealengine.com/events/join-the-unreal-engine-team-at-i-itsec-2019";s:7:"attribs";a:0:{}s:8:"xml_base";s:0:"";s:17:"xml_base_explicit";b:0;s:8:"xml_lang";s:0:"";}}}}}}}}}}}}s:4:"type";i:512;s:7:"headers";a:14:{s:4:"date";s:29:"Fri, 13 Dec 2019 20:06:33 GMT";s:12:"content-type";s:24:"text/html; charset=utf-8";s:13:"cache-control";s:19:"no-cache=set-cookie";s:16:"content-encoding";s:4:"gzip";s:4:"etag";s:37:"W/"47672-mitquaYja7urb8swZ6IemI4fcbE"";s:10:"set-cookie";s:360:"EPIC_CLIENT_SESSION=U-ywkE_Ps22Mru8yvuFIsQ.dvR-Ob-I-IDbUg8SqjgACxbGsLo3S-dwljLU1uqZBX_p2YT8hK3o7RQ8srB1U2jP.1576267593529.86400000.IAs6SascQTejyo6pKK3s59r7vjYskYPbHqOTTi6VE_8; path=/; httponly, AWSELB=CB09F12B0648991B03A3DAA1A9213B7724874A65184F41D99AE0726648E59B0F9805C9A3245EE61300192163DEED36A20FB6A75F0A37A8435EE3ED9162A30744AA8C35EB37;PATH=/;MAX-AGE=86400";s:25:"strict-transport-security";s:16:"max-age=15552000";s:4:"vary";s:15:"Accept-Encoding";s:22:"x-content-type-options";s:7:"nosniff";s:22:"x-dns-prefetch-control";s:3:"off";s:18:"x-download-options";s:6:"noopen";s:21:"x-epic-correlation-id";s:36:"0f53ca80-1de4-11ea-ba28-1bc50e0a35f7";s:15:"x-frame-options";s:22:"SAMEORIGIN, SAMEORIGIN";s:16:"x-xss-protection";s:13:"1; mode=block";}s:5:"build";s:14:"20191213195805";}